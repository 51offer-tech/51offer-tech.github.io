{"pages":[{"title":"关于我","text":"我是一个大龄低学历程序猿，虽然不是非常热爱代码，但是还是喜欢折腾，如果有兴趣交流，可以加我QQ:188781475","link":"/about/index.html"},{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"Golang基础学习总结之开篇","text":"Go, also known as Golang, is a statically typed, compiled programming language designed at Google by Robert Griesemer, Rob Pike, and Ken Thompson. Go is syntactically similar to C, but with memory safety, garbage collection, structural typing, and CSP-style concurrency 几个月前，兴趣使然，我偶然学了一个月的go语言，并开发了两个简单的小程序(短域名服务和微信记事本小程序)，感受到了golang的简洁和强大。可是我并没有做一个学习总结，所以接下来，我将简单是分几篇文章来简单的总结一下golang的基础内容。这里我们先简单列举几个Golang的优点： 1、语法简洁 2、强大的标准库 3、性能好 4、开发效率高 5、天生支持并发 6、编译效率高 …… Hello World一般学习一门新语言，都是从Hello world开始的，下面，我就来感受一下Golang的简洁，在这里我推荐大家使用Goland这款IDE,当然如果vs code用得很6的话也可以。 12345678package main //包名import &quot;fmt&quot; 导入fmt包//main主函数func main() { fmt.Println(&quot;Hello World&quot;) //打印输出Hello World} Go语言以包(package)作为管理单位，每个Go 源文件都必须先声明它所属的包，Go语言的包与文件夹是一一对应的，默认情况下同级目录下的文件属于同一个包，包名也可以与目录名不同。main包是Go语言程序的入口包，一个Go语言程序必须有且仅有一个 main 包。如果一个程序没有 main 包，那么编译时将会出错，无法生成可执行文件。main函数是main包里面的启动函数，如果没有main函数启动也是会报错。go预览编译也很简单，直接到项目目录执行go build 即可在同级目录生成一个exe的可执行文件。","link":"/20191121/Golang%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93.html"},{"title":"AccessibilityService自动刷视频","text":"使用AccessibilityService实现自动刷视频，赚点小钱 最近很多人在推精简版的快手、抖音等app来赚钱，邀请人之后，可得佣金，每天刷视频也可以的金币换RMB，所以一些闲来无事的人就整体拿着手机刷刷刷，那么有没有什么自动的方式，让我们解放双手呢？Android自动化测试的框架比较多，大家可以自行百度。下面就介绍几种常用的： 模拟MotionEvent这个功能只能给自己本身的app发送Event，无法跨App。 Instrumentation现在有很多基于Instrumentation的自动化测试框架，但是也无法跨App操作，如果想要跨App的话，就只有获得root权限或者系统签名。这两种方式都有些麻烦。 ADB命令需要在PC端执行adb命令，那么就需要USB连接到电脑上，在PC端发送input的shell脚本命令，如果再手机端执行input tap等命令，也需要root权限。操作还是很麻烦 AccessibilityService服务现在很多复制工具都是基于AccessibilityService开发的，通过给予一定的权限，监听手机端的动作，然后查找相应节点，向指定节点发送相应的指令。为了节约时间，我在百度找到一篇文章AccessibilityService实现文本的自动全选黏贴、点击、滑动。利用dispatchGesture+AccessibilityService来实现自动刷新视频，我将其稍作修改，就可以对刷抖音、快手、趣多多等app进行跨应用刷视频，这样一来省了不少时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private void slideVertical(int startSlideRatio, int stopSlideRatio) { sliderCount++; int screenHeight = ScreenUtils.getScreenHeight(getApplicationContext()); int screenWidth = ScreenUtils.getScreenWidth(getApplicationContext()); L.e(&quot;屏幕：&quot; + (screenHeight - (screenHeight / 10)) + &quot;/&quot; + (screenHeight - (screenHeight - (screenHeight / 10))) + &quot;/&quot; + screenWidth / 2); Path path = new Path(); int start = (screenHeight / 20) * startSlideRatio; int stop = (screenHeight / 20) * stopSlideRatio; L.e(&quot;屏幕：&quot; + start + &quot;/&quot; + stop + &quot;/&quot; + screenWidth / 2); path.moveTo(screenWidth / 2, start);//如果只是设置moveTo就是点击 path.lineTo(screenWidth / 2, stop);//如果设置这句就是滑动 StringBuffer sb = new StringBuffer(); sb.append(&quot;滑动次数&quot; + sliderCount + &quot;次\\n&quot;); sb.append(&quot;滑动时间&quot; + Utils.formatUTC(System.currentTimeMillis(),null) + &quot;\\n&quot;); sb.append(&quot;开始位置&quot; + start + &quot;\\n&quot;); sb.append(&quot;结束位置&quot; + stop + &quot;\\n&quot;); Intent mIntent = new Intent(MainActivity.RECEIVER_ACTION); mIntent.putExtra(&quot;result&quot;, sb.toString()); //发送广播 sendBroadcast(mIntent); GestureDescription.Builder builder = new GestureDescription.Builder(); GestureDescription gestureDescription = builder .addStroke(new GestureDescription. StrokeDescription(path, 200, 200)) .build(); dispatchGesture(gestureDescription, new GestureResultCallback() { @Override public void onCompleted(GestureDescription gestureDescription) { super.onCompleted(gestureDescription); L.w(&quot;滑动结束&quot; + gestureDescription.getStrokeCount()); } @Override public void onCancelled(GestureDescription gestureDescription) { super.onCancelled(gestureDescription); L.w(&quot;滑动取消&quot;); } }, null); } 效果图:","link":"/20191024/AccessibilityService%E8%87%AA%E5%8A%A8%E5%88%B7%E8%A7%86%E9%A2%91.html"},{"title":"DataX将DB2数据同步到GBase中","text":"DataX 是阿里开源的异构数据源离线同步工具，致力于实现包括关系型数据库(MySQL、Oracle等)、HDFS、Hive、ODPS、HBase、FTP等各种异构数据源之间稳定高效的数据同步功能。阿里云开源离线同步工具DataX3.0介绍 在2015年的时候，项目有用到DataX1.0来开发提数功能，使用很方便，我们自己也扩展一些插件,如DB2Writer、DB2Reader、GBaseWriter、GBaseReader等，不得不说，DataX的插件功能真的很强大很灵活。再到后来，2018年的时候，涉及到跨库数据定时同步。因为当时所涉及的数据量不大，也就几万，最多十几万的数据处理和同步。所以选用了Kettle,这款工具上手也比较快，图形化操作，我们在GUI中设计好我们的ktr和kjb，在定时通过命令的方式来执行kjb的方式实现定时ETL数据处理、同步功能。但是,Kettle已经满足不了我们了，因为我们要把上亿的指标数据从DB2同步到GBase中，当然比较好的方式多是从DB2导出文件然后load到GBase中，但是目前权限不够，也因为只有一台主机，没办法做相应的操作。那么就又得请出我们的DataX杀手锏。 手动编译DataX工具: Maven Git Idea Jdk1.8当然你也可以不用Git和Idea直接下载下来执行Maven命令即可.使用Idea导入DataX:点击clone后，就会下载代码，下载完成后就会下载依赖包。等待依赖包安装完成,执行打包命令:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107mvn -U clean package assembly:assembly -Dmaven.test.skip=true[INFO] Reading assembly descriptor: package.xml[INFO] datax/lib\\commons-io-2.4.jar already added, skipping[INFO] datax/lib\\commons-lang3-3.3.2.jar already added, skipping[INFO] datax/lib\\commons-math3-3.1.1.jar already added, skipping[INFO] datax/lib\\datax-common-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\datax-transformer-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\fastjson-1.1.46.sec01.jar already added, skipping[INFO] datax/lib\\hamcrest-core-1.3.jar already added, skipping[INFO] datax/lib\\logback-classic-1.0.13.jar already added, skipping[INFO] datax/lib\\logback-core-1.0.13.jar already added, skipping[INFO] datax/lib\\slf4j-api-1.7.10.jar already added, skipping[INFO] Building tar : F:\\WorkAbout\\work\\DataX\\target\\datax.tar.gz[INFO] datax/lib\\commons-io-2.4.jar already added, skipping[INFO] datax/lib\\commons-lang3-3.3.2.jar already added, skipping[INFO] datax/lib\\commons-math3-3.1.1.jar already added, skipping[INFO] datax/lib\\datax-common-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\datax-transformer-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\fastjson-1.1.46.sec01.jar already added, skipping[INFO] datax/lib\\hamcrest-core-1.3.jar already added, skipping[INFO] datax/lib\\logback-classic-1.0.13.jar already added, skipping[INFO] datax/lib\\logback-core-1.0.13.jar already added, skipping[INFO] datax/lib\\slf4j-api-1.7.10.jar already added, skipping[INFO] datax/lib\\commons-io-2.4.jar already added, skipping[INFO] datax/lib\\commons-lang3-3.3.2.jar already added, skipping[INFO] datax/lib\\commons-math3-3.1.1.jar already added, skipping[INFO] datax/lib\\datax-common-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\datax-transformer-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\fastjson-1.1.46.sec01.jar already added, skipping[INFO] datax/lib\\hamcrest-core-1.3.jar already added, skipping[INFO] datax/lib\\logback-classic-1.0.13.jar already added, skipping[INFO] datax/lib\\logback-core-1.0.13.jar already added, skipping[INFO] datax/lib\\slf4j-api-1.7.10.jar already added, skipping[INFO] Copying files to F:\\WorkAbout\\work\\DataX\\target\\datax[INFO] datax/lib\\commons-io-2.4.jar already added, skipping[INFO] datax/lib\\commons-lang3-3.3.2.jar already added, skipping[INFO] datax/lib\\commons-math3-3.1.1.jar already added, skipping[INFO] datax/lib\\datax-common-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\datax-transformer-0.0.1-SNAPSHOT.jar already added, skipping[INFO] datax/lib\\fastjson-1.1.46.sec01.jar already added, skipping[INFO] datax/lib\\hamcrest-core-1.3.jar already added, skipping[INFO] datax/lib\\logback-classic-1.0.13.jar already added, skipping[INFO] datax/lib\\logback-core-1.0.13.jar already added, skipping[INFO] datax/lib\\slf4j-api-1.7.10.jar already added, skipping[WARNING] Assembly file: F:\\WorkAbout\\work\\DataX\\target\\datax is not a regular file (it may be a directory). It cannot be attached to the project build for installation or deployment.[INFO] ------------------------------------------------------------------------[INFO] Reactor Summary:[INFO][INFO] datax-all 0.0.1-SNAPSHOT ........................... SUCCESS [14:23 min][INFO] datax-common ....................................... SUCCESS [ 3.743 s][INFO] datax-transformer .................................. SUCCESS [ 4.746 s][INFO] datax-core ......................................... SUCCESS [ 35.608 s][INFO] plugin-rdbms-util .................................. SUCCESS [ 2.233 s][INFO] mysqlreader ........................................ SUCCESS [ 3.712 s][INFO] drdsreader ......................................... SUCCESS [ 2.849 s][INFO] sqlserverreader .................................... SUCCESS [ 2.668 s][INFO] postgresqlreader ................................... SUCCESS [ 3.018 s][INFO] oraclereader ....................................... SUCCESS [ 2.720 s][INFO] odpsreader ......................................... SUCCESS [ 4.960 s][INFO] otsreader .......................................... SUCCESS [ 5.210 s][INFO] otsstreamreader .................................... SUCCESS [ 4.729 s][INFO] plugin-unstructured-storage-util ................... SUCCESS [ 1.542 s][INFO] txtfilereader ...................................... SUCCESS [ 11.342 s][INFO] hdfsreader ......................................... SUCCESS [ 36.736 s][INFO] streamreader ....................................... SUCCESS [ 2.925 s][INFO] ossreader .......................................... SUCCESS [ 12.321 s][INFO] ftpreader .......................................... SUCCESS [ 12.288 s][INFO] mongodbreader ...................................... SUCCESS [ 11.568 s][INFO] rdbmsreader ........................................ SUCCESS [ 3.784 s][INFO] hbase11xreader ..................................... SUCCESS [ 15.342 s][INFO] hbase094xreader .................................... SUCCESS [ 13.149 s][INFO] tsdbreader ......................................... SUCCESS [ 3.722 s][INFO] opentsdbreader ..................................... SUCCESS [ 6.592 s][INFO] cassandrareader .................................... SUCCESS [ 11.834 s][INFO] mysqlwriter ........................................ SUCCESS [ 3.282 s][INFO] drdswriter ......................................... SUCCESS [ 9.150 s][INFO] odpswriter ......................................... SUCCESS [ 13.498 s][INFO] txtfilewriter ...................................... SUCCESS [ 21.791 s][INFO] ftpwriter .......................................... SUCCESS [ 19.378 s][INFO] hdfswriter ......................................... SUCCESS [ 32.956 s][INFO] streamwriter ....................................... SUCCESS [ 5.611 s][INFO] otswriter .......................................... SUCCESS [ 5.545 s][INFO] oraclewriter ....................................... SUCCESS [ 4.152 s][INFO] sqlserverwriter .................................... SUCCESS [ 2.689 s][INFO] postgresqlwriter ................................... SUCCESS [ 2.502 s][INFO] osswriter .......................................... SUCCESS [ 12.467 s][INFO] mongodbwriter ...................................... SUCCESS [ 12.070 s][INFO] adswriter .......................................... SUCCESS [ 9.578 s][INFO] ocswriter .......................................... SUCCESS [ 5.485 s][INFO] rdbmswriter ........................................ SUCCESS [ 2.927 s][INFO] hbase11xwriter ..................................... SUCCESS [ 15.926 s][INFO] hbase094xwriter .................................... SUCCESS [ 15.623 s][INFO] hbase11xsqlwriter .................................. SUCCESS [ 27.912 s][INFO] hbase11xsqlreader .................................. SUCCESS [ 35.410 s][INFO] elasticsearchwriter ................................ SUCCESS [ 7.341 s][INFO] tsdbwriter ......................................... SUCCESS [ 3.051 s][INFO] adbpgwriter ........................................ SUCCESS [ 5.857 s][INFO] gdbwriter .......................................... SUCCESS [ 11.935 s][INFO] cassandrawriter .................................... SUCCESS [ 6.054 s][INFO] hbase20xsqlreader .................................. SUCCESS [ 3.264 s][INFO] hbase20xsqlwriter 0.0.1-SNAPSHOT ................... SUCCESS [ 3.577 s][INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 23:03 min[INFO] Finished at: 2019-12-18T11:59:17+08:00[INFO] ------------------------------------------------------------------------ 打包成功后，会在对应目录下生成target文件夹.我这儿打包好的文件有1.12G，因为里面包含了很多插件以及插件所需要的依赖包。我只留下了mysql和rdbms两个插件。 因为我是按照的Python3.6.5如果直接使用官网的命令的话，会报错: 12345F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin&gt;python datax.py -r mysqlreader -w mysqlwriter File &quot;datax.py&quot;, line 114 print readerRef ^SyntaxError: Missing parentheses in call to &apos;print&apos;. Did you mean print(readerRef)? 所以，咱们得转换一下啦，Python3.x已经为我们提供了2to3的工具,在安装目录下面的Tools\\scripts中,来体验一下它的强大: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687D:\\Programs\\Python\\Python36-32\\Tools\\scripts&gt;2to3.py --output-dir=D:/datax -W -n F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.pyWARNING: --write-unchanged-files/-W implies -w.lib2to3.main: Output in &apos;D:/datax&apos; will mirror the input directory &apos;F:\\\\WorkAbout\\\\work\\\\DataX\\\\target\\\\datax\\\\datax\\\\bin&apos; layout.RefactoringTool: Skipping optional fixer: bufferRefactoringTool: Skipping optional fixer: idiomsRefactoringTool: Skipping optional fixer: set_literalRefactoringTool: Skipping optional fixer: ws_commaRefactoringTool: Refactored F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.py--- F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.py (original)+++ F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.py (refactored)@@ -52,13 +52,13 @@ def suicide(signum, e): global child_process- print &gt;&gt; sys.stderr, &quot;[Error] DataX receive unexpected signal %d, starts to suicide.&quot; % (signum)+ print(&quot;[Error] DataX receive unexpected signal %d, starts to suicide.&quot; % (signum), file=sys.stderr) if child_process: child_process.send_signal(signal.SIGQUIT) time.sleep(1) child_process.kill()- print &gt;&gt; sys.stderr, &quot;DataX Process was killed ! you did ?&quot;+ print(&quot;DataX Process was killed ! you did ?&quot;, file=sys.stderr) sys.exit(RET_STATE[&quot;KILL&quot;])@@ -111,10 +111,10 @@ def generateJobConfigTemplate(reader, writer): readerRef = &quot;Please refer to the %s document:\\n https://github.com/alibaba/DataX/blob/master/%s/doc/%s.md \\n&quot; % (reader,reader,reader) writerRef = &quot;Please refer to the %s document:\\n https://github.com/alibaba/DataX/blob/master/%s/doc/%s.md \\n &quot; % (writer,writer,writer)- print readerRef- print writerRef+ print(readerRef)+ print(writerRef) jobGuid = &apos;Please save the following configuration as a json file and use\\n python {DATAX_HOME}/bin/datax.py {JSON_FILE_NAME}.json \\nto run the job.\\n&apos;- print jobGuid+ print(jobGuid) jobTemplate={ &quot;job&quot;: { &quot;setting&quot;: {@@ -134,15 +134,15 @@ writerTemplatePath = &quot;%s/plugin/writer/%s/plugin_job_template.json&quot; % (DATAX_HOME,writer) try: readerPar = readPluginTemplate(readerTemplatePath);- except Exception, e:- print &quot;Read reader[%s] template error: can\\&apos;t find file %s&quot; % (reader,readerTemplatePath)+ except Exception as e:+ print(&quot;Read reader[%s] template error: can\\&apos;t find file %s&quot; % (reader,readerTemplatePath)) try: writerPar = readPluginTemplate(writerTemplatePath);- except Exception, e:- print &quot;Read writer[%s] template error: : can\\&apos;t find file %s&quot; % (writer,writerTemplatePath)+ except Exception as e:+ print(&quot;Read writer[%s] template error: : can\\&apos;t find file %s&quot; % (writer,writerTemplatePath)) jobTemplate[&apos;job&apos;][&apos;content&apos;][0][&apos;reader&apos;] = readerPar; jobTemplate[&apos;job&apos;][&apos;content&apos;][0][&apos;writer&apos;] = writerPar;- print json.dumps(jobTemplate, indent=4, sort_keys=True)+ print(json.dumps(jobTemplate, indent=4, sort_keys=True)) def readPluginTemplate(plugin): with open(plugin, &apos;r&apos;) as f:@@ -168,7 +168,7 @@ if options.remoteDebug: tempJVMCommand = tempJVMCommand + &quot; &quot; + REMOTE_DEBUG_CONFIG- print &apos;local ip: &apos;, getLocalIp()+ print(&apos;local ip: &apos;, getLocalIp()) if options.loglevel: tempJVMCommand = tempJVMCommand + &quot; &quot; + (&quot;-Dloglevel=%s&quot; % (options.loglevel))@@ -198,11 +198,11 @@ def printCopyright():- print &apos;&apos;&apos;+ print(&apos;&apos;&apos; DataX (%s), From Alibaba ! Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.-&apos;&apos;&apos; % DATAX_VERSION+&apos;&apos;&apos; % DATAX_VERSION) sys.stdout.flush()RefactoringTool: Writing converted F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.py to D:/datax\\datax.py.RefactoringTool: Files that were modified:RefactoringTool: F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin\\datax.py 我将转到好的py文件更名为datax3.py,复制到bin目录下面,重新执行命令: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\bin&gt;python datax3.py -r mysqlreader -w mysqlwriterDataX (DATAX-OPENSOURCE-3.0), From Alibaba !Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.Please refer to the mysqlreader document: https://github.com/alibaba/DataX/blob/master/mysqlreader/doc/mysqlreader.mdPlease refer to the mysqlwriter document: https://github.com/alibaba/DataX/blob/master/mysqlwriter/doc/mysqlwriter.mdPlease save the following configuration as a json file and use python {DATAX_HOME}/bin/datax.py {JSON_FILE_NAME}.jsonto run the job.{ &quot;job&quot;: { &quot;content&quot;: [ { &quot;reader&quot;: { &quot;name&quot;: &quot;mysqlreader&quot;, &quot;parameter&quot;: { &quot;column&quot;: [], &quot;connection&quot;: [ { &quot;jdbcUrl&quot;: [], &quot;table&quot;: [] } ], &quot;password&quot;: &quot;&quot;, &quot;username&quot;: &quot;&quot;, &quot;where&quot;: &quot;&quot; } }, &quot;writer&quot;: { &quot;name&quot;: &quot;mysqlwriter&quot;, &quot;parameter&quot;: { &quot;column&quot;: [], &quot;connection&quot;: [ { &quot;jdbcUrl&quot;: &quot;&quot;, &quot;table&quot;: [] } ], &quot;password&quot;: &quot;&quot;, &quot;preSql&quot;: [], &quot;session&quot;: [], &quot;username&quot;: &quot;&quot;, &quot;writeMode&quot;: &quot;&quot; } } } ], &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: &quot;&quot; } } }} 我们可以把命令执行结果保存在文件中: 1python datax3.py -r mysqlreader -w mysqlwriter &gt; mysql2gbase.json 会在当前目录生成mysql2gbase.json文件。做相应的配置即可: 123456789101112131415161718192021222324252627282930313233343536373839{ &quot;job&quot;: { &quot;content&quot;: [{ &quot;reader&quot;: { &quot;name&quot;: &quot;mysqlreader&quot;, &quot;parameter&quot;: { &quot;column&quot;: [&quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot;], &quot;connection&quot;: [{ &quot;jdbcUrl&quot;: [&quot;jdbc:mysql://10.101.42.91:1299/zhcj_test&quot;], &quot;table&quot;: [&quot;op_log&quot;] }], &quot;password&quot;: &quot;bingosoft!&quot;, &quot;username&quot;: &quot;root&quot;, &quot;where&quot;: &quot;&quot; } }, &quot;writer&quot;: { &quot;name&quot;: &quot;mysqlwriter&quot;, &quot;parameter&quot;: { &quot;column&quot;: [&quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot;], &quot;connection&quot;: [{ &quot;jdbcUrl&quot;: &quot;jdbc:mysql://10.101.42.91:1299/zhcs_test&quot;, &quot;table&quot;: [&quot;datax_op_log&quot;] }], &quot;password&quot;: &quot;bingosoft!&quot;, &quot;preSql&quot;: [], &quot;session&quot;: [], &quot;username&quot;: &quot;root&quot;, &quot;writeMode&quot;: &quot;insert&quot; } } }], &quot;setting&quot;: { &quot;speed&quot;: { &quot;channel&quot;: &quot;4&quot; } } }} 执行同步命令python datax3.py mysql2gbase.json 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148DataX (DATAX-OPENSOURCE-3.0), From Alibaba !Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.2019-12-18 18:38:21.572 [main] INFO VMInfo - VMInfo# operatingSystem class =&gt; sun.management.OperatingSystemImpl2019-12-18 18:38:21.578 [main] INFO Engine - the machine info =&gt; osInfo: Oracle Corporation 1.8 25.231-b11 jvmInfo: Windows 10 amd64 10.0 cpu num: 8 totalPhysicalMemory: -0.00G freePhysicalMemory: -0.00G maxFileDescriptorCount: -1 currentOpenFileDescriptorCount: -1 GC Names [PS MarkSweep, PS Scavenge] MEMORY_NAME | allocation_size | init_size PS Eden Space | 256.00MB | 256.00MB Code Cache | 240.00MB | 2.44MB Compressed Class Space | 1,024.00MB | 0.00MB PS Survivor Space | 42.50MB | 42.50MB PS Old Gen | 683.00MB | 683.00MB Metaspace | -0.00MB | 0.00MB 2019-12-18 18:38:21.594 [main] INFO Engine - { &quot;content&quot;:[ { &quot;reader&quot;:{ &quot;name&quot;:&quot;mysqlreader&quot;, &quot;parameter&quot;:{ &quot;column&quot;:[ &quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot; ], &quot;connection&quot;:[ { &quot;jdbcUrl&quot;:[ &quot;jdbc:mysql://10.101.42.91:1299/zhcj_test&quot; ], &quot;table&quot;:[ &quot;op_log&quot; ] } ], &quot;password&quot;:&quot;**********&quot;, &quot;username&quot;:&quot;root&quot;, &quot;where&quot;:&quot;&quot; } }, &quot;writer&quot;:{ &quot;name&quot;:&quot;mysqlwriter&quot;, &quot;parameter&quot;:{ &quot;column&quot;:[ &quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot; ], &quot;connection&quot;:[ { &quot;jdbcUrl&quot;:&quot;jdbc:mysql://10.101.42.91:1299/zhcs_test&quot;, &quot;table&quot;:[ &quot;datax_op_log&quot; ] } ], &quot;password&quot;:&quot;**********&quot;, &quot;preSql&quot;:[], &quot;session&quot;:[], &quot;username&quot;:&quot;root&quot;, &quot;writeMode&quot;:&quot;insert&quot; } } } ], &quot;setting&quot;:{ &quot;speed&quot;:{ &quot;channel&quot;:&quot;4&quot; } }}2019-12-18 18:38:21.606 [main] WARN Engine - prioriy set to 0, because NumberFormatException, the value is: null2019-12-18 18:38:21.608 [main] INFO PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=02019-12-18 18:38:21.608 [main] INFO JobContainer - DataX jobContainer starts job.2019-12-18 18:38:21.609 [main] INFO JobContainer - Set jobId = 02019-12-18 18:38:21.906 [job-0] INFO OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true.2019-12-18 18:38:21.962 [job-0] INFO OriginalConfPretreatmentUtil - table:[op_log] has columns:[SCENE_ID,OP_TIME,OP_JOB_NO,REMARK].2019-12-18 18:38:22.184 [job-0] INFO OriginalConfPretreatmentUtil - table:[datax_op_log] all columns:[SCENE_ID,OP_TIME,OP_JOB_NO,REMARK].2019-12-18 18:38:22.242 [job-0] INFO OriginalConfPretreatmentUtil - Write data [insert INTO %s (SCENE_ID,OP_TIME,OP_JOB_NO,REMARK) VALUES(?,?,?,?)], which jdbcUrl like:[jdbc:mysql://10.101.42.91:1299/zhcs_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true]2019-12-18 18:38:22.243 [job-0] INFO JobContainer - jobContainer starts to do prepare ...2019-12-18 18:38:22.243 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do prepare work .2019-12-18 18:38:22.243 [job-0] INFO JobContainer - DataX Writer.Job [mysqlwriter] do prepare work .2019-12-18 18:38:22.244 [job-0] INFO JobContainer - jobContainer starts to do split ...2019-12-18 18:38:22.244 [job-0] INFO JobContainer - Job set Channel-Number to 4 channels.2019-12-18 18:38:22.247 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.2019-12-18 18:38:22.248 [job-0] INFO JobContainer - DataX Writer.Job [mysqlwriter] splits to [1] tasks.2019-12-18 18:38:22.260 [job-0] INFO JobContainer - jobContainer starts to do schedule ...2019-12-18 18:38:22.262 [job-0] INFO JobContainer - Scheduler starts [1] taskGroups.2019-12-18 18:38:22.264 [job-0] INFO JobContainer - Running by standalone Mode.2019-12-18 18:38:22.272 [taskGroup-0] INFO TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.2019-12-18 18:38:22.275 [taskGroup-0] INFO Channel - Channel set byte_speed_limit to -1, No bps activated.2019-12-18 18:38:22.275 [taskGroup-0] INFO Channel - Channel set record_speed_limit to -1, No tps activated.2019-12-18 18:38:22.282 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started2019-12-18 18:38:22.284 [0-0-0-reader] INFO CommonRdbmsReader$Task - Begin to read record by Sql: [select SCENE_ID,OP_TIME,OP_JOB_NO,REMARK from op_log ] jdbcUrl:[jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2019-12-18 18:38:23.295 [0-0-0-reader] INFO CommonRdbmsReader$Task - Finished read record by Sql: [select SCENE_ID,OP_TIME,OP_JOB_NO,REMARK from op_log ] jdbcUrl:[jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2019-12-18 18:38:23.592 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[1311]ms2019-12-18 18:38:23.592 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] completed it&apos;s tasks.2019-12-18 18:38:32.281 [job-0] INFO StandAloneJobContainerCommunicator - Total 15167 records, 849566 bytes | Speed 82.96KB/s, 1516 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.832s | All Task WaitReaderTime 0.058s | Percentage 100.00%2019-12-18 18:38:32.281 [job-0] INFO AbstractScheduler - Scheduler accomplished all tasks.2019-12-18 18:38:32.281 [job-0] INFO JobContainer - DataX Writer.Job [mysqlwriter] do post work.2019-12-18 18:38:32.281 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do post work.2019-12-18 18:38:32.281 [job-0] INFO JobContainer - DataX jobId [0] completed successfully.2019-12-18 18:38:32.282 [job-0] INFO HookInvoker - No hook invoked, because base dir not exists or is a file: F:\\WorkAbout\\work\\DataX\\target\\datax\\datax\\hook2019-12-18 18:38:32.283 [job-0] INFO JobContainer - [total cpu info] =&gt; averageCpu | maxDeltaCpu | minDeltaCpu -1.00% | -1.00% | -1.00% [total gc info] =&gt; NAME | totalGCCount | maxDeltaGCCount | minDeltaGCCount | totalGCTime | maxDeltaGCTime | minDeltaGCTime PS MarkSweep | 0 | 0 | 0 | 0.000s | 0.000s | 0.000s PS Scavenge | 0 | 0 | 0 | 0.000s | 0.000s | 0.000s 2019-12-18 18:38:32.283 [job-0] INFO JobContainer - PerfTrace not enable!2019-12-18 18:38:32.284 [job-0] INFO StandAloneJobContainerCommunicator - Total 15167 records, 849566 bytes | Speed 82.96KB/s, 1516 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.832s | All Task WaitReaderTime 0.058s | Percentage 100.00%2019-12-18 18:38:32.285 [job-0] INFO JobContainer - 任务启动时刻 : 2019-12-18 18:38:21任务结束时刻 : 2019-12-18 18:38:32任务总计耗时 : 10s任务平均流量 : 82.96KB/s记录写入速度 : 1516rec/s读出记录总数 : 15167读写失败总数 : 0 上面只是一个简单的示例，接下来。我们将进入正式实践环节。首先需要开发一个GbaseWriter,因为没有涉及到太多细节的处理，直接按照DataX插件开发宝典开发一个,打包插件mvn -U clean package assembly:assembly -pl gbasewriter -am -Dmaven.test.skip=true,然后执行:python datax.py -r mysqlreader -w gbasewriter,按照实际情况配置即可，运行效果如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157DataX (DATAX-OPENSOURCE-3.0), From Alibaba !Copyright (C) 2010-2017, Alibaba Group. All Rights Reserved.2019-12-20 15:07:22.954 [main] INFO VMInfo - VMInfo# operatingSystem class =&gt; sun.management.OperatingSystemImpl2019-12-20 15:07:22.960 [main] INFO Engine - the machine info =&gt; osInfo: Oracle Corporation 1.8 25.231-b11 jvmInfo: Windows 10 amd64 10.0 cpu num: 8 totalPhysicalMemory: -0.00G freePhysicalMemory: -0.00G maxFileDescriptorCount: -1 currentOpenFileDescriptorCount: -1 GC Names [PS MarkSweep, PS Scavenge] MEMORY_NAME | allocation_size | init_size PS Eden Space | 256.00MB | 256.00MB Code Cache | 240.00MB | 2.44MB Compressed Class Space | 1,024.00MB | 0.00MB PS Survivor Space | 42.50MB | 42.50MB PS Old Gen | 683.00MB | 683.00MB Metaspace | -0.00MB | 0.00MB 2019-12-20 15:07:22.996 [main] INFO Engine - { &quot;content&quot;:[ { &quot;reader&quot;:{ &quot;name&quot;:&quot;mysqlreader&quot;, &quot;parameter&quot;:{ &quot;column&quot;:[ &quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot; ], &quot;connection&quot;:[ { &quot;jdbcUrl&quot;:[ &quot;jdbc:mysql://10.101.42.91:1299/zhcj_test&quot; ], &quot;table&quot;:[ &quot;op_log&quot; ] } ], &quot;password&quot;:&quot;**********&quot;, &quot;username&quot;:&quot;root&quot;, &quot;where&quot;:&quot;&quot; } }, &quot;writer&quot;:{ &quot;name&quot;:&quot;gbasewriter&quot;, &quot;parameter&quot;:{ &quot;column&quot;:[ &quot;SCENE_ID&quot;, &quot;OP_TIME&quot;, &quot;OP_JOB_NO&quot;, &quot;REMARK&quot; ], &quot;connection&quot;:[ { &quot;jdbcUrl&quot;:&quot;jdbc:gbase://10.101.42.91:1238/gdb_cd&quot;, &quot;table&quot;:[ &quot;datax_op_log&quot; ] } ], &quot;password&quot;:&quot;********&quot;, &quot;preSql&quot;:[], &quot;session&quot;:[], &quot;username&quot;:&quot;cd_system&quot;, &quot;writeMode&quot;:&quot;insert&quot; } } } ], &quot;setting&quot;:{ &quot;speed&quot;:{ &quot;channel&quot;:&quot;2&quot; } }}2019-12-20 15:07:23.009 [main] WARN Engine - prioriy set to 0, because NumberFormatException, the value is: null2019-12-20 15:07:23.011 [main] INFO PerfTrace - PerfTrace traceId=job_-1, isEnable=false, priority=02019-12-20 15:07:23.011 [main] INFO JobContainer - DataX jobContainer starts job.2019-12-20 15:07:23.013 [main] INFO JobContainer - Set jobId = 02019-12-20 15:07:23.344 [job-0] INFO OriginalConfPretreatmentUtil - Available jdbcUrl:jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true.2019-12-20 15:07:23.404 [job-0] INFO OriginalConfPretreatmentUtil - table:[op_log] has columns:[SCENE_ID,OP_TIME,OP_JOB_NO,REMARK].2019-12-20 15:07:23.761 [job-0] INFO OriginalConfPretreatmentUtil - table:[datax_op_log] all columns:[SCENE_ID,OP_TIME,OP_JOB_NO,REMARK].2019-12-20 15:07:23.962 [job-0] INFO OriginalConfPretreatmentUtil - Write data [insert INTO %s (SCENE_ID,OP_TIME,OP_JOB_NO,REMARK) VALUES(?,?,?,?)], which jdbcUrl like:[jdbc:gbase://10.101.42.91:1238/gdb_cd]2019-12-20 15:07:23.962 [job-0] INFO JobContainer - jobContainer starts to do prepare ...2019-12-20 15:07:23.962 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do prepare work .2019-12-20 15:07:23.963 [job-0] INFO JobContainer - DataX Writer.Job [gbasewriter] do prepare work .2019-12-20 15:07:23.963 [job-0] INFO JobContainer - jobContainer starts to do split ...2019-12-20 15:07:23.963 [job-0] INFO JobContainer - Job set Channel-Number to 2 channels.2019-12-20 15:07:24.060 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] splits to [1] tasks.2019-12-20 15:07:24.060 [job-0] INFO JobContainer - DataX Writer.Job [gbasewriter] splits to [1] tasks.2019-12-20 15:07:24.173 [job-0] INFO JobContainer - jobContainer starts to do schedule ...2019-12-20 15:07:24.199 [job-0] INFO JobContainer - Scheduler starts [1] taskGroups.2019-12-20 15:07:24.201 [job-0] INFO JobContainer - Running by standalone Mode.2019-12-20 15:07:24.245 [taskGroup-0] INFO TaskGroupContainer - taskGroupId=[0] start [1] channels for [1] tasks.2019-12-20 15:07:24.313 [taskGroup-0] INFO Channel - Channel set byte_speed_limit to -1, No bps activated.2019-12-20 15:07:24.313 [taskGroup-0] INFO Channel - Channel set record_speed_limit to -1, No tps activated.2019-12-20 15:07:24.434 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] attemptCount[1] is started2019-12-20 15:07:24.441 [0-0-0-reader] INFO CommonRdbmsReader$Task - Begin to read record by Sql: [select SCENE_ID,OP_TIME,OP_JOB_NO,REMARK from op_log ] jdbcUrl:[jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2019-12-20 15:07:34.475 [job-0] INFO StandAloneJobContainerCommunicator - Total 0 records, 0 bytes | Speed 0B/s, 0 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.000s | All Task WaitReaderTime 0.000s | Percentage 0.00%2019-12-20 15:07:44.502 [job-0] INFO StandAloneJobContainerCommunicator - Total 2560 records, 149496 bytes | Speed 14.60KB/s, 256 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.142s | All Task WaitReaderTime 0.035s | Percentage 0.00%2019-12-20 15:07:54.502 [job-0] INFO StandAloneJobContainerCommunicator - Total 2560 records, 149496 bytes | Speed 0B/s, 0 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 0.142s | All Task WaitReaderTime 0.035s | Percentage 0.00%2019-12-20 15:08:04.503 [job-0] INFO StandAloneJobContainerCommunicator - Total 4608 records, 269164 bytes | Speed 11.69KB/s, 204 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 24.193s | All Task WaitReaderTime 0.044s | Percentage 0.00%2019-12-20 15:08:14.504 [job-0] INFO StandAloneJobContainerCommunicator - Total 4608 records, 269164 bytes | Speed 0B/s, 0 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 24.193s | All Task WaitReaderTime 0.044s | Percentage 0.00%2019-12-20 15:08:24.505 [job-0] INFO StandAloneJobContainerCommunicator - Total 6656 records, 390129 bytes | Speed 11.81KB/s, 204 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 43.026s | All Task WaitReaderTime 0.050s | Percentage 0.00%2019-12-20 15:08:44.505 [job-0] INFO StandAloneJobContainerCommunicator - Total 8704 records, 510488 bytes | Speed 5.88KB/s, 102 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 60.643s | All Task WaitReaderTime 0.053s | Percentage 0.00%2019-12-20 15:08:54.506 [job-0] INFO StandAloneJobContainerCommunicator - Total 10752 records, 612379 bytes | Speed 9.95KB/s, 204 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 78.139s | All Task WaitReaderTime 0.055s | Percentage 0.00%2019-12-20 15:09:14.506 [job-0] INFO StandAloneJobContainerCommunicator - Total 12800 records, 731913 bytes | Speed 5.84KB/s, 102 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 94.918s | All Task WaitReaderTime 0.058s | Percentage 0.00%2019-12-20 15:09:24.507 [job-0] INFO StandAloneJobContainerCommunicator - Total 12800 records, 731913 bytes | Speed 0B/s, 0 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 94.918s | All Task WaitReaderTime 0.058s | Percentage 0.00%2019-12-20 15:09:34.467 [0-0-0-reader] INFO CommonRdbmsReader$Task - Finished read record by Sql: [select SCENE_ID,OP_TIME,OP_JOB_NO,REMARK from op_log ] jdbcUrl:[jdbc:mysql://10.101.42.91:1299/zhcj_test?yearIsDateType=false&amp;zeroDateTimeBehavior=convertToNull&amp;tinyInt1isBit=false&amp;rewriteBatchedStatements=true].2019-12-20 15:09:34.508 [job-0] INFO StandAloneJobContainerCommunicator - Total 14848 records, 840903 bytes | Speed 10.64KB/s, 204 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 112.371s | All Task WaitReaderTime 0.060s | Percentage 0.00%2019-12-20 15:09:42.112 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] taskId[0] is successed, used[137708]ms2019-12-20 15:09:42.112 [taskGroup-0] INFO TaskGroupContainer - taskGroup[0] completed it&apos;s tasks.2019-12-20 15:09:44.508 [job-0] INFO AbstractScheduler - Scheduler accomplished all tasks.2019-12-20 15:09:44.508 [job-0] INFO JobContainer - DataX Writer.Job [gbasewriter] do post work.2019-12-20 15:09:44.509 [job-0] INFO JobContainer - DataX Reader.Job [mysqlreader] do post work.2019-12-20 15:09:44.509 [job-0] INFO JobContainer - DataX jobId [0] completed successfully.2019-12-20 15:09:44.510 [job-0] INFO HookInvoker - No hook invoked, because base dir not exists or is a file: F:\\WorkAbout\\datax\\datax\\hook2019-12-20 15:09:44.511 [job-0] INFO JobContainer - [total cpu info] =&gt; averageCpu | maxDeltaCpu | minDeltaCpu -1.00% | -1.00% | -1.00% [total gc info] =&gt; NAME | totalGCCount | maxDeltaGCCount | minDeltaGCCount | totalGCTime | maxDeltaGCTime | minDeltaGCTime PS MarkSweep | 0 | 0 | 0 | 0.000s | 0.000s | 0.000s PS Scavenge | 0 | 0 | 0 | 0.000s | 0.000s | 0.000s 2019-12-20 15:09:44.511 [job-0] INFO JobContainer - PerfTrace not enable!2019-12-20 15:09:44.511 [job-0] INFO StandAloneJobContainerCommunicator - Total 15167 records, 849566 bytes | Speed 5.93KB/s, 108 records/s | Error 0 records, 0 bytes | All Task WaitWriterTime 129.781s | All Task WaitReaderTime 0.061s | Percentage 100.00%2019-12-20 15:09:44.512 [job-0] INFO JobContainer - 任务启动时刻 : 2019-12-20 15:07:23任务结束时刻 : 2019-12-20 15:09:44任务总计耗时 : 141s任务平均流量 : 5.93KB/s记录写入速度 : 108rec/s读出记录总数 : 15167读写失败总数 : 0 没办法，机器太low。这并不是Datax真实的效果。现在就可以把Datax放在服务器上去同步数据了。","link":"/20191218/DataX%E5%B0%86DB2%E4%B8%8A%E4%BA%BF%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%88%B0GBase%E4%B8%AD.html"},{"title":"借助alibaba Driud SQL Parser组件处理sql语句","text":"Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。 先来看看我们要达到的效果:这个项目的目的是让业务用户通过手动拖拽自己想要的字段即可展示、分析、下载数据，之前的流程是先添加数据源-&gt;在系统中导入表-&gt;配置分析模型-选择分析模型展示数据。这里的分析模型其实就是通过拖拽表类配置表与表之间是关联关系。然后拖拽字段后，前端就发送选择的字段表达式和过滤条件表达式到后端，通过配置是分析模型关系，解析出相应数据库的SQL语句发送到数据库执行。现在有一种场景，就是用户能只需要查询单张表，如果这样也需要去配置分析模型，那么就增加了复杂度。所以，需要给用户提供一种直接通过数据源直接选择未建立关联关系的原表来查询、分析、下载数据。由于项目是没有源代码，而且之前的解析那一块都是基于分析模型，内部逻辑比较复杂。所以我选择了一种相对来说要方便一点的方式就是通过Driud来解析生成SQL语句。我们都知道Druid是一个JDBC组件库，包括数据库连接池、SQL Parser等组件,我们一般都是拿来做JDBC连接池和SQL语句监控使用。这里，我只是把这次SQL Parser组件的使用过程记录一下。感兴趣的朋友可以去看看Druid 使用手册 Druid_SQL_AST学习什么是ASTAST是abstract syntax tree的缩写，也就是抽象语法树。和所有的Parser一样，Druid Parser会生成一个抽象语法树。 在Druid SQL Parser中有哪些AST节点类型在Druid中，AST节点类型主要包括SQLObject、SQLExpr、SQLStatement三种抽象类型。 123456789package com.alibaba.druid.sql.ast; interface SQLObject {}interface SQLExpr extends SQLObject {}interface SQLStatement extends SQLObject {} interface SQLTableSource extends SQLObject {}class SQLSelect extends SQLObject {}class SQLSelectQueryBlock extends SQLObject {} 常用的SQLExpr有哪些123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.alibaba.druid.sql.ast.expr; // SQLName是一种的SQLExpr的Expr，包括SQLIdentifierExpr、SQLPropertyExpr等public interface SQLName extends SQLExpr {} // 例如 ID = 3 这里的ID是一个SQLIdentifierExprclass SQLIdentifierExpr implements SQLExpr, SQLName { String name;} // 例如 A.ID = 3 这里的A.ID是一个SQLPropertyExprclass SQLPropertyExpr implements SQLExpr, SQLName { SQLExpr owner; String name;} // 例如 ID = 3 这是一个SQLBinaryOpExpr// left是ID (SQLIdentifierExpr)// right是3 (SQLIntegerExpr)class SQLBinaryOpExpr implements SQLExpr { SQLExpr left; SQLExpr right; SQLBinaryOperator operator;} // 例如 select * from where id = ?，这里的?是一个SQLVariantRefExpr，name是&apos;?&apos;class SQLVariantRefExpr extends SQLExprImpl { String name;} // 例如 ID = 3 这里的3是一个SQLIntegerExprpublic class SQLIntegerExpr extends SQLNumericLiteralExpr implements SQLValuableExpr { Number number; // 所有实现了SQLValuableExpr接口的SQLExpr都可以直接调用这个方法求值 @Override public Object getValue() { return this.number; }} // 例如 NAME = &apos;jobs&apos; 这里的&apos;jobs&apos;是一个SQLCharExprpublic class SQLCharExpr extends SQLTextLiteralExpr implements SQLValuableExpr{ String text;} 常用的SQLStatemment最常用的Statement当然是SELECT/UPDATE/DELETE/INSERT，他们分别是 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.alibaba.druid.sql.ast.statement; class SQLSelectStatement implements SQLStatement { SQLSelect select;}class SQLUpdateStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLUpdateSetItem&gt; items; SQLExpr where;}class SQLDeleteStatement implements SQLStatement { SQLTableSource tableSource; SQLExpr where;}class SQLInsertStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLExpr&gt; columns; SQLSelect query;}2.3. SQLTableSource常见的SQLTableSource包括SQLExprTableSource、SQLJoinTableSource、SQLSubqueryTableSource、SQLWithSubqueryClause.Entryclass SQLTableSourceImpl extends SQLObjectImpl implements SQLTableSource { String alias;} // 例如 select * from emp where i = 3，这里的from emp是一个SQLExprTableSource// 其中expr是一个name=emp的SQLIdentifierExprclass SQLExprTableSource extends SQLTableSourceImpl { SQLExpr expr;} // 例如 select * from emp e inner join org o on e.org_id = o.id// 其中left &apos;emp e&apos; 是一个SQLExprTableSource，right &apos;org o&apos;也是一个SQLExprTableSource// condition &apos;e.org_id = o.id&apos;是一个SQLBinaryOpExprclass SQLJoinTableSource extends SQLTableSourceImpl { SQLTableSource left; SQLTableSource right; JoinType joinType; // INNER_JOIN/CROSS_JOIN/LEFT_OUTER_JOIN/RIGHT_OUTER_JOIN/... SQLExpr condition;} // 例如 select * from (select * from temp) a，这里第一层from(...)是一个SQLSubqueryTableSourceSQLSubqueryTableSource extends SQLTableSourceImpl { SQLSelect select;} /* 例如WITH RECURSIVE ancestors AS ( SELECT * FROM org UNION SELECT f.* FROM org f, ancestors a WHERE f.id = a.parent_id)SELECT *FROM ancestors; 这里的ancestors AS (...) 是一个SQLWithSubqueryClause.Entry*/class SQLWithSubqueryClause { static class Entry extends SQLTableSourceImpl { SQLSelect subQuery; }}2.4. SQLSelect &amp; SQLSelectQuerySQLSelectStatement包含一个SQLSelect，SQLSelect包含一个SQLSelectQuery，都是组成的关系。SQLSelectQuery有主要的两个派生类，分别是SQLSelectQueryBlock和SQLUnionQuery。class SQLSelect extends SQLObjectImpl { SQLWithSubqueryClause withSubQuery; SQLSelectQuery query;} interface SQLSelectQuery extends SQLObject {} class SQLSelectQueryBlock implements SQLSelectQuery { List&lt;SQLSelectItem&gt; selectList; SQLTableSource from; SQLExprTableSource into; SQLExpr where; SQLSelectGroupByClause groupBy; SQLOrderBy orderBy; SQLLimit limit;} class SQLUnionQuery implements SQLSelectQuery { SQLSelectQuery left; SQLSelectQuery right; SQLUnionOperator operator; // UNION/UNION_ALL/MINUS/INTERSECT} SQLCreateTableStatement建表语句包含了一系列方法，用于方便各种操作 1234567891011121314public class SQLCreateTableStatement extends SQLStatementImpl implements SQLDDLStatement, SQLCreateStatement { SQLExprTableSource tableSource; List&lt;SQLTableElement&gt; tableElementList; Select select; // 忽略大小写的查找SQLCreateTableStatement中的SQLColumnDefinition public SQLColumnDefinition findColumn(String columName) {} // 忽略大小写的查找SQLCreateTableStatement中的column关联的索引 public SQLTableElement findIndex(String columnName) {} // 是否外键依赖另外一个表 public boolean isReferenced(String tableName) {}} 怎样产生AST通过SQLUtils产生List1234import com.alibaba.druid.util.JdbcConstants; String dbType = JdbcConstants.MYSQL;List&lt;SQLStatement&gt; statementList = SQLUtils.parseStatements(sql, dbType); 通过SQLUtils产生SQLExpr12String dbType = JdbcConstants.MYSQL;SQLExpr expr = SQLUtils.toSQLExpr(&quot;id=3&quot;, dbType); 怎样打印AST节点通过SQLUtils工具类打印节点123456789package com.alibaba.druid.sql; public class SQLUtils { // 可以将SQLExpr/SQLStatement打印为String类型 static String toSQLString(SQLObject sqlObj, String dbType); // 可以将一个&amp;lt;SQLStatement&amp;gt;打印为String类型 static String toSQLString(List&lt;SQLStatement&gt; statementList, String dbType);} 在Select语句中添加Group by这个先简单的做一个场景，依然拿本次这个项目来说，在前端发送SUM、COUNT等聚合表达式的SQL时，我们需要在语句后面添加Group by。 123456789101112131415161718192021222324252627282930313233343536373839404142public static String getSql(String sql, int offset, int count) { List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, JdbcConstants.MYSQL); SQLSelectStatement sqlSelectStatement = (SQLSelectStatement) stmtList.get(0); SQLSelectQuery sqlSelectQuery = sqlSelectStatement.getSelect().getQuery(); MySqlSchemaStatVisitor visitor = new MySqlSchemaStatVisitor(); sqlSelectStatement.accept(visitor); if (sqlSelectQuery instanceof SQLSelectQueryBlock) { SQLSelectQueryBlock sqlSelectQueryBlock = (SQLSelectQueryBlock) sqlSelectQuery; List&lt;TableStat.Column&gt; cols = new ArrayList&lt;&gt;(visitor.getColumns()); SQLExpr where = sqlSelectQueryBlock.getWhere(); // 获取字段列表 List&lt;SQLSelectItem&gt; selectItems = sqlSelectQueryBlock.getSelectList(); int idx = 0; boolean hasAggregate = false; SQLSelectGroupByClause sqlSelectGroupByClause = new SQLSelectGroupByClause(); //判断是否有聚合函数 for (int selectIdx = 0; selectIdx &lt;= selectItems.size() - 1; selectIdx++) { if (selectItems.get(selectIdx).getExpr() instanceof SQLAggregateExpr) { hasAggregate = true; break; } } if (hasAggregate) { //添加SQLSelectGroupByClause字段 for (int colIndex = 0; colIndex &lt;= cols.size() - 1; colIndex++) { if (cols.get(colIndex).isSelect()) { sqlSelectGroupByClause.addItem(SQLUtils.toSQLExpr(cols.get(colIndex).toString(), JdbcConstants.MYSQL)); } } } sqlSelectQueryBlock.setGroupBy(sqlSelectGroupByClause); if (count &gt;= 1) { return PagerUtils.limit(sqlSelectStatement.toString(), JdbcConstants.MYSQL, offset, count); } return sqlSelectStatement.toString(); } return &quot;&quot;; } 输入sql语句： 1SELECT SUM(`address`) `address`,SUM(`address1`) `address1` FROM `demo` WHERE 1 = 1 最终结果: 1234SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1 生成分页 12345SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1LIMIT 1, 100 也可以创建一个SQLSelect对象来生成sql语句: 1234567SQLSelect sqlSelect = new SQLSelect();MySqlSelectQueryBlock sqlSelectQueryBlock = new MySqlSelectQueryBlock();sqlSelectQueryBlock.addSelectItem(new SQLSelectItem(new SQLIdentifierExpr(&quot;col1&quot;))); //查询列名sqlSelectQueryBlock.addSelectItem(new SQLSelectItem(new SQLIdentifierExpr(&quot;col2&quot;))); //查询列名sqlSelectQueryBlock.setFrom(new SQLExprTableSource(new SQLIdentifierExpr(&quot;demo&quot;))); //表名sqlSelect.setQuery(sqlSelectQueryBlock);String sql = SQLUtils.toSQLString(sqlSelect); Druid支持多种数据库的sql解析,在JdbcConstants中可以看到 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public interface JdbcConstants { String JTDS = &quot;jtds&quot;; String MOCK = &quot;mock&quot;; String HSQL = &quot;hsql&quot;; String DB2 = &quot;db2&quot;; String DB2_DRIVER = &quot;com.ibm.db2.jcc.DB2Driver&quot;; String POSTGRESQL = &quot;postgresql&quot;; String POSTGRESQL_DRIVER = &quot;org.postgresql.Driver&quot;; String SYBASE = &quot;sybase&quot;; String SQL_SERVER = &quot;sqlserver&quot;; String SQL_SERVER_DRIVER = &quot;com.microsoft.jdbc.sqlserver.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_SQLJDBC4 = &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_JTDS = &quot;net.sourceforge.jtds.jdbc.Driver&quot;; String ORACLE = &quot;oracle&quot;; String ORACLE_DRIVER = &quot;oracle.jdbc.OracleDriver&quot;; String ORACLE_DRIVER2 = &quot;oracle.jdbc.driver.OracleDriver&quot;; String ALI_ORACLE = &quot;AliOracle&quot;; String ALI_ORACLE_DRIVER = &quot;com.alibaba.jdbc.AlibabaDriver&quot;; String MYSQL = &quot;mysql&quot;; String MYSQL_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String MYSQL_DRIVER_6 = &quot;com.mysql.cj.jdbc.Driver&quot;; String MYSQL_DRIVER_REPLICATE = &quot;com.mysql.jdbc.&quot;; String MARIADB = &quot;mariadb&quot;; String MARIADB_DRIVER = &quot;org.mariadb.jdbc.Driver&quot;; String DERBY = &quot;derby&quot;; String HBASE = &quot;hbase&quot;; String HIVE = &quot;hive&quot;; String HIVE_DRIVER = &quot;org.apache.hive.jdbc.HiveDriver&quot;; String H2 = &quot;h2&quot;; String H2_DRIVER = &quot;org.h2.Driver&quot;; String DM = &quot;dm&quot;; String DM_DRIVER = &quot;dm.jdbc.driver.DmDriver&quot;; String KINGBASE = &quot;kingbase&quot;; String KINGBASE_DRIVER = &quot;com.kingbase.Driver&quot;; String GBASE = &quot;gbase&quot;; String GBASE_DRIVER = &quot;com.gbase.jdbc.Driver&quot;; String XUGU = &quot;xugu&quot;; String XUGU_DRIVER = &quot;com.xugu.cloudjdbc.Driver&quot;; String OCEANBASE = &quot;oceanbase&quot;; String OCEANBASE_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String INFORMIX = &quot;informix&quot;; /** * 阿里云odps */ String ODPS = &quot;odps&quot;; String ODPS_DRIVER = &quot;com.aliyun.odps.jdbc.OdpsDriver&quot;; String TERADATA = &quot;teradata&quot;; String TERADATA_DRIVER = &quot;com.teradata.jdbc.TeraDriver&quot;; /** * Log4JDBC */ String LOG4JDBC = &quot;log4jdbc&quot;; String LOG4JDBC_DRIVER = &quot;net.sf.log4jdbc.DriverSpy&quot;; String PHOENIX = &quot;phoenix&quot;; String PHOENIX_DRIVER = &quot;org.apache.phoenix.jdbc.PhoenixDriver&quot;; String ENTERPRISEDB = &quot;edb&quot;; String ENTERPRISEDB_DRIVER = &quot;com.edb.Driver&quot;; String KYLIN = &quot;kylin&quot;; String KYLIN_DRIVER = &quot;org.apache.kylin.jdbc.Driver&quot;; String SQLITE = &quot;sqlite&quot;; String SQLITE_DRIVER = &quot;org.sqlite.JDBC&quot;; String ALIYUN_ADS = &quot;aliyun_ads&quot;; String ALIYUN_DRDS = &quot;aliyun_drds&quot;; String PRESTO = &quot;presto&quot;; String PRESTO_DRIVER = &quot;com.facebook.presto.jdbc.PrestoDriver&quot;; String ELASTIC_SEARCH = &quot;elastic_search&quot;; String ELASTIC_SEARCH_DRIVER = &quot;com.alibaba.xdriver.elastic.jdbc.ElasticDriver&quot;; String CLICKHOUSE = &quot;clickhouse&quot;; String CLICKHOUSE_DRIVER = &quot;ru.yandex.clickhouse.ClickHouseDriver&quot;;} github","link":"/20191120/Driud-SqlParse.html"},{"title":"ES6常用关键字总结","text":"ES6(ECMAScript 6.0)是JavaScript 语言的新一代标准，2015年6月正式发布。其提供了一些新特性使代码更加简洁。由于目前有些版本浏览兼容性不足，所以需要实用babel这类工具讲我们的ES6转换为ES5. let、const在ES6之前，是使用var来定义变量， 1var demo=&apos;demo&apos;; ES6之前，只有全局作用域和函数作用域，没有块级作用域,这种情况下会出现变量提升的现象导致变量被覆盖之类的问题，在ES6中，使用let就不存在这种问题，它只会在定义之后且在该块级作用域内可使用 1let demo=&apos;demo&apos;; const声明一个只读的常量，在声明时必须赋初始值，并且赋值后不可改变 1const API_URL=&quot;http://xxx.xxx.xxx&quot;; 模板字符串在ES6之前，需要拼接字符串，一般是通过”+”或者数组join的方式 123var a1=&apos;a1&apos;;var a2=a1+&apos;aa&apos;;var strs=[&apos;a1&apos;,&apos;a2&apos;].join(); 现在我们可以通过模版字符串来拼接 12let a1=&apos;a1&apos;;let a2=`aa${a1}`; 变量解构赋值E6之前只能一个个变量赋值 123let a = 1;let b = 2;let c = 3; ES6以后可以使用数组批量按照对应位置赋值 12let [a, b, c] = [1, 2, 3]; //a=1,b=2,c=3;let [a1,b1,c1]=[1,2]; //a1=1,a2=2,a3=undefined 也可以解析对象，解析对象的时候变量名必须和属性名一致，否则会解构失败， 1let { a, b } = { a: &apos;aaa&apos;, b: &apos;bbb&apos; }; //a=&apos;aaa&apos;,b=&apos;bbb&apos; 解构赋值对提取 JSON 对象中的数据 123456789let jsonData = { id: 42, status: &quot;OK&quot;, data: [867, 5309]};let { id, status, data: number } = jsonData;console.log(id, status, number); 箭头函数ES6 允许使用”箭头”（=&gt;）定义函数。函数体内的this对象，就是定义时所在的对象，而不是使用时所在的对象 123456var f = v =&gt; v;// 等同于var f = function (v) { return v;}; 如果箭头函数不需要参数或需要多个参数，就使用一个圆括号代表参数部分。 123456789var f = () =&gt; 5;// 等同于var f = function () { return 5 };var sum = (num1, num2) =&gt; num1 + num2;// 等同于var sum = function(num1, num2) { return num1 + num2;}; …操作符…用于获取函数的多余参数，这样就不需要使用arguments对象了。rest 参数搭配的变量是一个数组，该变量将多余的参数放入数组中。 1234567891011function add(...values) { let sum = 0; for (var val of values) { sum += val; } return sum;}add(2, 5, 3) // 10 注意，rest 参数之后不能再有其他参数（即只能是最后一个参数），否则会报错。 Class类ES6中提供了class关键字来定义类 12345678910111213141516171819class Point { constructor(x, y) { this.x = x; this.y = y; } toString() { return &apos;(&apos; + this.x + &apos;, &apos; + this.y + &apos;)&apos;; }}//等价于function Point(x, y) { this.x = x; this.y = y;}Point.prototype.toString = function () { return &apos;(&apos; + this.x + &apos;, &apos; + this.y + &apos;)&apos;;}; constructor方法是类的默认方法，通过new命令生成对象实例时，自动调用该方法。一个类必须有constructor方法，如果没有显式定义，一个空的constructor方法会被默认添加。 1234567class Point {}// 等同于class Point { constructor() {}} 这里只记录了几个常用的 新特性关键字，系统完整的学习可以去阮一峰大神的博客学习","link":"/20191122/ES6-7-8-9-10.html"},{"title":"AngularJS v1.x使用总结","text":"最近在改一个前后端分离的项目,前端用的Angular 1.4.5,后端用的java,由于AngularJs在4年前简单的使用过一次，大多都忘记了，这次拿到这个项目(前端被压缩过),第一眼就瞬间懵逼了,但是领导已经下了死命令了，也只得硬着头皮干，索性就把这次遇到的一些知识点记录一下。 控制器&amp;作用域ng-controller 指令指定使用的控制器，ng-app 指令初始化一个 AngularJS 应用程序,$scope作用域作为当前controller范围内的数据传输纽带，在controller中的$scope上添加相应的对象或者属性，在html即可使用 12345678910&lt;div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []); //定义一个模块app.controller(&apos;myCtrl&apos;, function($scope) { });&lt;/script&gt; 表达式 ,AngularJS 表达式可包含文字、运算符、变量、对象，将表达式中的内容绑定到HTML中 12345678910111213div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;&lt;h1&gt;{{carname}}&lt;/h1&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []);app.controller(&apos;myCtrl&apos;, function($scope) { $scope.carname = &quot;Volvo&quot;;});&lt;/script&gt; ng-model 指令数据双向绑定,在界面或者js中改变绑定变量的值，另一边也会随之影响 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;script src=&quot;https://cdn.staticfile.org/angular.js/1.4.6/angular.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt;&lt;body&gt;&lt;div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;名字: &lt;input ng-model=&quot;name&quot;&gt;&lt;h1&gt;你输入了: {{name}}&lt;/h1&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []);app.controller(&apos;myCtrl&apos;, function($scope) { $scope.name = &quot;John Doe&quot;;});&lt;/script&gt;&lt;p&gt;修改输入框的值，标题的名字也会相应修改。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 自定义指令Angular可以使用directive 来自定义指令 12345678910111213angular.module(&quot;app&quot;).directive(&quot;pivottableViewPanel&quot;, function() { return { restrict: &quot;AE&quot;, scope: { authType: &quot;@&quot;, authId: &quot;=&quot;, appChange(): &quot;&amp;&quot; }, templateUrl: &quot;js/modules/apps/pivottable/tpls/pivottableViewPanel.html&quot;, link: function($scope, $element, $attr) {} } }) restrict 值可以是以下几种: E 作为元素名使用 A 作为属性使用 C 作为类名使用 M 作为注释使用templateUrl：指定组件引用的html，可以是html代码也可以是html路径；scope：定义组件属性:@:单项绑定的前缀标识符,例如:;=:双向数据绑定前缀标识符,例如:;&lt;:单项绑定的前缀标识符，和=使用类似,例如:,但是不会影响父组件对象的值;&amp;:绑定函数方法的前缀标识符，例如：我们定义好的组件有一下几种方式可以调用: 元素名:&lt;pivottable-view-panel&gt;&lt;/pivottable-view-panel&gt;; 属性：&lt;div pivottable-view-panel&gt;&lt;/div&gt;; 类名：&lt;div class=&quot;pivottable-view-panel&quot;&gt;&lt;/div&gt;; 注解：&lt;!--directive: pivottable-view-panel--&gt;;这里需要注意的是，组件用驼峰命名法，Angular会自动将大写字母转为小写且在字母前以-隔开,在定义的scope中，如果对象属性只有值，默认组件属性是属性名转换后的名称,如果属性有值则使用属性值转换后的属性123456789101112scope: { authType: &quot;@&quot;, authId: &quot;=&quot;, appChange(): &quot;&amp;&quot; } 用的时候则是&lt;xxx auth-id&gt;&lt;/xxx&gt;scope: { authType: &quot;@&quot;, authId: &quot;=curAuthId&quot;, appChange(): &quot;&amp;&quot; } 用的时候则是&lt;xxx cur-auth-id&gt;&lt;/xxx&gt; 自定义服务Service是一个函数或对象，AngularJs自带了30多个服务，例如$http(向服务器请求数据)、$timeout(setTimeout),也可以自定义 123angular.module(&quot;demo&quot;).service(&quot;dataSetService&quot;,function(){}); 使用的话需要在控制器中注入这个Service 123angular.module(&quot;demo&quot;).controller(&apos;myCtrl&apos;, function($scope, dataSetService) { //使用dataSetService}); 依赖注入Angular提供了依赖注入功能，在使用的时候，加入事先定义好的service/factory/provider即可在自动注入 [\"$q\", \"$timeout\", \"DataAjaxService\"123function ($q, $timeout, dataAjaxService) { //此处即可使用$q}]); 未完待续","link":"/20191123/AngularJS-v1-4-5.html"},{"title":"Hexo SEO优化记录","text":"写博客其实是对自己工作经验和学过程的总结，可能写得不好，但是还是希望自己踩过的坑能让更多人去避开我们踩过的坑。所以，在自己记录的同时，更希望帮助更多的人去解决一些问题。但是我们写的东西别人一直都搜索不到，怎么办呢？要让别人知道，要么就是自己主动分享，要么就是朋友们自己搜索，我们今天是来说后者，那就是如何让百度收录我们的博客。 百度搜索其实还是挺严格的，它回去分析你博客的质量，如果质量太差也不会收录，当然这需要多学多练多写多总结。我们这次只总结搜索引擎的SEO优化。 生成sitemap这里我们需要安装三个插件 12npm install hexo-generator-sitemap --save-dev # 传统的sitemapnpm install hexo-generator-baidu-sitemap --save-dev # 百度sitemap 插件安装完成后，执行hexo g后，会在public目录下生成sitemap.xml和baidusitemap.xml文件,我们留着备用。 缩短Hexo生成的URL目录层级根据其他的SEO经验,URL层级越短越容易被抓取,有助于提升搜索结果排名,建议保持最多三个层级。默认情况下，Hexo给我们生成的规则是: 1permalink: :year/:month/:day/:title/ # 目录为 https://domain/year/month/day/title/ 目录层级有点，我们需要优化一下: 1permalink: :year-:month-:day/:title.html # 目录为 https://domain/year-month-day/title.html 百度站长提交连接我们先登录到百度的站点管理,没有账号的请自行注册。然后我们点击添加站点这里根据自己的实际情况填写然后下一步,自己勾选，然后再下一步。就是验证域名这里于三种方式，都有详细的说明，我选择的第三种CNAME验证,大家自行选择。解析完域名后稍等数分钟，点击完成验证，然后就OK，接下来我们生成sitemap文件并上传到七牛云，为什么要上传到七牛云呢，因为github禁止了搜索引擎爬虫，会导致百度抓取失败。或者把静态页面分别放置在github和coding上面，针对百度解析到不同的服务器上。至于如何提交到七牛云，请翻看我之前的文章，这里不再赘述。在生成之前切记要修改_config.yml的url属性.现在我们来访问一下http://blogs.52fx.biz/sitemap.xml可以看到接下来，把我们的sitemap文件提交到百度自动提交配置中.进入链接提交-&gt;自动提交-&gt;sitemap进行配置.提交后会有一个抓取队列,可以时刻关注状态，但是这种方式有点慢。大家看上面的图片，也能知道有三种方式提交，上面只是其中一种，还有两种，我们来分别讲解一下自动推送这种方式，也比较简单，在对象的主题的footer.ejs中加入: 1234567891011121314&lt;script&gt;(function(){ var bp = document.createElement(&apos;script&apos;); var curProtocol = window.location.protocol.split(&apos;:&apos;)[0]; if (curProtocol === &apos;https&apos;) { bp.src = &apos;https://zz.bdstatic.com/linksubmit/push.js&apos;; } else { bp.src = &apos;http://push.zhanzhang.baidu.com/push.js&apos;; } var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(bp, s);})();&lt;/script&gt; 即可，每次访问的时候，页面就会向百度提交。主动推送(实时),这个就需要我们安装一个插件： 1npm install hexo-baidu-url-submit --save 然后在_config.yml配置 12345678910111213141516deploy: - type: git repository: github: git@github.com:51offer-tech/51offer-tech.github.io.git #coding: git@git.coding.net:offer-tech/51offer-tech.git coding: https://e.coding.net/offer-tech/offer-tech.git gitee: https://gitee.com/eyiadmin/offer-tech.git branch: master - type: baidu_url_submitter# 百度链接自动提交baidu_url_submit: count: 1000 ## 提交最新的一个链接 host: http://blogs.52fx.biz ## 在百度站长平台中注册的域名 token: xxxxxxxx ## 请注意这是您的秘钥， 所以请不要把博客源代码发布在公众仓库里! path: baidu_urls.txt ## 文本文档的地址， 新链接会保存在此文本文档里 详细的资料大家可以去hexo-baidu-url-submit 的github查看. Hexo Keywords关键字设置由于我用的hexo-theme-icarus,我也没有过多的去查找资料，就直接手动加了一个: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354hexo.extend.helper.register(&apos;page_keywords&apos;, function (page = null) { page = page === null ? this.page : page; let title = page.title; if (this.is_archive()) { title = this._p(&apos;common.archive&apos;, Infinity); if (this.is_month()) { title += &apos;: &apos; + page.year + &apos;/&apos; + page.month; } else if (this.is_year()) { title += &apos;: &apos; + page.year; } } else if (this.is_category()) { title = this._p(&apos;common.category&apos;, 1) + &apos;: &apos; + page.category; } else if (this.is_tag()) { title = this._p(&apos;common.tag&apos;, 1) + &apos;: &apos; + page.tag; } else if (this.is_categories()) { title = this._p(&apos;common.category&apos;, Infinity); } else if (this.is_tags()) { title = this._p(&apos;common.tag&apos;, Infinity); } let keywords=page.keywords; const siteTitle = hexo.extend.helper.get(&apos;get_config&apos;).bind(this)(&apos;title&apos;, &apos;&apos;, true); keywords=keywords||hexo.extend.helper.get(&apos;get_config&apos;).bind(this)(&apos;keywords&apos;, &apos;&apos;, true); return [title, siteTitle,keywords].filter(str =&gt; typeof (str) !== &apos;undefined&apos; &amp;&amp; str.trim() !== &apos;&apos;).join(&apos; = &apos;); }); hexo.extend.helper.register(&apos;page_description&apos;, function (page = null) { page = page === null ? this.page : page; let title = page.title; if (this.is_archive()) { title = this._p(&apos;common.archive&apos;, Infinity); if (this.is_month()) { title += &apos;: &apos; + page.year + &apos;/&apos; + page.month; } else if (this.is_year()) { title += &apos;: &apos; + page.year; } } else if (this.is_category()) { title = this._p(&apos;common.category&apos;, 1) + &apos;: &apos; + page.category; } else if (this.is_tag()) { title = this._p(&apos;common.tag&apos;, 1) + &apos;: &apos; + page.tag; } else if (this.is_categories()) { title = this._p(&apos;common.category&apos;, Infinity); } else if (this.is_tags()) { title = this._p(&apos;common.tag&apos;, Infinity); } let description=page.description; const siteTitle = hexo.extend.helper.get(&apos;get_config&apos;).bind(this)(&apos;title&apos;, &apos;&apos;, true); description=description||hexo.extend.helper.get(&apos;get_config&apos;).bind(this)(&apos;description&apos;, &apos;&apos;, true); return [title, siteTitle,description].filter(str =&gt; typeof (str) !== &apos;undefined&apos; &amp;&amp; str.trim() !== &apos;&apos;).join(&apos; , &apos;); }); 然后在主题的head.ejs中加上： 123&lt;meta name=&quot;keywords&quot; content=&quot;&lt;%= page_keywords() %&gt;&quot;&gt;&lt;meta name=&quot;description&quot; content=&quot;&lt;%= page_description() %&gt;&quot;&gt;&lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no&quot;/&gt; 最终效果 使用HTTPS 据说百度会给https的网站加权。我这里是直接配置的七牛云免费的SSL证书，当然是需要费用的，不过也很便宜 123第 0 GB 至 100 TB (含) 0.28 元/GB第 100 TB 至 1024 TB (含) 0.23 元/GB第 1024 TB 以上 0.18 元/GB 未完待续，持续更新中.","link":"/20200106/Hexo-SEO%E4%BC%98%E5%8C%96%E8%AE%B0%E5%BD%95.html"},{"title":"Docker常用命令整理","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 Docker基础命令docker images 查看当前下载镜像列表 12345[root@VM_175_142_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhwdsl2/ipsec-vpn-server latest 62e5a169190a 7 months ago 206MBpostgres latest 30bf4f039abe 8 months ago 312MBredis latest 0f88f9be5839 8 months ago 95MB docker search {镜像名} (镜像仓库中的镜像)docker pull {镜像名}:{版本号} (拉取指定版本镜像,如果不指定版本， 将默认使用 latest 镜像)docker run -t -i {镜像名} (启动镜像,如果主机不存在，会自动下载镜像) 123456789101112131415161718192021222324252627282930313233343536373839404142-d, --detach=false， 设置容器上前台运行还是后台运行，默认为false后台运行-i, --interactive=false， 打开STDIN，用于控制台交互-t, --tty=false， 分配tty设备，可以支持终端登录，默认为false-u, --user=&quot;&quot;， 设置容器的用户-a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=&quot;&quot; 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=&quot;&quot; 指定容器的内存上限 -P, --publish-all=false， 指定容器暴露的端口-p, --publish=[]， 指定容器暴露的端口-h, --hostname=&quot;&quot;， 指定容器的主机名-v, --volume=[]， 给容器挂载存储卷，挂载到容器的某个目录--volumes-from=[]， 给容器挂载其他容器上的卷，挂载到容器的某个目录--cap-add=[]， 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities--cap-drop=[]， 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities--cidfile=&quot;&quot;， 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法--cpuset=&quot;&quot;， 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU--device=[]， 添加主机设备给容器，相当于设备直通--dns=[]， 指定容器的dns服务器--dns-search=[]， 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件--entrypoint=&quot;&quot;， 覆盖image的入口点--env-file=[]， 指定环境变量文件，文件格式为每行一个环境变量--expose=[]， 指定容器暴露的端口，即修改镜像的暴露端口--link=[]， 指定容器间的关联，使用其他容器的IP、env等信息--lxc-conf=[]， 指定容器的配置文件，只有在指定--exec-driver=lxc时使用--name=&quot;&quot;， 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字--net=&quot;bridge&quot; 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge),但是不进行配置--privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=&quot;no&quot; 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 docker run -d --name=nginx nginx:latest -p 宿主机端口:容器端口 -v 宿主机目录:容器目录 docker ps #查看正在运行的容器docker ps -l #查看最后退出的容器的IDdocker ps -a #查看所有的容器，包括退出的。docker logs {容器ID|容器名称} #查询某个容器的所有操作记录。docker logs -f {容器ID|容器名称} #实时查看容易的操作记录。 1234docker rm$(docker ps -a -q) #删除所有容器docker rm {容器ID|容器名} #删除单个容器docker rmi {镜像ID} #删除单个镜像docker rmi$(docker images | grep none | awk &apos;{print $3}&apos; | sort -r) #删除所有镜像 docker stop {容器ID|容器名} #停止某个容器docker start {容器ID|容器名} #启动某个容器docker kill {容器ID|容器名} #杀掉某个容器 docker export {容器ID|容器名} -o /root/文件名.tar(或者docker export {容器ID|容器名} &gt; /root/文件名.tar) #导出docker import {容器文件} {镜像名}:{tag} #导入后生成的是镜像不是容器，docker load也可以导入，其中两者人区别如下： 12docker load 保留了容器的完整记录docker import 仅保存容器当时的快照状态，在导入的时候自己定义标签、名称等元数据 docker container inspect {容器ID|容器名} #返回容器的ID、创建时间、路径、状态、镜像等信息 docker container stats {容器ID|容器名} #查看容器的CPU、内存、存储、网络等资源的使用情况可以使用 docker cp {宿主机目录} {容器ID}:{容器目录} #将宿主机内的指定目录文件传输至容器内部的指定目录 docker cp {容器ID}:{容器目录} {宿主机目录} #将容器内部的指定目录文件复制到宿主机指定目录 docker commit {容器ID} {镜像名}:{tag} #将容器重新打包成镜像 1234567-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 docker push {镜像名|镜像ID} #推送在镜像仓库 Dockerfile文件参数 FROM #指定基础镜像，必须为第一个命令 MAINTAINER #作者信息 RUN #构建镜像时执行的命令 ADD #复制文件到容器中 COPY #复制文本到容器中COPY &lt;源路径&gt;… &lt;目标路径&gt; 1ADD和COPY的差别：ADD命令tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，COPY不会自动解压文件，也不能访问网络资源 CMD #容器启动时执行的命令。shell 格式： CMD &lt;命令&gt; exec 格式： CMD [“可执行文件”, “参数1”, “参数2”…] ENTRYPOINT #配置容器 LABEL #为镜像添加元数据 ENV #设置环境变量 EXPOSE #指定外界交互的容器端口EXPOSE &lt;端口1&gt; [&lt;端口2&gt;…] VOLUME #指定持久化目录VOLUME [“&lt;路径1&gt;”, “&lt;路径2&gt;”…] WORKDIR #工作目录，自动cd到执行目录 示例： 123456789101112 # FROM代表此次构建的镜像的基础镜像基础,可在镜像名后带版本号，不带版本号默认latestFROM python# COPY是拷贝宿主机文件到镜像中COPY ./spider /work# RUN则是在镜像中执行命令，有时候可能需要安装依赖环境，也可以在run中执行RUN ls /work# 切换工作目录，相当于cd workWORKDIR /work#EXPOSE 外界交互的端口EXPOSE 8080# CMD是镜像启动后默认执行，CMD加中括号等同于exec执行命令，不加中括号等同于 sh -c 执行命令CMD [&quot;python&quot;,&quot;spider.py&quot;] docker build ocnfig #用于检查dockerfile文件是否有误 docker build . -t spider:v1.0 #构建镜像，构建好之后可以使用docker images命令进行查询 Docker-compose.yml文件配置build：定义镜像生成，可以指定Dockerfile构建，在up 启动之时执行构建任务 image：指定镜像启动容器，如果镜像不存在会自动拉去最新镜像 environment：环境变量和配置 ports：端口映射，将容器端口映射在宿主机 depends_on：指定依赖关系。适用于需要按顺序启动的服务，会先启动所依赖的镜像 volumes：挂载宿主机目录或者数据容器卷 volumes_from: 从容器挂载 context：指定Dockerfile文件或者是远程网络文件 args：构建参数，这些参数只能在构建过程中访问 container_name：指定容器名称 links: 链接其他容器 command: 启动执行命令 示例： 123456789101112131415161718192021version: &quot;3&quot;services: pgsql: image: postgres ports: - &quot;15432:5432&quot; environment: POSTGRES_PASSWORD: scyd! volumes: - ./data/postgresql_data1:/var/lib/postgresql/data restart: always redis: image: redis command: redis-server --requirepass scyd! ports: - &quot;16379:6379&quot; volumes: - ./data/redis_data1:/data restart: always 执行docker-compose ps： 12345[root@VM_175_142_centos ~]# docker-compose ps Name Command State Ports -------------------------------------------------------------------------------root_pgsql_1 docker-entrypoint.sh postgres Up 0.0.0.0:15432-&gt;5432/tcproot_redis_1 docker-entrypoint.sh redis ... Up 0.0.0.0:16379-&gt;6379/tcp 容器名：{目录名}{服务名}{容器序号} 从1开始 docker-compose up -d #构建并启动容器,首次运行会执行docker-compose build 1234-d：后台进程--scale：指定服务运行的容器个数（如果服务有对外的端口就不能指定多个容器，因为端口已经被占用） Eg：docker-compose up -d --scale web=1 --scale redis=2 docker-compose exec {服务名称} bash #登录到某个容器中 docker-compose down #删除所有容器,镜像 docker-compose ps #显示所有容器 docker-compose restart {服务名称} #重新启动容器 docker-compose build {服务名称} #构建镜像 。 docker-compose build –no-cache {服务名称} #不带缓存的构建。 docker-compose logs {服务名称} #查看容器的日志 docker-compose logs -f {服务名称} #查看容器的实时日志 docker-compose rm {服务名称} #删除compose服务 docker-compose kill {服务名称} #kill compose服务 docker-compose stop {服务名称} #重启compose服务 docker-compose start {服务名称} #启动容器 docker-compose config -q #验证yml文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息 docker-compose run {服务名} {cmd} #在某个服务上运行shell命令","link":"/20191108/Docker-compose-ymal.html"},{"title":"Go在Windows下编译linux可执行二进制文件","text":"完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？ 完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？我们需要修改几个参数： 1234SET CGO_ENABLED=0SET GOARCH=amd64SET GOOS=linuxgo build main.go 一次执行以上命令，就可以在项目目录生成一个二进制文件，所修改的变量值仅对当前窗口有效，可以如果我们每次都需要输入这些命令的话，着实还是有些繁琐，那么，我们可以新建一个bat文件，将命令复制到bat文件中，以后每次就只需要执行这个bat文件即可。如果又想编译成Windows文件，要么就是关闭窗口重新打开，要么就是修改变量值： 1234SET CGO_ENABLED=1SET GOARCH=SET GOOS=windowsgo build main.go","link":"/20191103/Go%E5%9C%A8Windows%E4%B8%8B%E7%BC%96%E8%AF%91linux%E5%8F%AF%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6.html"},{"title":".Net Core 3.X WebApi 自宿主并注册成Windows服务","text":".net core跨平台之后，部署方式也变得多了。在Windows上可以IIS、Kestrel、Windows 服务,我之前做的一个项目,用的Kestrel前面再加了一层Nginx代理。因为之前.net的时候部署老是用IIS,感觉有点繁琐，所以这次就来探究一下Windows 服务的方式。 基于WindowsServices创建服务首先，我们需要安装一个组件Microsoft.Extensions.Hosting.WindowsServices,然后在Program.cs使用UseWindowsService()即可,完整代码如下: 12345678910111213141516171819public class Program { public static async Task Main(string[] args) { await CreateHostBuilder(args).Build().RunAsync(); } public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .UseServiceProviderFactory(new AutofacServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); }).ConfigureLogging(logging =&gt; { logging.ClearProviders(); //删除日志组件 logging.SetMinimumLevel(Microsoft.Extensions.Logging.LogLevel.Trace); }).UseNLog().UseWindowsService(); } 我们发布尝试一下。 1dotnet publish -r win7-x64 -c release -o ./bin/output 发布完成后，我们有两种方式创建服务: 基于Windows的SC 基于PowerShell的New-Service 基于Windows的SC创建Windows服务首先，我们熟悉一下sc的用法: 1sc [ServerName] create Servicename [Optionname= Optionvalues] [ServerName]可选，可以操作远程计算机。如果在本地计算机上操作就不用添加任何参数。 Servicename 注册的服务名称 Optionname &amp; Optionvalues 注册服务时指定的参数名&amp;参数值 123456type=[own|share|interact|kernel|filesys] #关于建立服务的类型，默认是share。start=[boot|system|auto|demand|disabled] #关于启动服务的类型，默认是demand（手动）。error=[normal|severe|critical|ignore] #当服务在导入失败错误的严重性，默认是normal。binPath=[binary path] #服务二进制文件的路径名。displayname=[服务显示名称]password=[用户密码] #如果一个不同于localsys tem的账号使用时需要使用这个。 sc 删除: 1sc [ServerName] delete [ServiceName] sc start/stop 1sc start/stop [ServiceName] SC创建服务我们现在就把我们刚才发布的二进制文件注册成Windows服务 12 C:\\Users\\lenovo\\source\\repos\\Swagger.Demo\\Web\\bin\\output&gt;sc create SwaggerDemo start=auto binpath=&quot;\\&quot;C:\\Users\\lenovo\\source\\repos\\Swagger.Demo\\Web\\bin\\output\\Web.exe\\&quot;[SC] CreateService 成功 现在我们就启动起来看看效果: 123456789101112 C:\\Users\\lenovo\\source\\repos\\Swagger.Demo\\Web\\bin\\output&gt;sc start SwaggerDemoSERVICE_NAME: SwaggerDemo TYPE : 10 WIN32_OWN_PROCESS STATE : 2 START_PENDING (NOT_STOPPABLE, NOT_PAUSABLE, IGNORES_SHUTDOWN) WIN32_EXIT_CODE : 0 (0x0) SERVICE_EXIT_CODE : 0 (0x0) CHECKPOINT : 0x0 WAIT_HINT : 0x7d0 PID : 14428 FLAGS : 基于PowerShell New-Service创建服务语法格式: 123456789101112New-Service [-Name] &lt;String&gt; [-BinaryPathName] &lt;String&gt; [-DisplayName &lt;String&gt;] [-Description &lt;String&gt;] [-SecurityDescriptorSddl &lt;String&gt;] [-StartupType &lt;ServiceStartupType&gt;] [-Credential &lt;PSCredential&gt;] [-DependsOn &lt;String[]&gt;] [-WhatIf] [-Confirm] [&lt;CommonParameters&gt;] 我们使用New-Service重新注册服务。 12345PS C:\\Users\\lenovo&gt; New-Service -Name SwaggerDemoByPowerShell -BinaryPathName C:\\Users\\lenovo\\source\\repos\\Swagger.Demo\\Web\\bin\\output\\Web.exe -Description &quot;SwaggerDemoByPowerShell&quot; -DisplayName &quot;SwaggerDemoByPowerShell&quot; -StartupType AutomaticStatus Name DisplayName------ ---- -----------Stopped SwaggerDemoByPo... SwaggerDemoByPowerShell [参考]https://www.cnblogs.com/inuex/p/4299690.htmlhttps://docs.microsoft.com/zh-cn/aspnet/core/host-and-deploy/windows-service?view=aspnetcore-3.1&amp;tabs=visual-studio","link":"/20200112/Net-Core-3-X-Windows-Service.html"},{"title":"工作中常用的抓包工具-Fiddler和Wireshark介绍","text":"我们这个信息化时代，每天都不知不觉的会给不知道哪些软件运营商偷偷的说一些悄悄话，特别是我们程序猿，在开发过程中更是，偶尔会遇到不知道TCP交互过程中到底传递或者接受了哪些信息，给我们的Debug蒙上了一层神秘的面纱，这时候，我们需要一些抓包工具帮助我们轻松Debug。一般的请求可以借助浏览器自带的NetWork抓包工具，移动端一些网页的话可以借助腾讯开源的vConsole，再高端一点就是借助Fiddler来抓取http或者https请求。但是有时候这样也满足不了我们的需要，那么就再祭出Wireshark神器来抓取tcp和udp请求。 浏览器自带的抓包工具一些主流浏览器都自带有Network抓包工具,只需F12即可唤出,非常方便,我这里只演示了 Chrome浏览器的抓包过程。 Fiddler简单操作Fiddler是一款http\\https协议代理调试工具，它能够获取请求之间的数据和状态，设置断点，以及修改数据。首先去Fiddler网站下载并手动安装。安装成功后打开Fiddler，界面如下:默认情况下，它是抓取我们所有的请求。我们需要对Fiddler进行过滤设置。假如我们只想抓取www.cnblogs.com的请求，我们需要这样处理：,最后我们可以得到这样的效果:,还可以指定客户端的进程:进程方式除了刚才在Filters中设置外，还可以使用拖动方式，下面，我们来试试抓取手机端的请求，在抓取手机端请求前，请确保手机和电脑在同一个局域网中，然后进入Tools-&gt;Options-&gt;Connections对Fiddler进行如下设置:,由于我在PC端映射了一个wifi供手机连接，故我手机代理设置如下:假如我们抓取美团App的请求，现在打开App即可看到:这里只是一个简单的示例介绍，更多高深技巧请自行探索。 Wireshark简单操作首先Wireshark下载，安装完成后打开可以看到我们本地有很多网卡驱动，我们怎么知道现在网络是哪个网卡呢？有两个方式，一个是查看本地连接，另外一个就是看界面的网络流量。可以看到Wireshark开始为我们抓包，由于Wireshark为我们抓取了TCP和HTTP，会有很多无用的信息导致我们无从下手，这时候可以使用Wireshark的过滤规则:,在过滤栏输入关键字就会有相应的智能提示。 在Wireshark抓包中有多层信息: Frame 15788: 79 bytes on wire (632 bits), 79 bytes captured (632 bits) on interface \\Device\\NPF_{69B14E8C-A0A5-4064-9CF7-EB4651D24A99}, id 0：物理层的数据帧概况。 Ethernet II, Src: HuaweiTe_22:5a:c6 (fc:48:ef:22:5a:c6), Dst: WistronI_fd:67:50 (54:ee:75:fd:67:50)：数据链路层以太网帧头部信息。 Internet Protocol Version 4, Src: 10.101.11.97, Dst: 10.101.27.241：互联网层IP包头部信息,源地址和目的地址。 Transmission Control Protocol, Src Port: 80, Dst Port: 50773, Seq: 2606, Ack: 3560, Len: 25：传输层的数据段头部信息，TCP协议层信息。 Hypertext Transfer Protocol：应用层的信息，此处是HTTP\\HTTPS协议会现在该项。 Wireshark常用过滤条件: 地址过滤。ip.dst==xxx.xx.xxx.xxx 过滤目的地址为xxx.xx.xxx.xxx，ip.src==xxx.xx.xxx.xxx 过滤原地址地址为xxx.xx.xxx.xxx,ip.dst==xxx.xx.xxx.xxx &amp;&amp; ip.src==xxx.xx.xxx.xxx 过滤源地址为xxx.xx.xxx.xxx且目的地址xxx.xx.xxx.xxx 协议过滤。直接在过滤栏输入协议即可 tcp、udp、arp、http、ftp、ssl、smtp、dns、ip、ardp 端口过滤。在过滤栏输入tcp.port==端口号(目的端口和源端口)或者 tcp.dstport==端口号(目的端口)，tcp.srcport==端口号(源端口) HTTP过滤。这个就比较多了，暂时详述: 通过Wireshark可以很方便的分析TCP的三次握手和四次挥手的过程，有助于我们更佳直观的理解TCP协议。 好了，暂时先告一段落吧，这里只是简单是写了软件的基本使用，如果要抓取HTTP和HTTPS协议的数据的话，个人建议使用Fiddler。其他更加高级的应用在后面再分享吧。","link":"/20200110/HttpRequest-Tools-On-Windows.html"},{"title":".Net Core3.x部署到阿里云ACK中","text":"前面，我使用自己的服务器基于Docker部署了core程序，现在我们来使用一下新的方法，将我们的程序发布到阿里云ACK中，如果是IDEA的话，可以使用Alibaba Cloud Toolkit实现快速部署，但是现在仅支持IntelliJ IDEA、Eclipse、PyCharm 以及其他、Mave，不过据说VS CODE快要来了。那么现在我们暂时就先手动来操作一番吧 发布Core程序我习惯使用命令方式: 1dotnet publish -r linux-x64 -o ./bin/output -c release 具体命令说明详见https://docs.microsoft.com/zh-cn/dotnet/core/tools/dotnet-publish?tabs=netcore21,其中的RID也比较重要，大家也需要了解一下.我们开始编写Dockerfile: 123456FROM mcr.microsoft.com/dotnet/core/runtime:3.1WORKDIR /appEXPOSE 80EXPOSE 443COPY [&quot;.&quot;, &quot;.&quot;]ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] 开始构建： 12345678910111213141516171819202122232425262728293031[root@instance-p0a4erj8 core]# docker build -t core3.x-swagger -f Dockerfile .Sending build context to Docker daemon 125.3MBStep 1/6 : FROM mcr.microsoft.com/dotnet/core/runtime:3.13.1: Pulling from dotnet/core/runtime000eee12ec04: Pull complete 67bac0b5d3cc: Pull complete e8c80b499c83: Pull complete 77b73bc084ae: Pull complete Digest: sha256:9946cd419d740e903f94677ed57af28f56e77b967186b868ed64765b870bf49dStatus: Downloaded newer image for mcr.microsoft.com/dotnet/core/runtime:3.1 ---&gt; 08d8cf51bdfdStep 2/6 : WORKDIR /app ---&gt; Running in 6663a593f044Removing intermediate container 6663a593f044 ---&gt; bb8603da7b34Step 3/6 : EXPOSE 80 ---&gt; Running in 8c844a10467eRemoving intermediate container 8c844a10467e ---&gt; 61cf39dd9c13Step 4/6 : EXPOSE 443 ---&gt; Running in 7a616725163cRemoving intermediate container 7a616725163c ---&gt; 6ded800d3aecStep 5/6 : COPY [&quot;.&quot;, &quot;.&quot;] ---&gt; 4eb15d11ccb0Step 6/6 : ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] ---&gt; Running in a087553cf793Removing intermediate container a087553cf793 ---&gt; 90fc47847faaSuccessfully built 90fc47847faaSuccessfully tagged core3.x-swagger:latest 运行我们的镜像: 1docker run --name swagger -d -p 80:80 core3.x-swagger 可以看到我们的容器已经启动好了。 123[root@instance-p0a4erj8 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESeb38557539a9 core3.x-swagger &quot;dotnet Web.dll&quot; About a minute ago Up About a minute 0.0.0.0:80-&gt;80/tcp, 443/tcp swagger 可以查看一下日志: 1234567891011[root@instance-p0a4erj8 ~]# docker logs eb38557539a9info: Microsoft.Hosting.Lifetime[0] Now listening on: http://[::]:80info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down.info: Microsoft.Hosting.Lifetime[0] Hosting environment: Productioninfo: Microsoft.Hosting.Lifetime[0] Content root path: /appwarn: Microsoft.AspNetCore.HttpsPolicy.HttpsRedirectionMiddleware[3] Failed to determine the https port for redirect. 访问也是正常.好，接下来，我们就上传到阿里的ACR上面。先去https://cr.console.aliyun.com进行设置.首先需要提示设置密码.设置完后，会跳转到创建仓库页面创建完成后，我们就开始登陆到ACR 1234567[root@instance-p0a4erj8 ~]# docker login --username=xxxxxx registry.cn-hangzhou.aliyuncs.comPassword: WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded 推送镜像 1234567891011121314 docker tag [ImageId] registry.cn-hangzhou.aliyuncs.com/52fx/52fx:[镜像版本号] docker push registry.cn-hangzhou.aliyuncs.com/52fx/52fx:[镜像版本号] 示例:[root@instance-p0a4erj8 ~]# docker tag core3.x-swagger registry.cn-hangzhou.aliyuncs.com/52fx/52fx:1.0[root@instance-p0a4erj8 ~]# docker push registry.cn-hangzhou.aliyuncs.com/52fx/52fx:1.0The push refers to repository [registry.cn-hangzhou.aliyuncs.com/52fx/52fx]66fe7dbc7904: Pushed 3391145729e6: Pushed 52d5ea296228: Pushed 239bf536471e: Pushed cad0d4e88a35: Pushed 831c5620387f: Pushed 1.0: digest: sha256:b37a187840b68d1937ffef2c350bc190f7f435840ece7262ae9445533c5fb766 size: 1583 部署镜像 创建K8S集群，需要创建一个专有网络 需要开通两个授权的权限 创建成功后需要耐心的等待几分钟 接下来就是部署镜像,全是界面操作。 创建好Service-&gt;Ingress就可以访问了 service: 12345678910111213141516171819202122apiVersion: v1kind: Servicemetadata: creationTimestamp: &apos;2019-12-14T03:28:23Z&apos; name: net namespace: default resourceVersion: &apos;19318673&apos; selfLink: /api/v1/namespaces/default/services/net uid: c8ba0fb3-1e21-11ea-9a91-9e68548c9b68spec: clusterIP: None ports: - name: http port: 80 protocol: TCP targetPort: 80 selector: app: 52fx-default sessionAffinity: None type: ClusterIPstatus: loadBalancer: {} Ingress： 123456789101112131415161718192021222324apiVersion: extensions/v1beta1kind: Ingressmetadata: annotations: nginx.ingress.kubernetes.io/service-weight: &apos;net: 100&apos; creationTimestamp: &apos;2019-12-14T03:33:32Z&apos; generation: 1 name: 52fx namespace: default resourceVersion: &apos;19338000&apos; selfLink: /apis/extensions/v1beta1/namespaces/default/ingresses/52fx uid: 80bd156a-1e22-11ea-9a91-9e68548c9b68spec: rules: - http: paths: - backend: serviceName: net servicePort: 80 path: /status: loadBalancer: ingress: - ip: 39.105.240.144 后面，我们再详细了解一下k8s的相关配置参考容器服务Kubernetes版","link":"/20191213/Net-Core3-x%E9%83%A8%E7%BD%B2%E5%88%B0%E9%98%BF%E9%87%8C%E4%BA%91ACK%E4%B8%AD.html"},{"title":"IntelliJ IDEA 常用快捷键整理","text":"IntelliJ IDEA是为了最大限度地提高开发者的生产力而设计的，其强大的静态代码分析和人机工程学设计，为源代码编制了索引后，通过在各种上下文中提供相关建议，而且提供了快速而智能的体验,比如代码自动补全、即时的代码分析和可靠的重构工具。 IntelliJ 最常用的几个快捷键组合Ø Top #10切来切去：Ctrl+Tab Ø Top #9选你所想：Ctrl+W Ø Top #8代码生成：Template/Postfix +Tab Ø Top #7发号施令：Ctrl+Shift+A Ø Top #6无处藏身：Shift+Shift Ø Top #5自动完成：Ctrl+Shift+Enter Ø Top #4创造万物：Alt+Insert Ø Top #3智能补全：Ctrl+Shift+Space Ø Top #2自我修复：Alt+Enter Ø Top #1重构一切：Ctrl+Shift+Alt+T 代码快速生成缩写 缩写 内容 fori for (int i = 0; i &lt; ; i++) {} psvm public static void main(String[] args){} sout System.out.println(); (在 Kotlin 中是 println()) souf System.out.printf(); serr System.err.println(); psf public static final psfi public static final int psfs public static final String 调试快捷键 快捷键 作用 Alt+F8 debug时选中查看值 Alt+Shift+F9 选择Debug Alt+Shift+F10 选择Run Ctrl+Shift+F9 编译 Ctrl+Shift+F8 查看断点 F7 步入 Shift+F7 智能步入 Alt+Shift+F7 强制步入 F8 步过 Shift+F8 步出 Alt+Shift+F8 强制步过 F9 恢复程序 Alt+F9 运行至光标处 Ctrl+Alt+F9 强制运行至光标处 Alt+F10 定位到断点 查询快捷键 快捷键 作用 Ctrl＋Shift＋Backspace 可以跳转到上次编辑的地 Ctrl+Alt+ left/right 前后导航编辑过的地方 ALT+7 靠左窗口显示当前文件的结构 Ctrl+F12 浮动显示当前文件的结构 Alt+F7 找到你的函数或者变量或者类的所有引用到的地方 Ctrl+Alt+F7 找到你的函数或者变量或者类的所有引用到的地方 Ctrl+Shift+Alt+N 查找类中的方法或变量 Ctrl+N 查找类 Ctrl+Shift+N 查找文件 Ctrl+G 定位行 Ctrl+F 在当前窗口查找文本 Ctrl+Shift+F 在指定窗口查找文本 Ctrl+R 在当前窗口替换文本 Ctrl+Shift+R 在指定窗口替换文本 Alt+Shift+C 查找修改的文件 Ctrl+E 最近打开的文件 F3 向下查找关键字出现位置 Shift+F3 向上一个关键字出现位置 选中文本，按Alt+F3 高亮相同文本，F3逐个往下查找相同文本 F4 查找变量来源 Ctrl+Shift+O 弹出显示查找内容 Ctrl+W 选中代码，连续按会有其他效果 F2 或Shift+F2 高亮错误或警告快速定位 Ctrl+Up/Down 光标跳转到第一行或最后一行下 Ctrl+B 快速打开光标处的类或方法 Ctrl+Alt+B 找所有的子类 Ctrl+Shift+B 找变量的类 Ctrl+Shift+上下键 上下移动代码 Ctrl+Alt+left/right 返回至上次浏览的位置 Ctrl+X 删除行 Ctrl+D 复制行 Ctrl+/ 或 Ctrl+Shift+/ 注释(// 或者/…/) Ctrl+H 显示类结构图 Ctrl+Q 显示注释文档 Alt+F1 查找代码所在位置 Alt+1 快速打开或隐藏工程面板 Alt+left/right 切换代码视图 Alt+↑/↓ 在方法间快速移动定位 Ctrl+Alt+ left/right 前后导航编辑过的地方 Ctrl＋Shift＋Backspace 可以跳转到上次编辑的地 Alt+6 查找TODO 代码相关 快捷键 作用 Ctrl+Alt+O 优化导入的类和包 Alt+Insert 生成代码(如Getter,Setter方法,构造函数等)或者右键(Generate) Ctrl+Alt+T 生成try catch 或者 Alt+enter Ctrl+Alt+T 把选中的代码放在 TRY{} IF{} ELSE{} 里 Ctrl+O 重写方法 Ctrl+I 实现方法 Ctr+Shift+U 大小写转化 Alt+回车 导入包,自动修正 Alt+/ 代码提示 Ctrl+J 自动代码 Ctrl+Shift+J 整合两行为一行 Ctrl+空格 代码提示 Ctrl+Shift+Space 自动补全代码 Ctrl+Alt+L 格式化代码 Ctrl+Alt+I 自动缩进 Ctrl+E 最近更改的代码 Ctrl+Alt+Space 类名或接口名提示 Ctrl+P 方法参数提示 Ctrl+Q 可以看到当前方法的声明 Shift+F6 重构-重命名 (包、类、方法、变量、甚至注释等) Ctrl+Alt+V 提取变量","link":"/20191230/IntelliJ-IDEA-%E5%B8%B8%E7%94%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E6%94%B6%E8%97%8F%E6%95%B4%E7%90%86.html"},{"title":"Nginx HTTP/TCP代理配置","text":"众所周知，nginx是一款高性能的反向代理工具，在之前nginx只能代理应用层的应用，如果是要做TCP即网络第4层的代理就只有借助HaProxy等工具，在nginx1.9版本之后即可支持TCP的代理。下面，我们来展现一下nginx强大的代理能力。 我们的网络有内网和办公网还有互联网，首先所有项目部署在内网，使用只能在生产网(需要开通特殊策略)，特殊情况下，可以申请互联网的网络，但是比较麻烦，而且，我们进入生产服务器必须在内网的环境下通过堡垒机才能登陆，现在多个生产部署多个系统，但是映射到办公网只有个IP且只有一个端口。此时，我们就需要用到反向代理实现系统的访问。 Nginx基本配置说明 nginx有强大的url匹配功能，下面，我们一起来了解一下nginx的优先级匹配。以下是匹配语法模版 1234location [=|~|~*|^~] /uri/ { root html; index index.html index.htm;} 说明： 1234567= 表示精确匹配^~ 表示uri以某个常规字符串开头~ 表示区分大小写的正则匹配~* 表示不区分大小写的正则匹配 !~ 表示区分大小写不匹配的正则!~* 表示不区分大小写不匹配的正则/ 通用匹配，相当于根目录可以匹配到任何请求 优先级: 精确匹配&gt;普通匹配&gt;正则匹配 nginx对http进行反向代理： 123location / { proxy_pass http://127.0.0.1; } Nginx Http反向代理实践配置下面是我们为解决上面的问题所做的配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //HTTP代理 location / { proxy_pass http://xx.xx.xxx.xxx:8081/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /Insight { proxy_pass http://xx.xxx.x.xxx:8083/BingoInsight; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /etl{ proxy_pass http://xx.xxx.x.xxx:8080/etl; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header Host $host:$server_port; #这里是重点,这样配置才不会丢失端口} //websocket 代理 location /gateone/{ proxy_pass http://xx.xx.xx.xx:58080/gateone/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; client_max_body_size 300m; proxy_http_version 1.1; proxy_redirect off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;} ...... Nginx 代理转发TCP配置 我又有另外一个场景，也是内网和办公网的交互，但是这个场景不需要那么严格，可以直连服务器，但是我们是想在办公网直连数据库。这显然形成了一个屏障 这种情况下，我们想要连接到数据库就只有做一个TCP四层代理。我们就可以借助nginx upstream的功能实现TCP转发。配置如下 123456789upstream proxy_redis{ server xx.xxx.xx.xxx:6379;} server { listen 6379; #监听端口 proxy_pass proxy_redis; #转发请求} 然后刷新一下nginx配置: 1nginx -s reload 此时连接代理服务器响应的端口，就可以将TCP请求转发到实际服务器。 官方文档nginx下载地址","link":"/20191108/Nginx-agent-configuration.html"},{"title":"Nginx Proxy_Pass和Rewirte的用法","text":"在Nginx中我们用的比较多的肯定就是server和loction模块，在模块中用的比较多的就是proxy_pass和rewrite，我们这里就来大概了解一下这二者的常用用法。 Nginx内置的常用变量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960$args #请求中的参数值$query_string #同 $args$arg_NAME #GET请求中NAME的值$is_args #如果请求中有参数，值为&quot;?&quot;，否则为空字符串$uri #请求中的当前URI(不带请求参数，参数位于$args)，可以不同于浏览器传递的$request_uri的值，它可以通过内部重定向，或者使用index指令进行修改，$uri不包含主机名，如&quot;/foo/bar.html&quot;。$document_uri #同 $uri$document_root #当前请求的文档根目录或别名$host #优先级：HTTP请求行的主机名&gt;&quot;HOST&quot;请求头字段&gt;符合请求的服务器名.请求中的主机头字段，如果请求中的主机头不可用，则为服务器处理请求的服务器名称$hostname #主机名$https #如果开启了SSL安全模式，值为&quot;on&quot;，否则为空字符串。$binary_remote_addr #客户端地址的二进制形式，固定长度为4个字节$body_bytes_sent #传输给客户端的字节数，响应头不计算在内；这个变量和Apache的mod_log_config模块中的&quot;%B&quot;参数保持兼容$bytes_sent #传输给客户端的字节数$connection #TCP连接的序列号$connection_requests #TCP连接当前的请求数量$content_length #&quot;Content-Length&quot; 请求头字段$content_type #&quot;Content-Type&quot; 请求头字段$cookie_name #cookie名称$limit_rate #用于设置响应的速度限制$msec #当前的Unix时间戳$nginx_version #nginx版本$pid #工作进程的PID$pipe #如果请求来自管道通信，值为&quot;p&quot;，否则为&quot;.&quot;$proxy_protocol_addr #获取代理访问服务器的客户端地址，如果是直接访问，该值为空字符串$realpath_root #当前请求的文档根目录或别名的真实路径，会将所有符号连接转换为真实路径$remote_addr #客户端地址$remote_port #客户端端口$remote_user #用于HTTP基础认证服务的用户名$request #代表客户端的请求地址$request_body #客户端的请求主体：此变量可在location中使用，将请求主体通过proxy_pass，fastcgi_pass，uwsgi_pass和scgi_pass传递给下一级的代理服务器$request_body_file #将客户端请求主体保存在临时文件中。文件处理结束后，此文件需删除。如果需要之一开启此功能，需要设置client_body_in_file_only。如果将次文件传 递给后端的代理服务器，需要禁用request body，即设置proxy_pass_request_body off，fastcgi_pass_request_body off，uwsgi_pass_request_body off，or scgi_pass_request_body off$request_completion #如果请求成功，值为&quot;OK&quot;，如果请求未完成或者请求不是一个范围请求的最后一部分，则为空$request_filename #当前连接请求的文件路径，由root或alias指令与URI请求生成$request_length #请求的长度 (包括请求的地址，http请求头和请求主体)$request_method #HTTP请求方法，通常为&quot;GET&quot;或&quot;POST&quot;$request_time #处理客户端请求使用的时间,单位为秒，精度毫秒； 从读入客户端的第一个字节开始，直到把最后一个字符发送给客户端后进行日志写入为止。$request_uri #这个变量等于包含一些客户端请求参数的原始URI，它无法修改，请查看$uri更改或重写URI，不包含主机名，例如：&quot;/cnphp/test.php?arg=freemouse&quot;$scheme #请求使用的Web协议，&quot;http&quot; 或 &quot;https&quot;$server_addr #服务器端地址，需要注意的是：为了避免访问linux系统内核，应将ip地址提前设置在配置文件中$server_name #服务器名$server_port #服务器端口$server_protocol #服务器的HTTP版本，通常为 &quot;HTTP/1.0&quot; 或 &quot;HTTP/1.1&quot;$status #HTTP响应代码$time_iso8601 #服务器时间的ISO 8610格式$time_local #服务器时间（LOG Format 格式）$cookie_NAME #客户端请求Header头中的cookie变量，前缀&quot;$cookie_&quot;加上cookie名称的变量，该变量的值即为cookie名称的值$http_NAME #匹配任意请求头字段；变量名中的后半部分NAME可以替换成任意请求头字段，如在配置文件中需要获取http请求头：&quot;Accept-Language&quot;，$http_accept_language即可$http_cookie$http_host #请求地址，即浏览器中你输入的地址（IP或域名）$http_referer #url跳转来源,用来记录从那个页面链接访问过来的$http_user_agent #用户终端浏览器等信息$http_x_forwarded_for$sent_http_NAME #可以设置任意http响应头字段；变量名中的后半部分NAME可以替换成任意响应头字段，如需要设置响应头Content-length，$sent_http_content_length即可$sent_http_cache_control$sent_http_connection$sent_http_content_type$sent_http_keep_alive$sent_http_last_modified$sent_http_location$sent_http_transfer_encoding proxy_pass的用法proxy_pass反向代理,主要用于请求的转发,先来看看常用的转发方式先配置一个简单的html服务器: 12345678910111213server{ listen 800; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } 123location /proxy1/{ proxy_pass http://localhost:800/; } 访问:http://localhost/proxy1/index.html，代理到 http://localhost:800/index.html 123location /proxy2/{ proxy_pass http://localhost:800; } 访问:http://localhost/proxy2/index.html，代理到 http://localhost:800/proxy2/index.html 123location /proxy3/{ proxy_pass http://localhost:800/web/; } 访问:http://localhost/proxy3/index.html，代理到 http://localhost:800/web/index.html 123location /proxy4/{ proxy_pass http://localhost:800/web; } 访问:http://localhost/proxy4/index.html，代理到 http://localhost:800/webindex.html 上面演示的只是简单的请求代理，一般我们还会用到较为高级一点的负载均衡，Nginx均衡策略有6种: 轮询：每个请求按顺序逐一分配到不同的后端服务器，如果后端服务器down掉，就不在分配； 1234upstream webapi { server 127.0.0.1:801 max_fails=5 fail_timeout=20; server 127.0.0.1:802 max_fails=5 fail_timeout=20; } 权重轮询：根据后端服务器性能不通配置轮询的权重比，权重越高访问的比重越高； 1234upstream webapi { server 127.0.0.1:801 weight=2 max_fails=5 fail_timeout=20; server 127.0.0.1:802 weight=6 max_fails=5 fail_timeout=20; } ip_hash：根据请求的ip地址hash结果进行分配，同一个IP的请求会落在同一个后端，可以解决Session同步的问题； 12345upstream webapi { ip_hash; server 127.0.0.1:801 max_fails=5 fail_timeout=20; server 127.0.0.1:802 max_fails=5 fail_timeout=20; } fair：按后端服务器的响应时间来分配请求，响应时间短的优先分配； 12345upstream webapi { fair; server 127.0.0.1:801 max_fails=5 fail_timeout=20; server 127.0.0.1:802 max_fails=5 fail_timeout=20; } url_hash：按访问url的hash结果来分配请求，使每个url落在同一个后端服务器，后端服务器为缓存时才用此种方式较妥。 12345upstream webapi { hash $request_uri； server 127.0.0.1:801 max_fails=5 fail_timeout=20; server 127.0.0.1:802 max_fails=5 fail_timeout=20; } least_conn:把请求转发给连接数较少的后端服务器 12345upstream webapi { least_conn; server 127.0.0.1:801 max_fails=5 fail_timeout=20; server 127.0.0.1:802 max_fails=5 fail_timeout=20; } 说明:在单位周期为fail_timeout设置的时间，中达到max_fails次数，这个周期次数内，如果后端同一个节点不可用，那么接将把节点标记为不可用，并等待下一个周期（同样时常为fail_timeout）再一次去请求，判断是否连接是否成功。默认：fail_timeout为10s,max_fails为1次。在做请求转发的时候，有时候可能会遇到端口丢失的情况,这时候就需要在location模块做如下配置: 1234proxy_set_header X-Forwarded-Host $host;proxy_set_header X-Forwarded-Server $host;proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;proxy_set_header Host $host:$server_port; #这里是重点,这样配置才不会丢失端口 Rewrite的用法Rewrite顾名思义，就是规则重写,主要功能是实现浏览器访问 Http URL的跳转，语法格式:rewrite &lt;正则表达式&gt; &lt;代替的内容&gt; &lt;重写类型&gt;;,重写类型有4种: last：本条规则匹配完成后，继续向下匹配新的location URI规则；浏览器地址栏URL地址不变；一般写在server和if中; break：本条规则匹配完成后，终止匹配，不再匹配后面的规则，浏览器地址栏URL地址不变；一般使用在location中； redirect：返回302临时重定向，浏览器地址会显示跳转后的URL地址； permanent：返回301永久重定向，浏览器地址栏会显示跳转后的URL地址；示例说明：1rewrite /rewrite.html /index.html last; 访问/rewrite.html的时候,页面内容重写到/index.html中，并继续匹配，浏览器URL地址不变 1rewrite /break.html /index.html break; 访问/break.html的时候,页面内容重写到/index.html中，并停止后续匹配，浏览器URL地址不变 1rewrite /redirect.html /index.html redirect; 访问/redirect.html的时候，页面直接302重定向到/index.html中，浏览器URL跳为index.html 1rewrite /permanent.html /index.html permanent; 访问/permanent.html的时候，页面直接301重定向到/index.html中，浏览器URL跳为index.html 1rewrite ^/html/(.+?).html$ /permanent/$1.html permanent; 把/html/*.html301重定向到/permanent/*.html 1rewrite ^/(.*) https://www.baidu.com/$1 permanent; 把当前域名的请求，重定向到新域名上，URL域名变化，域名后的路径不变，访问:http://localhost/s?wd=nginx%20rewrite%E8%AF%A6%E8%A7%A3&amp;rsv_spt=1&amp;rsv_iqid=0xd27651610002bd69&amp;issp=1&amp;f=3&amp;rsv_bp=1&amp;rsv_idx=2&amp;ie=utf-8&amp;rqlang=cn&amp;tn=baiduhome_pg&amp;rsv_enter=0&amp;rsv_dl=ts_0&amp;oq=nginx%25E4%25BB%25A3%25E7%2590%2586%25E7%25AB%25AF%25E5%258F%25A3%25E4%25B8%25A2%25E5%25A4%25B1&amp;inputT=2230&amp;rsv_t=3e937ZY1a4uEO2TEPB%2BcJfOX%2FgNXA%2B26nrz3bOXnJHZUv6OAhomZhXh74aAaaNCm3897&amp;rsv_pq=b9fe0f2a0000ae48&amp;rsv_sug3=127&amp;rsv_sug1=88&amp;rsv_sug7=100&amp;rsv_sug2=1&amp;prefixsug=nginx%2520Rewrite&amp;rsp=0&amp;rsv_sug4=2409, 地址会变为:https://www.baidu.com/s?wd=nginx%20rewrite%E8%AF%A6%E8%A7%A3&amp;rsv_spt=1&amp;rsv_iqid=0xd27651610002bd69&amp;issp=1&amp;f=3&amp;rsv_bp=1&amp;rsv_idx=2&amp;ie=utf-8&amp;rqlang=cn&amp;tn=baiduhome_pg&amp;rsv_enter=0&amp;rsv_dl=ts_0&amp;oq=nginx%25E4%25BB%25A3%25E7%2590%2586%25E7%25AB%25AF%25E5%258F%25A3%25E4%25B8%25A2%25E5%25A4%25B1&amp;inputT=2230&amp;rsv_t=3e937ZY1a4uEO2TEPB%2BcJfOX%2FgNXA%2B26nrz3bOXnJHZUv6OAhomZhXh74aAaaNCm3897&amp;rsv_pq=b9fe0f2a0000ae48&amp;rsv_sug3=127&amp;rsv_sug1=88&amp;rsv_sug7=100&amp;rsv_sug2=1&amp;prefixsug=nginx%2520Rewrite&amp;rsp=0&amp;rsv_sug4=2409","link":"/20191231/Nginx-Proxy-Pass%E5%92%8CRewirte%E7%9A%84%E7%94%A8%E6%B3%95.html"},{"title":"Golang基础学习总结之变量","text":"变量来源于数学，是计算机语言中能储存计算结果或能表示值抽象概念。变量可以通过变量名访问。Go 语言变量名由字母、数字、下划线组成，其中首个字符不能为数字。来源于https://www.runoob.com/go/go-variables.html Go语言定义变量有多种方式，下面我们来看看具体的示例var [变量名] [变量类型] = [值] 1var a int = 10 //定义变量并初始化值 也可以不赋值，如果未显示初始化值的时候，Go会自动为对应数据类型初始化一个默认值(零值)，: 1var a int //自动初始化零值 Go 语言中的零值大概有以下几种: 类型 零值 数值 0 布尔 false 字符串 “”(空字符串) slice nil map nil 指针 nil 函数 nil 接口 nil 信道 nil Go变量会根据初始值自动判断数据类型: 1var a = 10 简短定义: 1a := 10 多变量同类型定义: 12var a,b intvar a,b int = 0,1 多变量不同类型定义: 123456789101112var a ,b = 0,&quot;b&quot;var( a int b string )var( a int=0 b string=&quot;b&quot; )a ,b :=1,2 变量作用域,我理解的变量作用域有三种: 全局作用域 局部作用域 块级作用域 1234567891011121314151617package mainvar a=10 //全局作用域func main() { a := 9 //局部作用域 { a :=8 //块级作用域 println(a) } println(a) println(Get())}func Get() int { return a} 打印结果： 1238910 如有错误之处，敬请提建议，多谢。","link":"/20191210/Golang%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%E4%B9%8B%E5%8F%98%E9%87%8F.html"},{"title":"尚无已经注册的AppId，请先使用AccessTokenContainer.Register完成注册（全局执行一次即可）！模块：WeChat_OfficialAccount","text":"最近一个朋友在咨询我微信公众号推送消息的问题。因为我在17年的时候做了一年的微信公众号开发，自然有一丢丢经验，但是那时的服务端是用Spring Boot 开发的，这次是.net开发，而且时间也有点久了。所以在开发过程中遇到了一些问题。接下来，我就来和盆友们唠嗑唠嗑。 用.net开发公众号的各位盆友应该知道Senparc这个神器，其封装了微信公众号/小程序等接口，开箱即用。因为我在15年的时，使用ABP+Senparc开发了一个公众号网页，深感其带来的方便快捷。下面，我们进入正题吧。因为我不能进入到微信公众号后端，所以朋友就把AppId和AppSecret给我，然后就只有这么搞： 1234567891011121314151617181920212223242526272829303132333435363738394041424344var isGLobalDebug = true;//设置全局 Debug 状态var senparcSetting = SenparcSetting.BuildFromWebConfig(isGLobalDebug);var register = RegisterService.Start(senparcSetting).UseSenparcGlobal();//CO2NET全局注册，必须！var isWeixinDebug = true;//设置微信 Debug 状态var senparcWeixinSetting = SenparcWeixinSetting.BuildFromWebConfig(isWeixinDebug);senparcWeixinSetting.WeixinAppId = appId;senparcWeixinSetting.WeixinAppSecret = appSecret; register.UseSenparcWeixin(senparcWeixinSetting, senparcSetting).RegisterMpAccount(senparcWeixinSetting, &quot;【盛派网络小助手】公众号&quot;);//根据appId判断获取 if (!AccessTokenContainer.CheckRegistered(appId)) //检查是否已经注册 { AccessTokenContainer.RegisterAsync(appId, appSecret); //如果没有注册则进行注册 }string linkUrl = &quot;http://www.baidu.com&quot;; //点击详情后跳转后的链接地址，为空则不跳转 //为模版中的各属性赋值 var templateData = new{ first = new TemplateDataItem(&quot;您好，您的订单已支付成功！&quot;, &quot;#000000&quot;), product = new TemplateDataItem(&quot;旺旺大礼包&quot;, &quot;#000000&quot;), price = new TemplateDataItem(&quot;99.8元&quot;, &quot;#000000&quot;), time = new TemplateDataItem(&quot;2016-11-09 16:50:38&quot;, &quot;#000000&quot;), remark = new TemplateDataItem(&quot;感谢您的光临~&quot;, &quot;#000000&quot;)};string access_token = AccessTokenContainer.GetAccessToken(appId);SendTemplateMessageResult sendResult = TemplateApi.SendTemplateMessage(access_token, openId, templateId, linkUrl, templateData);//发送成功 if (sendResult.errcode.ToString() == &quot;请求成功&quot;){ Response.Write(&quot;请求成功&quot;);}else{ Response.Write(&quot;出现错误：&quot; + sendResult.errmsg);}Response.Write(&quot;ok&quot;); 肯定是我太菜，所以我就百度一番，顺手又改了几行代码: 12345678910111213141516171819202122232425262728293031323334var isGLobalDebug = true;//设置全局 Debug 状态var senparcSetting = SenparcSetting.BuildFromWebConfig(isGLobalDebug);var register = RegisterService.Start(senparcSetting).UseSenparcGlobal();//CO2NET全局注册，必须！var isWeixinDebug = true;//设置微信 Debug 状态var senparcWeixinSetting = SenparcWeixinSetting.BuildFromWebConfig(isWeixinDebug);register.UseSenparcWeixin(senparcWeixinSetting, senparcSetting); AccessTokenContainer.RegisterAsync(appId, appSecret); //如果没有注册则进行注册 string linkUrl = &quot;http://www.baidu.com&quot;; //点击详情后跳转后的链接地址，为空则不跳转 //为模版中的各属性赋值 var templateData = new{ first = new TemplateDataItem(&quot;您好，您的订单已支付成功！&quot;, &quot;#000000&quot;), product = new TemplateDataItem(&quot;旺旺大礼包&quot;, &quot;#000000&quot;), price = new TemplateDataItem(&quot;99.8元&quot;, &quot;#000000&quot;), time = new TemplateDataItem(&quot;2016-11-09 16:50:38&quot;, &quot;#000000&quot;), remark = new TemplateDataItem(&quot;感谢您的光临~&quot;, &quot;#000000&quot;)};string access_token = AccessTokenContainer.GetAccessToken(appId);SendTemplateMessageResult sendResult = TemplateApi.SendTemplateMessage(access_token, openId, templateId, linkUrl, templateData);//发送成功 if (sendResult.errcode.ToString() == &quot;请求成功&quot;){ Response.Write(&quot;请求成功&quot;);}else{ Response.Write(&quot;出现错误：&quot; + sendResult.errmsg);}Response.Write(&quot;ok&quot;); 但是还是报同样的错误，顿时绝望至极，我到底是又多菜啊？但是这个人虽然菜，可是也不是刚才说的那样脆弱，所以我就去Senparc的github看看。嗯可以看到Senparc非常友好的抛出这个错误，那么它是什么时候给我们抛出错误呢？这就要看看代码了: 123456789101112131415161718192021222324/// &lt;summary&gt;/// 获取凭证接口/// &lt;/summary&gt;/// &lt;param name=&quot;grant_type&quot;&gt;获取access_token填写client_credential&lt;/param&gt;/// &lt;param name=&quot;appid&quot;&gt;第三方用户唯一凭证&lt;/param&gt;/// &lt;param name=&quot;secret&quot;&gt;第三方用户唯一凭证密钥，既appsecret&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[ApiBind(NeuChar.PlatformType.WeChat_OfficialAccount, &quot;CommonApi.GetToken&quot;, true)]public static AccessTokenResult GetToken(string appid, string secret, string grant_type = &quot;client_credential&quot;){ //注意：此方法不能再使用ApiHandlerWapper.TryCommonApi()，否则会循环 var url = string.Format(Config.ApiMpHost + &quot;/cgi-bin/token?grant_type={0}&amp;appid={1}&amp;secret={2}&quot;, grant_type.AsUrlData(), appid.AsUrlData(), secret.AsUrlData()); AccessTokenResult result = Get.GetJson&lt;AccessTokenResult&gt;(url);//此处为最原始接口，不再使用重试获取的封装 if (Config.ThrownWhenJsonResultFaild &amp;&amp; result.errcode != ReturnCode.请求成功) { var unregisterAppIdEx = new UnRegisterAppIdException(null, $&quot;尚无已经注册的AppId，请先使用AccessTokenContainer.Register完成注册（全局执行一次即可）！模块：{NeuChar.PlatformType.WeChat_OfficialAccount}&quot;); throw unregisterAppIdEx;//抛出异常 } return result;} 就是说，只要不是成功状态，都是提示尚无已经注册的AppId，请先使用AccessTokenContainer.Register完成注册（全局执行一次即可）！模块：WeChat_OfficialAccount(我能说这样有点坑吗？),那么我猜想应该是调用接口出错了，那么就看看是怎么请求的接口呢？继续看代码吧: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/// &lt;summary&gt; /// 获取可用Token /// &lt;/summary&gt; /// &lt;param name=&quot;appId&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;getNewToken&quot;&gt;是否强制重新获取新的Token&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static string GetAccessToken(string appId, bool getNewToken = false) { return GetAccessTokenResult(appId, getNewToken).access_token; } /// &lt;summary&gt; /// 获取可用AccessTokenResult对象 /// &lt;/summary&gt; /// &lt;param name=&quot;appId&quot;&gt;&lt;/param&gt; /// &lt;param name=&quot;getNewToken&quot;&gt;是否强制重新获取新的Token&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static AccessTokenResult GetAccessTokenResult(string appId, bool getNewToken = false) { if (!BaseContainer&lt;AccessTokenBag&gt;.CheckRegistered(appId)) { throw new UnRegisterAppIdException(appId, $&quot;此appId（{appId}）尚未注册，请先使用AccessTokenContainer.Register完成注册（全局执行一次即可）！&quot;, null); } AccessTokenBag accessTokenBag = BaseContainer&lt;AccessTokenBag&gt;.TryGetItem(appId); using (BaseContainer&lt;AccessTokenBag&gt;.Cache.BeginCacheLock(&quot;MP.AccessTokenContainer&quot;, appId, 0, default(TimeSpan))) { if (getNewToken || accessTokenBag.AccessTokenExpireTime &lt;= SystemTime.Now) { accessTokenBag.AccessTokenResult = CommonApi.GetToken(accessTokenBag.AppId, accessTokenBag.AppSecret, &quot;client_credential&quot;); accessTokenBag.AccessTokenExpireTime = ApiUtility.GetExpireTime(accessTokenBag.AccessTokenResult.expires_in); BaseContainer&lt;AccessTokenBag&gt;.Update(accessTokenBag, null); } } return accessTokenBag.AccessTokenResult; } public class CommonApi { /// &lt;summary&gt; /// 获取凭证接口 /// &lt;/summary&gt; /// &lt;param name=&quot;grant_type&quot;&gt;获取access_token填写client_credential&lt;/param&gt; /// &lt;param name=&quot;appid&quot;&gt;第三方用户唯一凭证&lt;/param&gt; /// &lt;param name=&quot;secret&quot;&gt;第三方用户唯一凭证密钥，既appsecret&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [ApiBind(Senparc.NeuChar.PlatformType.WeChat_OfficialAccount, &quot;CommonApi.GetToken&quot;, true)] public static AccessTokenResult GetToken(string appid, string secret, string grant_type = &quot;client_credential&quot;) { AccessTokenResult json = Get.GetJson&lt;AccessTokenResult&gt;(string.Format(Config.ApiMpHost + &quot;/cgi-bin/token?grant_type={0}&amp;appid={1}&amp;secret={2}&quot;, grant_type.AsUrlData(), appid.AsUrlData(), secret.AsUrlData()), null, null); if (Config.ThrownWhenJsonResultFaild &amp;&amp; json.errcode != 0) { throw new UnRegisterAppIdException(null, $&quot;尚无已经注册的AppId，请先使用AccessTokenContainer.Register完成注册（全局执行一次即可）！模块：{Senparc.NeuChar.PlatformType.WeChat_OfficialAccount}&quot;, null); } return json; } } 根据代码我我就拼接了一个http的地址,直接在浏览器访问，得到了这样的结果: 1{&quot;errcode&quot;:40164,&quot;errmsg&quot;:&quot;invalid ip 183.221.39.24 ipv6 ::ffff:183.221.39.24, not in whitelist hint: [uBiTIa01561501]&quot;} 一看就知道，请求地址没有加入到白名单里面，所以我让朋友去登录公众平台，开发-&gt;基本配置-&gt;IP白名单-&gt;查看-&gt;修改-&gt;将IP地址添加进去,最后，OK了。","link":"/20200106/Senparc-appid-not-register.html"},{"title":"Nginx为同主机配置Https多域名","text":"前面，我有提到nginx多网站配置，以及nginx配置https.但是在windows下面同主机配置多Https域名暂未提及，那么这次正好遇到这个场景。我就把他记录下来 前言最近在做一个私活，因为老板考虑到节约成本，就只有一台2核4G的windows主机，可是现在是要独立出来多个微信小程序，故会涉及到多个应用。当然我也以才用nginx强大的location配置功能转发到不同的目录这也是可以实现的。但是感觉不是很优雅，所以还是使用强大的Server模块吧。我们来看看官网介绍http://nginx.org/en/docs/http/configuring_https_servers.html,官方文档也是很详细的 下载Nginxwindows使用nginx很简单，直接下载官方编译好的即可(如果自己来编译的话,操作还是有些繁琐).下载nginx的zip压缩包，如果想使用nginx+lua的话，那么就去下载OpenResty吧。 配置Nginx首先肯定是去域名注册商去下载nginx的SSL证书，然后把我们的证书放在nginx的conf目录下。接下来就是编辑我们的nginx.conf配置文件。配置如下: 123456789101112131415161718192021222324252627282930313233server { listen 443 ssl; server_name xxxxx.baoqipai.com; ssl_certificate cert/xxxxx.baoqipai.com.pem; ssl_certificate_key cert/xxxxx.baoqipai.com.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://127.0.0.1:8002; } } server { listen 443 ssl; server_name admin.xxxxx.nationallab.cn; ssl_certificate cert/admin.xxxxx.nationallab.cn.pem; ssl_certificate_key cert/admin.xxxxx.nationallab.cn.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://127.0.0.1:8001; } } server { listen 443 ssl; server_name host.xxxxx.nationallab.cn; ssl_certificate cert/host.xxxxx.nationallab.cn.pem; ssl_certificate_key cert/host.xxxxx.nationallab.cn.key; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers HIGH:!aNULL:!MD5; location / { proxy_pass http://127.0.0.1:8001; } } 启动nginx，解析域名，此时不出意外应该可以正常访问了。 遇到的问题这里有个会有一个小问题,会报could not build server_names_hash, you should increase server_names_hash_bucket_size: 32,这是因为server配置中server_name的值过长导致，http://nginx.org/en/docs/http/server_names.html提到修改server_names_hash_bucket_size的值: http { server_names_hash_bucket_size 64; …那么server_names_hash_bucket_size的默认值是多少呢？在官网文档中有提到: 123Syntax: server_names_hash_bucket_size size;Default: server_names_hash_bucket_size 32|64|128;Context: http Sets the bucket size for the server names hash tables. The default value depends on the size of the processor’s cache line. The details of setting up hash tables are provided in a separate document.","link":"/20191216/Nginx%E4%B8%BA%E7%BD%91%E7%AB%99%E9%85%8D%E7%BD%AEHttps.html"},{"title":"Nginx二级域名转发到不同端口/服务器","text":"有时候，我们资源有限，那么就会遇到一台主机对应1-N个域名，那么就会出现主机80端口占用完了，其他应用就只能占用其他的端口了，但是如果在域名后面带上端口号(如www.xxxx.com:8080 ),这显然很不优雅,而且像开发微信的时候，配置的域名只能使用80端口。那么有没有更好的处理方式能让我们不在域名后添加端口号呢？答案是肯定是，这里我们可以借助强大的Nginx来帮我们解决这个问题。 Nginx通过二级目录方式我们知道Nginx location强大的匹配模式，那么我们就可以通过location来匹配请求目录从而在内部转发到不同的端口/服务器。当然也可以使用Nginx+Lua(openresty、tengine)来判断请求参数也可以处理.但是现在我暂时还是才用的Nginx自身的一些API来实现. 1234567891011121314151617181920server { listen 443 ssl; server_name localhost; location / { root html; index index.html index.htm; } location /api/ { proxy_pass http://xxx.xxx.xxx.xx:8000/api/; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } 这时候，我们通过www.xxx.com/api 就可以转发到 http://xxx.xxx.xxx.xx:8000/api ,这里还有可以设置更高端的，比如才用Nginx Rewrite等。 Nginx匹配二级域名进行代理多个server模块通过server_name匹配代理server_name 是虚拟服务器的识别路径，不同的域名请求会带上相应的HOST请求头来匹配Nginx的server模块 12345678910111213141516171819202122232425262728293031323334353637383940414243server { listen 80; server_name www.cddj.top; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 80; server_name www.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html1; index index.html index.htm; } } server { listen 80; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html2; index index.html index.htm; } } 我们可以看到访问不同的域名就转到了不同的server模块,这里只是简单是静态显示，我们可以再server模块中做转发,例如: 1234567891011121314151617181920server { listen 80; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://localhost:8000/; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } } 多个server同端口的匹配规则是:完全匹配-&gt;通配符在前(如.biz)-&gt;通配符在后(如52fx.)-&gt;正则匹配(~^.52fx.biz$),如果都没匹配到就找默认server，如果还是匹配不到则去匹配端口的第一个server 一个server模块通过IF指令判断转发到不同端口/服务器可以借助Nginx if指令判断$host中的域名来转发到不同的端口: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { if ($host = &quot;www.cddj.top&quot;) { proxy_pass http://localhost:801; } if ($host = &quot;www.51offer.wang&quot;) { proxy_pass http://localhost:802; } if ($host = &quot;sub.51offer.wang&quot;) { proxy_pass http://localhost:803; } } }server { listen 801; server_name www.cddj.top; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } }server { listen 802; server_name www.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html1; index index.html index.htm; } }server { listen 803; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html2; index index.html index.htm; } } 结果和上面的图片一样，这里就不追加了。 Nginx+Lua我们可以借助Nginx+Lua来判断转发，这里也暂时就不说明，有兴趣的 可以自己去查找资料，在使用Lua的时候需要自行下载Nginx源码加Lua模块编译进去，或者使用openresty、tengine这种已经集成好的工具，个人比较喜欢openresty,因为社区相对比较活跃，有很多强大的插件如waf等。 修改配置后记得刷新配置哟 12nginx -t #验证配置文件nginx -s reload 刷新配置文件 如果有更方便快捷且强大的方式，请加我QQ告知我哟！！！","link":"/20191128/Nginx-domain-configuration.html"},{"title":"Spring Boot 常用注解汇总","text":"Spring Boot是越来越火了也主要是因为其注解给我们带来了莫大的帮助，使我们开发更加的快速便捷，所以，我们有必要简单的整理一下工作中常用的注解命令。 @SpringBootApplication:作用在主类上，标识该应用为Spring Boot 应用,为应用赋能。 12345678@SpringBootApplicationpublic class DemoApplication { public static void main(String[] args) { SpringApplication.run(DemoApplication.class, args); }} 在spring-boot-autoconfigure中，我们可以看到@SpringBootApplication包含了@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan三个注解： 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })public @interface SpringBootApplication {} @Configuration:该注解用于标识该类为一个配置类，作用于类，相当于配置文件如： 1234&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-2.0.xsd&quot; default-autowire=&quot;byName&quot;&gt; &lt;bean id=&quot;dmsDataSecurityRuleService&quot; class=&quot;xxxx.xx.datasecurity.service.DmsDataSecurityRuleService&quot;/&gt; &lt;bean id=&quot;dmsDataSecurityRuleAction&quot; class=&quot;xxxx.xx.datasecurity.web.DmsDataSecurityRuleAction&quot;/&gt;&lt;/beans&gt; @Bean:该注解主要作用于方法，作用是将该方法放回的类实例注入到IOC容器中.默认取方法名为对象bean id，可以使用@Bean注解设置属性值来指定bean id。 12345678910111213141516171819202122232425@Configuration //标识为配置类@EnableSwagger2@EnableSwaggerBootstrapUi@Import(BeanValidatorPluginsConfiguration.class)public class SwaggerConfiguration { @Bean(&quot;createRestApi&quot;) //指定bean id public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo( new ApiInfoBuilder() //页面标题 .title(&quot;Demo Web Api文档&quot;) //创建人 .contact(new Contact(&quot;eyiadmin&quot;, &quot;https://springfox.github.io/springfox/&quot;, &quot;eyiadmin@163.com&quot;)) .version(&quot;1.0&quot;) .description(&quot;Demo Web Api文档&quot;) .build()) .select() //API接口所在的包位置 .apis(RequestHandlerSelectors.basePackage(&quot;com.eyiadmin.demo.controller&quot;)) .paths(PathSelectors.any()) .build(); }} @Scope:该注解作用于类方法，用于指定bean的作用域，默认为单例： prototype：每次从IOC容器中取出对象都是重新创建Bean实例 singleton：整个应用IOC容器中只有一个Bean实例 request：同一个http请求创建一个Bean实例 session：同一个Session会话创建一个Bean实例 @EnableAutoConfiguration:允许 Spring Boot 自动配置注解，开启这个注解之后，Spring Boot 就能根据当前类路径&gt;下的包或者类来配置 Spring Bean。如：当前类路径下有 Mybatis 这个 JAR 包，MybatisAutoConfiguration 注解就能根据相&gt;关参数来配置 Mybatis 的各个 Spring Bean。 @SpringBootConfiguration:这个注解就是 @Configuration 注解的变体，只是用来修饰是 Spring Boot 配置而已，或&gt;者可利于 Spring Boot 后续的扩展。 @ComponentScan:该注解用来代替配置文件中的 component-scan 配置，开启&gt;组件扫描，相当于context:component-scan，如果扫描到有@Component @Controller @Service等这些注解的类，则把这些类注册为Bean @Component:该注解是将普通pojo实例化到spring容器中，相当于XML中的，一般加在主类上。 @AutoWired:该注解是将注入到的bean实例取出来，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到bean也不报错。 @RestController:该注解相当于@Controller、@ResponseBody两个注解的结合,我们可以再github查看源码https://github.com/spring-projects/spring-framework/blob/master/spring-web/src/main/java/org/springframework/web/bind/annotation/RestController.java: 1234567891011121314151617@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Controller@ResponseBodypublic @interface RestController { /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) * @since 4.0.1 */ @AliasFor(annotation = Controller.class) String value() default &quot;&quot;;} controller相关注解在https://github.com/spring-projects/spring-framework/tree/master/spring-web/src/main/java/org/springframework/web/bind/annotation能找到。 @Controller:该注解主要作用于类上，标识该类为一个控制器，在对应的类上加上该注解，视图解析器可以解析return 的jsp,html页面，并且跳转到相应页面。 @ResponseBody:表示该方法的返回结果直接写入HTTP response body中一般在异步获取数据时使用，在使用@RequestMapping后，返回值通常解析为跳转路径，加上@responsebody后返回结果不会被解析为跳转路径，而是直接写入HTTP response body中。比如异步获取json数据，加上@responsebody后，会直接返回json数据。 @RequestMapping:该注解会将 HTTP 请求映射到 MVC 和 REST 控制器的处理方法上,看源码: 1234567891011121314151617181920212223242526272829303132@Target({ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Documented@Mappingpublic @interface RequestMapping { String name() default &quot;&quot;; @AliasFor(&quot;path&quot;) String[] value() default {}; @AliasFor(&quot;value&quot;) String[] path() default {}; RequestMethod[] method() default {}; String[] params() default {}; String[] headers() default {}; String[] consumes() default {}; String[] produces() default {};}RequestMethod是一个枚举类型:public enum RequestMethod { GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS, TRACE} 使用时需要执行value和method参数,如:@RequestMapping(value = &quot;hello/{name}&quot;, method= RequestMethod.GET). @GetMapping:该注解将HTTP GET请求映射到指定处理程序: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documented@RequestMapping(method = RequestMethod.GET)public @interface GetMapping { /** * Alias for {@link RequestMapping#name}. */ @AliasFor(annotation = RequestMapping.class) String name() default &quot;&quot;; /** * Alias for {@link RequestMapping#value}. */ @AliasFor(annotation = RequestMapping.class) String[] value() default {}; /** * Alias for {@link RequestMapping#path}. */ @AliasFor(annotation = RequestMapping.class) String[] path() default {}; /** * Alias for {@link RequestMapping#params}. */ @AliasFor(annotation = RequestMapping.class) String[] params() default {}; /** * Alias for {@link RequestMapping#headers}. */ @AliasFor(annotation = RequestMapping.class) String[] headers() default {}; /** * Alias for {@link RequestMapping#consumes}. * @since 4.3.5 */ @AliasFor(annotation = RequestMapping.class) String[] consumes() default {}; /** * Alias for {@link RequestMapping#produces}. */ @AliasFor(annotation = RequestMapping.class) String[] produces() default {};} 我在源码中可以看到@RequestMapping(method = RequestMethod.GET)这句代码,组合了@RequestMapping注解并指定了GET请求方式,一般使用@GetMapping注解时，指定其value属性即可,如:@GetMapping(value = &quot;/name&quot;),等价于上面的@RequestMapping(value = &quot;hello/{name}&quot;, method= RequestMethod.GET)。除了@GetMapping,还有@PostMapping、@PutMapping、@DeleteMapping等，也是才用类似的方式，就不一一说明了。 @PathVariable:该注解用于获取url中占位符的数据，如： 1234567@RequestMapping(value = &quot;hello/{name}&quot;, method= RequestMethod.GET) public ResponseEntity&lt;String&gt; Hello( @PathVariable String name) { return new ResponseEntity&lt;&gt;(String.format(&quot;Hello %s!&quot;,name), HttpStatus.OK); }请求格式:http://localhost:8080/demo/hello/jane @RequestParam:该注解主要用于获取url中的请求参数,如: 1234567@RequestMapping(value = &quot;baby&quot;, method= RequestMethod.GET) public ResponseEntity&lt;String&gt; Baby( @RequestParam String name) { return new ResponseEntity&lt;&gt;(String.format(&quot;Hello, %s Baby!&quot;,name), HttpStatus.OK); }请求格式:http://localhost:8080/demo/baby?name=Jane @RequestBody:该注解用于接收HTTP的Body的内容并序列化为接受类型的对象，可接受复杂嵌套的内容，默认是使用JSON的格式。 还有@RequestHeader、@CookieValue等，大家自己去查阅相关文档吧 @Value:该注解主要作用于字段属性，用于属性取值: @value(“值”),如:@value(&quot;农民工&quot;); @Value(“#{}”) 表示SpEl表达式通常用来获取bean的属性，或者调用bean的某个方法,如:@Value(&quot;#{12*2}&quot;); @Value(“${xxxx}”)注解从配置文件读取值,如:@Value(&quot;${datasource.url}&quot;); 一般我们要取配置文件内容，还会配合@ConfigurationProperties一起使用,主要是用于指定配置文件中的指定 属性与该Bean绑定,如:@ConfigurationProperties(&quot;datasource&quot;) @Repository:该注解用于标注数据访问组件(DAO),作用于类,https://github.com/spring-projects/spring-framework/blob/master/spring-context/src/main/java/org/springframework/stereotype/Repository.java: 123456789101112131415@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Repository { /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;} @Service:该注解用于标识用业务层组件,作用于类,源码如下: 123456789101112131415@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface Service { /** * The value may indicate a suggestion for a logical component name, * to be turned into a Spring bean in case of an autodetected component. * @return the suggested component name, if any (or empty String otherwise) */ @AliasFor(annotation = Component.class) String value() default &quot;&quot;;} value值作为Bean id,我们可以为Service指定Bean id,如:@Service(&quot;serviceBeanId&quot;) @PropertySource:该注解用于导入properties配置文件,如:@PropertySource(value = {&quot;classpath : path/application.properties&quot;})，多配置文件在{}中意逗号(,)隔开。 @ImportResource:该注解用于导入xml配置文件,支持相对路径和绝对路径,代码如下： 1234567891011121314@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)@Documentedpublic @interface ImportResource { @AliasFor(&quot;locations&quot;) String[] value() default {}; @AliasFor(&quot;value&quot;) String[] locations() default {}; Class&lt;? extends BeanDefinitionReader&gt; reader() default BeanDefinitionReader.class;} @ControllerAdvice:该注解主要用于统一处理异常，作用于类，组合了@Component注解,源码如下： 12345678910111213141516171819@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface ControllerAdvice { @AliasFor(&quot;basePackages&quot;) String[] value() default {}; @AliasFor(&quot;value&quot;) String[] basePackages() default {}; Class&lt;?&gt;[] basePackageClasses() default {}; Class&lt;?&gt;[] assignableTypes() default {}; Class&lt;? extends Annotation&gt;[] annotations() default {};} 用法如下: 12345@ControllerAdvicepublic class GlobalExceptionHandler { } @ExceptionHandler:该注解声明异常处理方法，作用于方法上,例如: 1234@ExceptionHandler(Exception.class)String catchException(){ return &quot;&quot;;} 当触发Exception会执行catchException方法。 目前能想到的大概就这些，后面有新发现再补充吧。 [参考]终于有人总结Spring Boot最常用的25个注解，干货了解一下！","link":"/20191216/Spring-Boot-%E5%B8%B8%E7%94%A8%E6%B3%A8%E8%A7%A3%E6%B1%87%E6%80%BB.html"},{"title":"Spring Boot使用log4j2记录日志","text":"日志可以帮我们在开发过程中乃至于生产上快速有效的定位问题的好帮手，所以如何记录有效的日子变得更加重要，在Spring Boot中，已经为我们默认添加了logback和log4j2,默认情况下，Spring Boot采用的是logback。关于日志组件的性能，我并没有亲自验证过，只是在logback log4j log4j2 性能实测中说log4j2性能是最高的。 这里咱们就选用log4j2来作为我们的日志组件,由于默认是使用的logback ,所以在使用之前需要排除掉，并且引入log4j2,pom.xml配置如下: 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt;&lt;!-- 去掉springboot默认配置 --&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--log4j2--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j2&lt;/artifactId&gt; &lt;/dependency&gt; 在spring-boot-starter-log4j2中，我们可以看到依赖包: 1234567891011121314151617181920212223242526&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;2.12.1&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;2.12.1&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-jul&lt;/artifactId&gt; &lt;version&gt;2.12.1&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.29&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 接下来，我们正式开始启用吧,首先在resources目录下新建一个log4j2.xml配置文件，配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!--日志级别以及优先级排序: OFF &gt; FATAL &gt; ERROR &gt; WARN &gt; INFO &gt; DEBUG &gt; TRACE &gt; ALL --&gt;&lt;!--status=&quot;WARN&quot; :用于设置log4j2自身内部日志的信息输出级别，默认是OFF--&gt;&lt;!--monitorInterval=&quot;30&quot; :间隔秒数,自动检测配置文件的变更和重新配置本身--&gt;&lt;configuration status=&quot;WARN&quot; monitorInterval=&quot;30&quot;&gt; &lt;Properties&gt; &lt;!--自定义一些常量，之后使用${变量名}引用--&gt; &lt;Property name=&quot;logFilePath&quot;&gt;D://log&lt;/Property&gt; &lt;Property name=&quot;logFileName&quot;&gt;test.log&lt;/Property&gt; &lt;Property name=&quot;logPattern&quot;&gt; %d{yyyy-MM-dd HH:mm:ss.SSS} %5p %l ${hostName} -&amp;#45;&amp;#45; [%15.15t] %-40.40c{1.} : %m%n%ex &lt;/Property&gt; &lt;/Properties&gt; &lt;!--appenders:定义输出内容,输出格式,输出方式,日志保存策略等,常用其下三种标签[console,File,RollingFile]--&gt; &lt;appenders&gt; &lt;!--console :控制台输出的配置--&gt; &lt;console name=&quot;Console&quot; target=&quot;SYSTEM_OUT&quot;&gt; &lt;!--PatternLayout :输出日志的格式,LOG4J2定义了输出代码,详见第二部分--&gt; &lt;PatternLayout pattern=&quot;${logPattern}&quot;/&gt; &lt;/console&gt; &lt;!--File :同步输出日志到本地文件--&gt; &lt;!--append=&quot;false&quot; :根据其下日志策略,每次清空文件重新输入日志,可用于测试--&gt;&lt;!-- &lt;File name=&quot;log&quot; fileName=&quot;${logFilePath}/logs/info.log&quot; append=&quot;false&quot;&gt;--&gt;&lt;!-- &lt;PatternLayout pattern=&quot;%d{HH:mm:ss.SSS} %-5level %class{36} %L %M - %msg%xEx%n&quot;/&gt;--&gt;&lt;!-- &lt;/File&gt;--&gt; &lt;!--SMTP :邮件发送日志--&gt;&lt;!-- &lt;SMTP name=&quot;Mail&quot; subject=&quot;****SaaS系统正式版异常信息&quot; to=&quot;message@message.info&quot; from=&quot;message@lengjing.info&quot; smtpUsername=&quot;message@message.info&quot; smtpPassword=&quot;LENG****1234&quot; smtpHost=&quot;mail.lengjing.info&quot; smtpDebug=&quot;false&quot; smtpPort=&quot;25&quot; bufferSize=&quot;10&quot;&gt;--&gt;&lt;!-- &lt;PatternLayout pattern=&quot;[%-5p]:%d{YYYY-MM-dd HH:mm:ss} [%t] %c{1}:%L - %msg%n&quot; /&gt;--&gt;&lt;!-- &lt;/SMTP&gt;--&gt; &lt;!-- ${sys:user.home} :项目路径 --&gt; &lt;RollingFile name=&quot;RollingFileInfo&quot; fileName=&quot;${logFilePath}/logs/info.log&quot; filePattern=&quot;${logFilePath}/logs/$${date:yyyy-MM}/info-%d{yyyy-MM-dd}-%i.log&quot;&gt; &lt;!--ThresholdFilter :日志输出过滤--&gt; &lt;!--level=&quot;info&quot; :日志级别,onMatch=&quot;ACCEPT&quot; :级别在info之上则接受,onMismatch=&quot;DENY&quot; :级别在info之下则拒绝--&gt; &lt;ThresholdFilter level=&quot;info&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n&quot;/&gt; &lt;!-- Policies :日志滚动策略--&gt; &lt;Policies&gt; &lt;!-- TimeBasedTriggeringPolicy :时间滚动策略,默认0点小时产生新的文件,interval=&quot;6&quot; : 自定义文件滚动时间间隔,每隔6小时产生新文件, modulate=&quot;true&quot; : 产生文件是否以0点偏移时间,即6点,12点,18点,0点--&gt; &lt;TimeBasedTriggeringPolicy interval=&quot;6&quot; modulate=&quot;true&quot;/&gt; &lt;!-- SizeBasedTriggeringPolicy :文件大小滚动策略--&gt; &lt;SizeBasedTriggeringPolicy size=&quot;100 MB&quot;/&gt; &lt;/Policies&gt; &lt;!-- DefaultRolloverStrategy属性如不设置，则默认为最多同一文件夹下7个文件，这里设置了20 --&gt; &lt;DefaultRolloverStrategy max=&quot;20&quot;/&gt; &lt;/RollingFile&gt; &lt;RollingFile name=&quot;RollingFileWarn&quot; fileName=&quot;${logFilePath}/logs/warn.log&quot; filePattern=&quot;${logFilePath}/logs/$${date:yyyy-MM}/warn-%d{yyyy-MM-dd}-%i.log&quot;&gt; &lt;ThresholdFilter level=&quot;warn&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n&quot;/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;100 MB&quot;/&gt; &lt;/Policies&gt; &lt;/RollingFile&gt; &lt;RollingFile name=&quot;RollingFileError&quot; fileName=&quot;${logFilePath}/logs/error.log&quot; filePattern=&quot;${logFilePath}/logs/$${date:yyyy-MM}/error-%d{yyyy-MM-dd}-%i.log&quot;&gt; &lt;ThresholdFilter level=&quot;error&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;PatternLayout pattern=&quot;[%d{HH:mm:ss:SSS}] [%p] - %l - %m%n&quot;/&gt; &lt;Policies&gt; &lt;TimeBasedTriggeringPolicy/&gt; &lt;SizeBasedTriggeringPolicy size=&quot;100 MB&quot;/&gt; &lt;/Policies&gt; &lt;/RollingFile&gt; &lt;/appenders&gt; &lt;!--然后定义logger，只有定义了logger并引入的appender，appender才会生效--&gt; &lt;loggers&gt; &lt;!--过滤掉spring和mybatis的一些无用的DEBUG信息--&gt; &lt;!--Logger节点用来单独指定日志的形式，name为包路径,比如要为org.springframework包下所有日志指定为INFO级别等。 --&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;INFO&quot;&gt;&lt;/logger&gt; &lt;logger name=&quot;org.mybatis&quot; level=&quot;INFO&quot;&gt;&lt;/logger&gt; &lt;!-- Root节点用来指定项目的根日志，如果没有单独指定Logger，那么就会默认使用该Root日志输出 --&gt; &lt;Root level=&quot;ALL&quot;&gt; &lt;appender-ref ref=&quot;Console&quot;/&gt; &lt;appender-ref ref=&quot;RollingFileInfo&quot;/&gt; &lt;appender-ref ref=&quot;RollingFileWarn&quot;/&gt; &lt;appender-ref ref=&quot;RollingFileError&quot;/&gt; &lt;/Root&gt; &lt;!--AsyncLogger :异步日志,LOG4J有三种日志模式,全异步日志,混合模式,同步日志,性能从高到底,线程越多效率越高,也可以避免日志卡死线程情况发生--&gt; &lt;!--additivity=&quot;false&quot; : additivity设置事件是否在root logger输出，为了避免重复输出，可以在Logger 标签下设置additivity为”false”--&gt;&lt;!-- &lt;AsyncLogger name=&quot;AsyncLogger&quot; level=&quot;ALL&quot; includeLocation=&quot;true&quot; additivity=&quot;false&quot;&gt;--&gt;&lt;!-- &lt;appender-ref ref=&quot;RollingFileError&quot;/&gt;--&gt;&lt;!-- &lt;appender-ref ref=&quot;RollingFileInfo&quot;/&gt;--&gt;&lt;!-- &lt;/AsyncLogger&gt;--&gt; &lt;/loggers&gt;&lt;/configuration&gt; 以上配置类源于LOG4J2 完整配置详解,在代码中: 123456789101112131415161718192021222324protected void loadDefaults(LoggingInitializationContext initializationContext, LogFile logFile) { if (logFile != null) { loadConfiguration(getPackagedConfigFile(&quot;log4j2-file.xml&quot;), logFile); } else { loadConfiguration(getPackagedConfigFile(&quot;log4j2.xml&quot;), logFile); } } @Override protected String[] getStandardConfigLocations() { return getCurrentlySupportedConfigLocations(); }private String[] getCurrentlySupportedConfigLocations() { List&lt;String&gt; supportedConfigLocations = new ArrayList&lt;&gt;(); supportedConfigLocations.add(&quot;log4j2.properties&quot;); if (isClassAvailable(&quot;com.fasterxml.jackson.dataformat.yaml.YAMLParser&quot;)) { Collections.addAll(supportedConfigLocations, &quot;log4j2.yaml&quot;, &quot;log4j2.yml&quot;); } if (isClassAvailable(&quot;com.fasterxml.jackson.databind.ObjectMapper&quot;)) { Collections.addAll(supportedConfigLocations, &quot;log4j2.json&quot;, &quot;log4j2.jsn&quot;); } supportedConfigLocations.add(&quot;log4j2.xml&quot;); return StringUtils.toStringArray(supportedConfigLocations); } 大概可以看出Spring Boot是可以自动识别log4j2.xml或者log4j2.yaml等配置文件,当然，如果是其他命名方式，可以在application.properties配置文件中配置,如:logging.config=classpath:log4j2-config.xml,yaml配置类似。接下来就是在我们的程序中使用， 123456789101112@RequestMapping(&quot;/exception&quot;)@RestController@Api(tags = &quot;制造bug&quot;)public class ExceptionController { private static final Logger logger = LogManager.getLogger(ExceptionController.class); @GetMapping(&quot;err&quot;) public String getErr(){ logger.info(&quot;制造一个bug&quot;); int calc= 1/0; return &quot;error&quot;; }} 调用结果: 122019-12-25 09:49:31.199 DEBUG springfox.documentation.spring.web.PropertySourcedRequestMappingHandlerMapping.lookupHandlerMethod(PropertySourcedRequestMappingHandlerMapping.java:108) 2CNU7X5OLAUE004 --- [nio-8080-exec-1] pertySourcedRequestMappingHandlerMapping : looking up handler for path: /exception/err2019-12-25 09:49:31.205 INFO com.eyiadmin.demo.controller.ExceptionController.getErr(ExceptionController.java:17) 2CNU7X5OLAUE004 --- [nio-8080-exec-1] c.e.d.c.ExceptionController : 制造一个bug 这样一来，我们就可以在之前说的GlobalExceptionHandler来记录我们的错误日志了, 12345678910111213141516171819202122@RestControllerAdvicepublic class GlobalExceptionHandler { private static final Logger logger = LogManager.getLogger(GlobalExceptionHandler.class); @ExceptionHandler(BindException.class) public ResponseResult&lt;?&gt; handleValidationException(BindException ex) { BindingResult validResult = ex.getBindingResult(); if (validResult.hasErrors()) { logger.error(validResult.getAllErrors().stream().map(err-&gt;err.getDefaultMessage()).collect(Collectors.joining(&quot;|&quot;))); return ResponseResult.error(validResult.getAllErrors().get(0).getDefaultMessage()); } else { return ResponseResult.error(&quot;操作失败&quot;); } } //捕捉所有Exception异常，这里可以捕捉自定义的业务异常 @ExceptionHandler(Exception.class) ResponseResult&lt;?&gt; handleException(Exception ex){ logger.error(ex.getMessage()); logger.error(ex.getStackTrace()); return ResponseResult.error(ex.getMessage()); }} 最后效果: 12019-12-25 10:14:38.086 ERROR com.eyiadmin.demo.handler.GlobalExceptionHandler.handleValidationException(GlobalExceptionHandler.java:21) 2CNU7X5OLAUE004 --- [nio-8080-exec-2] c.e.d.h.GlobalExceptionHandler : 学生名字不能为空 至此， log4j2.xml整合完毕,但是我们的工作还没有完，我们在需要记录日志的每个类文件都要写一个private static final Logger logger = LogManager.getLogger(GlobalExceptionHandler.class);,虽然工作量不大，但有时候可能会马虎的忽视掉GlobalExceptionHandler.class，那么我们有没有更简便的使用方式呢？这里我们可以借助强大的Lombok插件为我们提供好的@Log4j2注解，在需要打印日志的类上加上这个注解即可。 12345@Retention(RetentionPolicy.SOURCE)@Target({ElementType.TYPE})public @interface Log4j2 { String topic() default &quot;&quot;;} 我们可以看到@Log4j2有一个参数，它用于标识我们记录器的类别，默认情况下，它会将使用注解的类型，接下来我们来尝试一下: 12345678910111213141516171819202122@RestControllerAdvice@Log4j2public class GlobalExceptionHandler { @ExceptionHandler(BindException.class) public ResponseResult&lt;?&gt; handleValidationException(BindException ex) { BindingResult validResult = ex.getBindingResult(); if (validResult.hasErrors()) { log.error(validResult.getAllErrors().stream().map(err-&gt;err.getDefaultMessage()).collect(Collectors.joining(&quot;|&quot;))); return ResponseResult.error(validResult.getAllErrors().get(0).getDefaultMessage()); } else { return ResponseResult.error(&quot;操作失败&quot;); } } //捕捉所有Exception异常，这里可以捕捉自定义的业务异常 @ExceptionHandler(Exception.class) ResponseResult&lt;?&gt; handleException(Exception ex){ log.error(ex.getMessage()); log.error(ex.getStackTrace()); return ResponseResult.error(ex.getMessage()); }} 最后打印的日志如下: 12019-12-25 10:21:33.684 ERROR com.eyiadmin.demo.handler.GlobalExceptionHandler.handleValidationException(GlobalExceptionHandler.java:22) 2CNU7X5OLAUE004 --- [nio-8080-exec-1] c.e.d.h.GlobalExceptionHandler : 学生名字不能为空 如果我们给@Log4j2带上topic会输出什么呢？: 12345678910111213@RequestMapping(&quot;/exception&quot;)@RestController@Api(tags = &quot;制造bug&quot;)@Log4j2(topic = &quot;exception&quot;)public class ExceptionController { @GetMapping(&quot;err&quot;) public String getErr(){ log.info(&quot;制造一个bug&quot;); int calc= 1/0; return &quot;error&quot;; }} 效果: 12019-12-25 10:22:57.078 INFO com.eyiadmin.demo.controller.ExceptionController.getErr(ExceptionController.java:19) 2CNU7X5OLAUE004 --- [nio-8080-exec-3] exception : 制造一个bug 这里只是简单的说了一下日志组件的使用，我们在实际使用过程中，也会结合AOP来应用。以及在分布式、微服务中的链路追踪，","link":"/20191225/Spring-Boot%E6%97%A5%E5%BF%97%E8%AE%B0%E5%BD%95.html"},{"title":"Spring Boot统一异常处理","text":"异常可以说像大宝一样天天见，一不小心就可能写了一个bug.不过有异常不可怕，可怕是出了问题连异常的都没有，一般情况下，我们也都是try catch的方式在程序里面捕捉，但是这样有时候可能一疏忽，连try catch都忘了写，这时候如果出现问题，就比较尴尬了，所以，我们需要更加方便、优雅的全局异常处理的方式来优化我们的异常捕捉机制。 Spring Boot默认的异常处理方式这里，我们先看看Spring Boot在我们 程序出现异常的时候，是怎么给我们的提示的。首先，我们得制造一个bug，这是我们最擅长的： 1234567891011@RequestMapping(&quot;/exception&quot;)@RestController@Api(tags = &quot;制造bug&quot;)public class ExceptionController { @GetMapping(&quot;err&quot;) public String getErr(){ int calc= 1/0; return &quot;error&quot;; }} 如果通过丝袜哥来调用我们的接口的话，它已经很体贴的帮我们处理了一下:可是Spring Boot可就没有丝袜哥那么贴心了:这样一来，我们得告诉一下Spring Boot，让他也给我们带来贴心的服务，这时候就要提到两个注解:@RestControllerAdvice和@ExceptionHandler。 浅析注解我们先来看看@RestControllerAdvice和@ExceptionHandler的代码: 12345678910111213141516171819202122232425262728293031@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@ControllerAdvice@ResponseBodypublic @interface RestControllerAdvice { @AliasFor( annotation = ControllerAdvice.class ) String[] value() default {}; @AliasFor( annotation = ControllerAdvice.class ) String[] basePackages() default {}; @AliasFor( annotation = ControllerAdvice.class ) Class&lt;?&gt;[] basePackageClasses() default {}; @AliasFor( annotation = ControllerAdvice.class ) Class&lt;?&gt;[] assignableTypes() default {}; @AliasFor( annotation = ControllerAdvice.class ) Class&lt;? extends Annotation&gt;[] annotations() default {};} 可以看到@RestControllerAdvice注解继承了@ResponseBody和@ControllerAdvice注解， 1234567891011121314151617@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Componentpublic @interface ControllerAdvice { @AliasFor(&quot;basePackages&quot;) String[] value() default {}; @AliasFor(&quot;value&quot;) String[] basePackages() default {}; Class&lt;?&gt;[] basePackageClasses() default {}; Class&lt;?&gt;[] assignableTypes() default {}; Class&lt;? extends Annotation&gt;[] annotations() default {};} @ControllerAdvice注解又继承了@Component注解,那么在类上使用@RestControllerAdvice就会自动被扫描注册到容器中,并且输出json格式. 123456@Target({ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface ExceptionHandler { Class&lt;? extends Throwable&gt;[] value() default {};} @ExceptionHandler的参数是一个继承了Throwable的类,比如:Exception等，也可以自定义Exception类。 统一返回封装开发Web Api的时候，返回的数据格式肯定都是固定的，所以，这里需要一个统一的返回格式类: 123456789101112131415161718192021222324252627@Datapublic class ResponseResult&lt;T&gt; { //描述 private String msg; //状态码 private int code; //数据 private T data; public ResponseResult(int code, String msg, T data) { this.msg = msg; this.code = code; this.data = data; } public static ResponseResult&lt;String&gt; success() { return success(null); } public static &lt;T&gt; ResponseResult&lt;T&gt; success(T data) { return new ResponseResult&lt;T&gt;(200, &quot;请求成功&quot;, data); } public static &lt;T&gt; ResponseResult&lt;T&gt; error(String msg) { return new ResponseResult&lt;T&gt;(500, msg, null); }} 统一异常处理我们新建一个GlobalExceptionHandler类，用于处理全局异常. 123456789@RestControllerAdvicepublic class GlobalExceptionHandler { //捕捉所有Exception异常，这里可以捕捉自定义的业务异常 @ExceptionHandler(Exception.class) ResponseResult&lt;?&gt; handleException(Exception ex){ return ResponseResult.error(ex.getMessage()); }} 可以看到GlobalExceptionHandler已经为我们处理了Exception异常，在之前的参数校验中，我们也可以这里统一处理: 123456789@ExceptionHandler(BindException.class) public ResponseResult&lt;?&gt; handleValidationException(BindException ex) { BindingResult validResult = ex.getBindingResult(); if (validResult.hasErrors()) { return ResponseResult.error(validResult.getAllErrors().get(0).getDefaultMessage()); } else { return ResponseResult.error(&quot;操作失败&quot;); } } 使用统一处理后，我们的Controller就更加简洁了: 12345678910@RequestMapping(&quot;/v1/student&quot;)@RestController@Api(tags = &quot;Student API展示&quot;)public class StudentController { @PostMapping(&quot;/CreateStudent&quot;) public ResponseResult&lt;?&gt; CreateStudent(@Valid StudentVO studentVO) { return ResponseResult.success(); }} 小插曲如果在@ExceptionHandler(BindException.class)捕捉的过程中没有进入到这个异常处理方法中，那么可以debug查看@ExceptionHandler(Exception.class)捕捉到的是哪个Exception，再针对这个Exception进行异常处理。","link":"/20191223/Spring-Boot%E7%BB%9F%E4%B8%80%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86.html"},{"title":"Spring Boot集成Swagger","text":"大部分人应该都知道Swagger是帮我们的Web API快速生成接口文档，前面我们也有提到.Net Core3.x集成Swagger，这里，我们再来归纳一下Spring Boot集成Swagger的常规操作 创建一个Spring Boot项目创建Spring Boot应用的方式有很多，如：直接访问spring提供的项目生成工具https://start.spring.io/、或者Idea里面的Spring Initializr模块创建等等。这里我们就直接通过Idea工具来创建，创建完成后，就是maven自动安装包了。 集成Swagger首先，我们需要引入引入jar包: 123456789101112&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; 配置Swagger 新建一个SwaggerConfiguration类，添加注解@Configuration、@EnableSwagger21234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo( new ApiInfoBuilder() //页面标题 .title(&quot;Demo Web Api文档&quot;) //创建人 .contact(new Contact(&quot;eyiadmin&quot;, &quot;https://springfox.github.io/springfox/&quot;, &quot;eyiadmin@163.com&quot;)) .version(&quot;1.0&quot;) .description(&quot;Demo Web Api文档&quot;) .build()) .select() //API接口所在的包位置 .apis(RequestHandlerSelectors.basePackage(&quot;com.eyiadmin.demo.controller&quot;)) .paths(PathSelectors.any()) .build(); }} 配置Controller:123456789101112@Api(tags = {&quot;Swagger Demo API展示&quot;})@RequestMapping(&quot;/demo&quot;)@RestControllerpublic class DemoController { @ApiOperation(value = &quot;示例&quot;, notes = &quot;通过名字打个招呼&quot;) @RequestMapping(value = &quot;hello/{name}&quot;, method= RequestMethod.GET) public ResponseEntity&lt;String&gt; Hello(@ApiParam(value = &quot;用户姓名&quot;,required = true) @PathVariable String name) { return new ResponseEntity&lt;&gt;(String.format(&quot;Hello %s!&quot;,name), HttpStatus.OK); }} 启动起来，访问localhost:8080/swagger-ui.html，还是那个熟悉的界面: 使用Swagger增强版knife4j-spring-ui在https://gitee.com/xiaoym/knife4j提供了swagger-bootstrap-ui,界面相对来说更加美观,也可以导出md文档，同时可以借助其他工具转成pdf等文档我们把修改一下pom.xml文件，将swagger替换成knife4j: 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt; &lt;/dependency&gt; 修改配置类: 1234@Configuration@EnableSwagger2@EnableSwaggerBootstrapUi@Import(BeanValidatorPluginsConfiguration.class) 启动Spring Boot，访问localhost:8080/doc.html：至此，Spring Boot集成Swagger暂时告一段落,下面，我会整理一些Swagger 常用注解. @Api一般作用于Controller类,标识类作用说明 1234参数说明:* tags=&quot;说明该类的作用&quot;* value=&quot;可不配置&quot;@Api(tags = {&quot;Swagger Demo API展示&quot;}) @ApiOperation一般作用于方法，标识说明该方法的作用 1234参数说明: * value=&quot;方法描述&quot; * notes=&quot;备注说明&quot;@ApiOperation(value = &quot;方法描述&quot;, notes = &quot;备注说明&quot;) @ApiParam作用于方法，解释方法中的参数说明 1public ResponseEntity&lt;String&gt; Hello(@ApiParam(value = &quot;参数名称&quot;,required = true) @PathVariable String name) @ApiModel作用于VO类,解释说明类 1@ApiModel(&quot;例如说明&quot;) @ApiModelProperty作用于字段属性,为VO类属性解释说明 12@ApiModelProperty(&quot;用户名&quot;) private String userName;","link":"/20191206/Spring-Boot-Swagger.html"},{"title":"Spring Boot 自定义Validation注解","text":"在项目开发过程中，注解给我们带来方便、快捷的极简编程体验，前面也有记录了一些常用的注解命令，可见注解是比较常用且重要的功能，有时候validation自带的注解可能不能满足我们的个性化需要时，我们能不能根据自己的情况自定义注解命令呢? 源码浅析我们先来看看常用的@Min注解，学习一下它是如何实现的，先看源码: 12345678910111213141516171819202122232425262728293031@Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })@Retention(RUNTIME)@Repeatable(List.class)@Documented@Constraint(validatedBy = { })public @interface Min { String message() default &quot;{javax.validation.constraints.Min.message}&quot;; Class&lt;?&gt;[] groups() default { }; Class&lt;? extends Payload&gt;[] payload() default { }; /** * @return value the element must be higher or equal to */ long value(); /** * Defines several {@link Min} annotations on the same element. * * @see Min */ @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE }) @Retention(RUNTIME) @Documented @interface List { Min[] value(); }} @Target 注解的作用范围，参数是一个枚举类型: 123456789101112131415161718192021222324252627282930313233343536373839 public enum ElementType { /** 类、接口或者是枚举 */ TYPE, /** 字段属性 */ FIELD, /** 方法 */ METHOD, /** 参数 */ PARAMETER, /** 构造方法 */ CONSTRUCTOR, /** 局部变量 */ LOCAL_VARIABLE, /** 注解类型 如：@interface修饰的类型 */ ANNOTATION_TYPE, /** 包 */ PACKAGE, /** * Type parameter declaration * * @since 1.8 */ TYPE_PARAMETER, /** * Use of a type * * @since 1.8 */ TYPE_USE} @Retention用于声明注解的声明周期，也是一个枚举类型： 123456789101112131415161718192021 public enum RetentionPolicy { /** * Annotations are to be discarded by the compiler. 注解是保留在源代码中,编译时丢弃 */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior.代码保留在class文件中，加载到JVM虚拟机时丢弃 */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * 保留在程序运行期间，此时可以通过反射获得定义在某个类上的所有注解 * @see java.lang.reflect.AnnotatedElement */ RUNTIME} @Repeatable注解表明标记的注解可以多次应用于相同的声明或类型 @Documented注解会被javadoc之类的工具处理, 所以注解类型信息也会被包括在生成的文档中.默认情况下javadoc是不包括注解的 @Constraint注解限定自定义注解的方法，指定自定义的处理类。 自定义注解刚才简单介绍了一下Spring给我们带来的注解的定义方式，接下来就依样画葫芦来实现自定义Validation注解。首先新建一个Phone注解: 123456789101112@Target({FIELD })@Retention(RUNTIME)@Documented@Constraint(validatedBy = {PhoneConstraintValidator.class})public @interface Phone { String message() default &quot;手机号错误&quot;; Class&lt;?&gt;[] groups() default {}; Class&lt;? extends Payload&gt;[] payload() default {};} 再创建一个Validator校验类,用于Phone @Constraint指定的处理校验类: 123456789101112131415161718public class PhoneConstraintValidator implements ConstraintValidator&lt;Phone,String&gt; { @Override public boolean isValid(String value, ConstraintValidatorContext context) { return isMobile(value); } private boolean isMobile(String source) { Pattern pattern = null; Matcher matcher = null; String reg=&quot;^[1](([3|5|8][\\\\d])|([4][4,5,6,7,8,9])|([6][2,5,6,7])|([7][^9])|([9][1,8,9]))[\\\\d]{8}$&quot;;// 验证手机号 if(!StringUtils.isEmpty(source)){ pattern = Pattern.compile(reg); matcher = pattern.matcher(source); return matcher.matches(); } return false; }} 现在就可以在使用我们自定义的注解: 12345678910111213141516171819202122@ApiModel(&quot;StudentVO&quot;)@Datapublic class StudentVO { @NotEmpty(message =&quot;学生名字不能为空&quot;) @ApiModelProperty(&quot;学生名字&quot;) private String name; @Range(min = 5, max = 30, message = &quot;学生年龄不能大于30岁或者小于5岁&quot;) @ApiModelProperty(&quot;学生年龄&quot;) private Integer age; @NotEmpty(message =&quot;学生住址不能为空&quot;) @ApiModelProperty(&quot;学生住址&quot;) private String address; @NotBlank(message = &quot;手机号必填&quot;) @Phone(message = &quot;号码不正确&quot;) @ApiModelProperty(&quot;手机号&quot;) private String PhoneNo;} 自定义Validation就暂时告一段落，后面，我们再来总结一下其他实用注解的定义方法。","link":"/20191222/Spring-Boot%E8%87%AA%E5%AE%9A%E4%B9%89%E6%B3%A8%E8%A7%A3.html"},{"title":"Linux中inode引起的故障","text":"inode是什么？ ETL脚本调度故障今日一大早，用户群就炸了，很多人说脚本调度无法运行，一直是未开始状态，起初，我并未引起重视，猜想可能是pieline服务阻塞引起的，由于情况紧急，就直接进入到tomcat manager进行reload操作，但是奇怪的是，reload之后，大批量的作业都直接终止掉，查看日志，发现是ETL脚本日志创建失败， 遂想到，肯定是文件系统占满，就开始rm一部分，然后，df -h，发现还有160+G，以为问题就解决掉了，但是没过多久，依然有很多未开始的作业。 df -i 解围因为对linux使用不是很熟，也只会ps -ef、cd、kill等常用命令，在百度中得知一个命令df -i，执行命令后，发现使用率100%，原来，真正的原因是：etl工具每天产生的小文件过多，把inode占满，导致工具无法创建日志文件。既然找到原因，当然就只有找到目录，将历史文件给rm掉 df的用法df命令一般用于查看磁盘空间大小，du -sh 查看当前目录使用大小。df -h 大文件占用大量的磁盘容量。df -i 过多的文件占用了大量的inode号。 [参考]linux命令df中df -h和df -i的区别","link":"/20191024/Linux%E4%B8%ADinode%E5%BC%95%E8%B5%B7%E7%9A%84%E6%95%85%E9%9A%9C.html"},{"title":"Spring Boot基于javax.validation进行参数校验","text":"在我们使用Spring Boot开发Web Api的时候，肯定会少不了参数校验，一般情况下，大部分是使用if来判断参数是否合法，在参数较少的情况下，这样做除了少量的重复工作外，也没有较大的工作量。但是当遇到一个复杂的参数的时候，可能整个方法大部分的代码都是if。工作量大不说，代码也精简。那么有没有更好的方式来处理呢？这就是我们这里要说到的参数校验技巧。 为了体现说明，我们事先创建好一个StudentVO类和一个StudentController.在StudentVO中加入几个简单的属性，仅做展示： 1234567891011121314151617import io.swagger.annotations.ApiModel;import io.swagger.annotations.ApiModelProperty;import lombok.Data;@ApiModel(&quot;StudentVO&quot;)@Datapublic class StudentVO { @ApiModelProperty(&quot;学生名字&quot;) private String name; @ApiModelProperty(&quot;学生年龄&quot;) private Integer age; @ApiModelProperty(&quot;学生住址&quot;) private String address;} 这里@ApiModelProperty和@ApiModel注解是我用了Swagger,你们可以直接写注释即可。为了减少Getter、Setter的工作量，我们引入了lombok工具包: 1234567&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; 这里需要注意的是，需要给IDE安装插件，因为我是用的IDEA所以插件安装很方便：Settings-&gt;Plugins,搜索lombok插件点击Install即可，安装完成后有个Restart IDE的按钮,点击重启即可。接下来，我们来进入示例环节,开始编码: 12345678910111213141516@RequestMapping(&quot;/v1/student&quot;)@RestController@Api(value = &quot;Student API展示&quot;)public class StudentController { @PostMapping(&quot;/CreateStudent&quot;) public ResponseEntity&lt;String&gt; CreateStudent(StudentVO studentVO) { if(StringUtils.isEmpty(studentVO.getName())) return new ResponseEntity&lt;&gt;(&quot;学生名字不能为空&quot;, HttpStatus.OK); if(studentVO.getAge()&gt;=5&amp;&amp;studentVO.getAge()&lt;=30) return new ResponseEntity&lt;&gt;(&quot;学生年龄不能大于30岁或者小于5岁&quot;, HttpStatus.OK); if(StringUtils.isEmpty(studentVO.getName())) return new ResponseEntity&lt;&gt;(&quot;学生住址不能为空&quot;, HttpStatus.OK); return new ResponseEntity&lt;&gt;(&quot;Success&quot;, HttpStatus.OK); }} 可以看到，目前这个vo类只有三个属性，在我们的action中也写了许多的用于校验的if,我们来看一下效果:当我们的属性有几十个的时候，还继续使用if来检验参数，确实是一件比较痛苦的事情，成了完全的手工活，而且还有可能会出错，为了提高我们的开发效率，自然得让一个工具来解决这个参数校验的问题，在我使用的Spring Boot2.2.1中已经为我们引入了javax.validation: 1234567&lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;${javax-validation.version}&lt;/version&gt; &lt;/dependency&gt;&lt;javax-validation.version&gt;2.0.1.Final&lt;/javax-validation.version&gt; 那么我们就可以直接使用validation-api,在使用之前，我们需要先熟悉几个注解: @AssertFalse 用于boolean字段，只能为true @AssertFalse 用于boolean字段，只能为false @DecimalMax（value=x）验证注解的元素值小于等于指定的value值 @DecimalMin（value=x）验证注解的元素值大于等于指定的value值 @Digits(integer=整数位数, fraction=小数位数) 验证注解的元素值必须是数值 @Email 验证注解的元素值是电子邮件地址 @Future(integer=整数位数, fraction=小数位数) 验证注解的元素值（日期类型）比当前时间晚 @FutureOrPresent(integer=整数位数, fraction=小数位数)验证注解的元素值（日期类型）比当前时间晚或者等于当前时间 @Past 验证注解的元素值（日期类型）比当前时间早 @ScriptAssert(lang= ,script=, alias=) @URL(protocol=,host=, port=,regexp=, flags=) URL验证 @PastOrPresent验证注解的元素值（日期类型）比当前时间早或等于现在 @Max（value=x）验证注解的元素值小于等于指定的value值 @Mix（value=x）验证注解的元素值大于等于指定的value值 @NotBlank 验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank只应用于字符串且在比较时会去除字符串的空格 @NotEmpty 验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0） @NotNull 验证注解的元素值不是null @CreditCardNumber 信用卡验证 @Null 验证注解的元素值是null @Pattern(regex=正则表达式, flag=) 验证注解的元素值与指定的正则表达式匹配 @Size(min=最小值, max=最大值) 验证注解的元素值的在min和max（包含）指定区间之内，如字符长度、集合大小我们就可以参照这些注解来校验参数:12345678910111213141516@ApiModel(&quot;StudentVO&quot;)@Datapublic class StudentVO { @NotEmpty(message =&quot;学生名字不能为空&quot;) @ApiModelProperty(&quot;学生名字&quot;) private String name; @Range(min = 5, max = 30, message = &quot;学生年龄不能大于30岁或者小于5岁&quot;) @ApiModelProperty(&quot;学生年龄&quot;) private Integer age; @NotEmpty(message =&quot;学生住址不能为空&quot;) @ApiModelProperty(&quot;学生住址&quot;) private String address;} 修改StudentController:12345678910111213141516171819@RequestMapping(&quot;/v1/student&quot;)@RestController@Api(value = &quot;Student API展示&quot;)public class StudentController { @PostMapping(&quot;/CreateStudent&quot;) public ResponseEntity&lt;String&gt; CreateStudent(@Valid StudentVO studentVO, BindingResult validResult) { if(validResult.hasErrors()) return new ResponseEntity&lt;&gt;(validResult.getAllErrors().get(0).getDefaultMessage(), HttpStatus.OK);// if(StringUtils.isEmpty(studentVO.getName()))// return new ResponseEntity&lt;&gt;(&quot;学生名字不能为空&quot;, HttpStatus.OK);// if(studentVO.getAge()&gt;=5&amp;&amp;studentVO.getAge()&lt;=30)// return new ResponseEntity&lt;&gt;(&quot;学生年龄不能大于30岁或者小于5岁&quot;, HttpStatus.OK);// if(StringUtils.isEmpty(studentVO.getName()))// return new ResponseEntity&lt;&gt;(&quot;学生住址不能为空&quot;, HttpStatus.OK); return new ResponseEntity&lt;&gt;(&quot;Success&quot;, HttpStatus.OK); }} 最后效果","link":"/20191220/Spring-Boot%E5%8F%82%E6%95%B0%E6%A0%A1%E9%AA%8C%E6%8A%80%E5%B7%A7.html"},{"title":"Vue制作静态页面简历并发布到七牛云上","text":"一般情况下，我们使用word可以写出漂亮的简历。但是我们是程序员，就应该用程序员的方式来做–使用网页写简历。当然，网页简历的方式就很多了，这里我们就用vue来搞定这个事，因为它灵活、高效、方便。 Vue插件和UI框架比较丰富，我们这里就借助elementui来帮助我们快速完成网页.大家可以先去Element官方查看相应的文档。 ElementUI快速上手安装ElementUI和相应的插件 12cnpm i element-ui -Scnpm install babel-plugin-component -D main.js文件引入ElementUI: 123456789101112131415import Vue from &apos;vue&apos;import App from &apos;./App&apos;import router from &apos;./router&apos;import ElementUI from &apos;element-ui&apos;;import &apos;element-ui/lib/theme-chalk/index.css&apos;;Vue.use(ElementUI); # 完整引入Vue.config.productionTip = false/* eslint-disable no-new */new Vue({ el: &apos;#app&apos;, router, components: { App }, template: &apos;&lt;App/&gt;&apos;}) 在.babelrc配置babel-plugin-component，我们借助 babel-plugin-component来实现按需引入，以达到减小项目体积的目的 12345678910111213141516171819{ &quot;presets&quot;: [ [&quot;env&quot;, { &quot;modules&quot;: false, &quot;targets&quot;: { &quot;browsers&quot;: [&quot;&gt; 1%&quot;, &quot;last 2 versions&quot;, &quot;not ie &lt;= 8&quot;] } }], &quot;stage-2&quot; ], &quot;plugins&quot;: [&quot;transform-vue-jsx&quot;, &quot;transform-runtime&quot;, [ &quot;component&quot;, { &quot;libraryName&quot;: &quot;element-ui&quot;, &quot;styleLibraryName&quot;: &quot;theme-chalk&quot; } ]]} 現在我們就可以註冊我們需要的組件， 123456789101112131415import Vue from &apos;vue&apos;;import { Button, Select } from &apos;element-ui&apos;;import App from &apos;./App.vue&apos;;Vue.component(Button.name, Button);Vue.component(Select.name, Select);/* 或写为 * Vue.use(Button) * Vue.use(Select) */new Vue({ el: &apos;#app&apos;, render: h =&gt; h(App)}); 我新建了几个组件， 结构如下：将我们的组件注册到router中: 1234567891011121314151617181920212223242526272829import About from &apos;@/components/about/About&apos;import Skill from &apos;@/components/skill/Index&apos;import Index from &apos;@/components/index/Index&apos;import His from &apos;@/components/history/Index&apos;Vue.use(Router)export default new Router({ routes: [ { path: &apos;/&apos;, name: &apos;Index&apos;, component: Index }, { path:&apos;/about&apos;, name:&apos;About&apos;, component:About },{ path:&apos;/skill&apos;, name:&apos;skill&apos;, component:Skill },{ path:&apos;/his&apos;, name:&apos;his&apos;, component:His } ]}) 在首页用到了Element 的layout布局，App.vue做了如下修改: 123456789101112131415161718192021222324252627&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;el-container&gt; &lt;el-header&gt; &lt;Header&gt;&lt;/Header&gt; &lt;/el-header&gt; &lt;el-main&gt; &lt;router-view /&gt; &lt;/el-main&gt; &lt;el-footer&gt; &lt;Footer&gt;&lt;/Footer&gt; &lt;/el-footer&gt; &lt;/el-container&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import Footer from &quot;@/components/footer/Footer&quot;;import Header from &quot;@/components/header/Header&quot;;export default { components: { Footer, Header }, name: &quot;App&quot;};&lt;/script&gt; 在Header.vue中用到了el-menu： 1234567891011121314151617181920212223&lt;template&gt; &lt;el-menu :default-active=&quot;activeIndex&quot; class=&quot;el-menu-demo&quot; :router=&quot;true&quot; mode=&quot;horizontal&quot; &gt; &lt;el-menu-item index=&quot;/&quot;&gt;首页&lt;/el-menu-item&gt; &lt;el-menu-item index=&quot;/about&quot;&gt;个人简介&lt;/el-menu-item&gt; &lt;el-menu-item index=&quot;/skill&quot;&gt;个人技能&lt;/el-menu-item&gt; &lt;el-menu-item index=&quot;/his&quot;&gt;工作经历&lt;/el-menu-item&gt; &lt;/el-menu&gt;&lt;/template&gt;&lt;script&gt;export default { name: &apos;Header&apos;, data () { return { activeIndex: &apos;/&apos; } }}&lt;/script&gt; 这里的组件代码来源于Vue+Element实现网页版个人简历系统.接下来编译成静态页面: 1npm run build 我之前有把博客上传到七牛云的文章，大家可以去看看。这里我只简单的走个流程: 1qshell qupload2 --overwrite=true --rescan-local=true --src-dir=E:\\vue\\myresume\\dist --bucket=eyiadminresume 之前也有说到将命令写入到package.json中: 1&quot;build&quot;: &quot;node build/build.js &amp; qshell qupload2 --overwrite=true --rescan-local=true --src-dir=E:/vue/myresume/dist --bucket=eyiadminresume&quot; 这样在执行npm run build的时候，会先执行node build/build.js然后会执行qshell qupload2上传到七牛云.关于qshell的详细教程请访问https://github.com/qiniu/qshell。上传完成后，我们就需要解析到我们的域名上resume.52fx.biz个人简历我会不定期更新，如有疑问可以加我QQ详聊188781475","link":"/20200102/Vue%E5%88%B6%E4%BD%9C%E9%9D%99%E6%80%81%E9%A1%B5%E9%9D%A2%E7%AE%80%E5%8E%86%E5%B9%B6%E5%8F%91%E5%B8%83%E5%88%B0%E4%B8%83%E7%89%9B%E4%BA%91%E4%B8%8A.html"},{"title":"展示一下Github的常规操作","text":"一般情况下，大部分人会自己使用Gitlab搭建一个私有的Git服务器，但是有时候为了避免麻烦，也可以使用诸如：Gitee,Github等免费的Git服务器来托管代码，这里个人使用的是Github 初始化项目Github账号注册很简单，这里就不说了。我们来看看怎么创建项目，登录到Github之后，右上角会有一个加号，从这里来new repository创建一个新repository这里public(公开项目),private(私有项目)都是免费的，根据个人情况选择常见完成后，会有操作提示，可以使用git clone到本地或者直接下载。这里我们还是使用git init来初始化一个项目吧 1234561. 先创建一个存放项目的文件夹，随意创建一个文件，通过cmd命令行cd到该目录开始执行命令2. git init #初始化仓库3. git add * #添加所有文件到暂存区4. git commit -m &quot;仓库初始化&quot; #此次的提交注释说明,并提交到本地仓库5. git remote add origin https://github.com/eyiadmin/demo.git # 与远程仓库建立关联关系6. git push -u origin master # 提交到远程仓库 常用命令 git add 文件名 添加单个文件到暂存区 git add -A 添加当前目录所有文件到暂存区 git add . 添加当前变更文件到暂存区 git commit -m '说明' 提交暂存区文件到本地仓库 git commit 文件名 -m '说明' 单个文件提交到本地仓库 git fetch 拉取代码 git pull 拉取最新内容并合并到当前分支 git pull origin develop 拉取具体的远程分支 git push origin master 提交到具体的远程分支,如果不存在会自动创建本地同名的远程分支 git checkout 分支名称 切换本地分支 git checkout origin/分支名称 切换远程分支 git checkout -b 新分支名称 基于本地分支新建新分支 git branch -d 分支名称 删除分支 git branch -M 旧分支名称 新分支名称 移动或者重命名分支 git checkout --track origin/分支名称 基于远程分支创建本地分支，并跟踪对应来自 ‘origin’ 的远程分支 git merge --no-ff 分支名称 保留合并分支的提交记录 git remote add origin 仓库地址 建立远程连接 git remote set-url origin 仓库地址 修改推送源 git reset --soft HEAD~1 软回滚到上一个版本 简单的代码提交流程 git status 查看仓库的状态 git add . 提交代码到暂存区 git commit -m &quot;提交内容说明&quot; 将暂存区代码提交到本地仓库 git pull 提交之前从远程拉取项目更新,git diff 对比内容，一般使用GUI查看 git push origin 分支名称 提交到指定分区 Git回滚到指定版本 git log 查看记录获取commit_sha1 git reset ---hard commit_sha1 硬回滚,抛弃回滚之后的内容,git reset ---soft commit_sha1 软回滚 未完待续","link":"/20191205/github-routine-operation.html"},{"title":".Net Core3.x使用NLog记录日志","text":"在.net core中，常用的日志组件大概就是Logging(自带)、Log4net和NLog等，其他的我目前还没有用到。我觉得NLog简单易用，性能也不错,支持多种日志写入方式。 安装NLog首先，我们通过Nuget安装NLog和NLog.Web.AspNetCore两个组件，我安装的版本是： 创建NLog配置文件在web目录新建一个nlog.config文件，内容 如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot; ?&gt;&lt;nlog xmlns=&quot;http://www.nlog-project.org/schemas/NLog.xsd&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; autoReload=&quot;true&quot; internalLogLevel=&quot;Info&quot; internalLogFile=&quot;logs\\internal-nlog.txt&quot;&gt; &lt;!-- enable asp.net core layout renderers --&gt; &lt;extensions&gt; &lt;add assembly=&quot;NLog.Web.AspNetCore&quot;/&gt; &lt;/extensions&gt; &lt;!-- the targets to write to --&gt; &lt;targets&gt; &lt;!-- write logs to file --&gt; &lt;target xsi:type=&quot;File&quot; name=&quot;allfile&quot; fileName=&quot;logs\\nlog-all-${shortdate}.log&quot; layout=&quot;${longdate}|${event-properties:item=EventId_Id}|${threadid}|${activityid}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}&quot; maxArchiveFiles=&quot;4&quot; archiveAboveSize=&quot;10240&quot; archiveEvery=&quot;Day&quot;/&gt; &lt;!-- another file log, only own logs. Uses some ASP.NET core renderers --&gt; &lt;target xsi:type=&quot;File&quot; name=&quot;ownFile-web&quot; fileName=&quot;logs\\nlog-own-${shortdate}.log&quot; layout=&quot;${longdate}|${event-properties:item=EventId_Id}|threadid-${threadid}|activityid-${activityid}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}&quot; maxArchiveFiles=&quot;4&quot; archiveAboveSize=&quot;10240&quot; archiveEvery=&quot;Day&quot;/&gt; &lt;target name=&quot;file&quot; xsi:type=&quot;AsyncWrapper&quot; queueLimit=&quot;5000&quot; overflowAction=&quot;Discard&quot;&gt; &lt;target xsi:type=&quot;File&quot; fileName=&quot;${basedir}/logs/${level}.txt&quot; keepFileOpen=&quot;true&quot; layout=&quot;${longdate}|${event-properties:item=EventId_Id}|threadid-${threadid}|activityid-${activityid}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action}&quot; maxArchiveFiles=&quot;4&quot; archiveAboveSize=&quot;10240&quot; archiveEvery=&quot;Day&quot;/&gt; &lt;/target&gt; &lt;/targets&gt; &lt;!-- rules to map from logger name to target --&gt; &lt;rules&gt; &lt;!--All logs, including from Microsoft--&gt; &lt;logger name=&quot;*&quot; minlevel=&quot;Trace&quot; writeTo=&quot;allfile&quot; /&gt; &lt;!--Skip non-critical Microsoft logs and so log only own logs--&gt; &lt;logger name=&quot;Microsoft.*&quot; maxlevel=&quot;Info&quot; final=&quot;true&quot; /&gt; &lt;!-- BlackHole without writeTo --&gt; &lt;logger name=&quot;*&quot; minlevel=&quot;Trace&quot; writeTo=&quot;ownFile-web&quot; /&gt; &lt;logger name=&quot;*&quot; minlevel=&quot;Debug&quot; writeTo=&quot;file&quot; /&gt; &lt;/rules&gt;&lt;/nlog&gt; 使用NLog我们首先在Program使用注册NLog: 1234567891011public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .UseServiceProviderFactory(new AutofacServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); }).ConfigureLogging(logging =&gt; { logging.ClearProviders(); //删除日志组件 logging.SetMinimumLevel(Microsoft.Extensions.Logging.LogLevel.Trace); }).UseNLog(); 然后，我们就可以再相应的地方调用: 123456789101112131415[ApiVersion(&quot;1.0&quot;)] [Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] [ApiController] public class ExampleController : ControllerBase { private readonly ILogger&lt;ExampleController&gt; _logger; IExampleService _exampleService; public ExampleController(IExampleService exampleService, ILogger&lt;ExampleController&gt; logger) { _logger = logger; _exampleService = exampleService; _logger.LogDebug(&quot;NLog injected&quot;); } } 效果如下: 12019-12-25 17:09:48.5355||DEBUG|Web.Controllers.v1.ExampleController|NLog injected NLog类似于string.Format的格式,如： 1_logger.LogInformation(&quot;Hello, {0}&quot;, Name); 最终结果: 12019-12-25 17:35:57.4098||threadid-10||INFO|Web.Controllers.v1.ExampleController|Hello, Jane |url: http://localhost/api/v1.0/Example/GetName/Jane|action: GetName 也支持格式化和对象: 12_logger.LogInformation(&quot;Hello,{name}&quot;,Name);_logger.LogInformation(&quot;Hello,{Name}&quot;, new { Name = Name }); 效果： 1232019-12-25 17:35:57.4288||threadid-10||INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetName/Jane|action: GetName2019-12-25 17:35:57.4288||threadid-10||INFO|Web.Controllers.v1.ExampleController|Hello,{ Name = Jane } |url: http://localhost/api/v1.0/Example/GetName/Jane|action: GetName 更多配置看NLog的文档。 上下文信息如果是单体应用的话，用上面的配置即可, 但是，我们现在经常会用到微服务或者是异步。微服务一般使用MDC的方式，这里我们暂时只说说异步，大家都知道异步是会在创新新线程执行，这时候的线程Id就不和主线程在同一个上下文中了。我们来试试看: 123456789101112131415161718/// &lt;summary&gt; /// 异步调用 /// &lt;/summary&gt; /// &lt;param name=&quot;Name&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] [Route(&quot;GetNameAsync/{Name}&quot;)] public async Task&lt;string&gt; GetNameAsync(string Name) { _logger.LogInformation(&quot;Hello,{0}&quot;, Name); string result = &quot;&quot;; await Task.Run(() =&gt; { _logger.LogInformation(&quot;Hello,{0}&quot;, Name); result = $&quot;Hello,{Name}&quot;; }); return result; } 打印两次, 最终日志为: 122019-12-25 17:55:45.5634||threadid-5|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName2019-12-25 17:55:45.5634||threadid-4|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName 可以看到我们的threadid不一样。这样在我们捕捉日志的时候会变得很困难，这时候，NLog的ndlc就可以帮我们解决这个问题,我们修改一下nlog.config的layout配置: 1${longdate}|${event-properties:item=EventId_Id}|NDLC-${ndlc}|threadid-${threadid}|activityid-${activityid}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action} 效果如下: 122019-12-26 08:58:30.6271||NDLC-ConnectionId:0HLS9JGU66BD8 RequestPath:/api/v1.0/Example/GetNameAsync/Jane RequestId:0HLS9JGU66BD8:00000001, SpanId:|59ece683-4c05d632d98d1cac., TraceId:59ece683-4c05d632d98d1cac, ParentId: Web.Controllers.v1.ExampleController.GetNameAsync (Web)|threadid-5|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName2019-12-26 08:58:30.6598||NDLC-ConnectionId:0HLS9JGU66BD8 RequestPath:/api/v1.0/Example/GetNameAsync/Jane RequestId:0HLS9JGU66BD8:00000001, SpanId:|59ece683-4c05d632d98d1cac., TraceId:59ece683-4c05d632d98d1cac, ParentId: Web.Controllers.v1.ExampleController.GetNameAsync (Web)|threadid-10|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName 但是有些信息可能我们不需要,我先来看看NDLC的代码: 123456789101112131415161718192021222324252627282930313233343536protected override void Append(StringBuilder builder, LogEventInfo logEvent) { if (TopFrames == 1) { // Allows fast rendering of topframes=1 var topFrame = NestedDiagnosticsLogicalContext.PeekObject(); if (topFrame != null) AppendAsString(topFrame, GetFormatProvider(logEvent), builder); return; } var messages = NestedDiagnosticsLogicalContext.GetAllObjects(); if (messages.Length == 0) return; int startPos = 0; int endPos = messages.Length; if (TopFrames != -1) { endPos = Math.Min(TopFrames, messages.Length); } else if (BottomFrames != -1) { startPos = messages.Length - Math.Min(BottomFrames, messages.Length); } var formatProvider = GetFormatProvider(logEvent); string currentSeparator = string.Empty; for (int i = endPos - 1; i &gt;= startPos; --i) { builder.Append(currentSeparator); AppendAsString(messages[i], formatProvider, builder); currentSeparator = Separator; } } 在VS2019启用Source Link,就可以进入到我们的NLog组件,可以看到:可以看到message是一个数组,那么我们只想要ConnectionId的话，可以做如下修改: 1${longdate}|${event-properties:item=EventId_Id}|NDLC-${ndlc:bottomFrames=1}|threadid-${threadid}|activityid-${activityid}|${uppercase:${level}}|${logger}|${message} ${exception:format=tostring}|url: ${aspnet-request-url}|action: ${aspnet-mvc-action} 效果如下: 122019-12-26 10:56:53.0233||NDLC-ConnectionId:0HLS9LSTP4B7D|threadid-4|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName2019-12-26 10:56:53.4459||NDLC-ConnectionId:0HLS9LSTP4B7D|threadid-15|activityid-|INFO|Web.Controllers.v1.ExampleController|Hello,Jane |url: http://localhost/api/v1.0/Example/GetNameAsync/Jane|action: GetName 这样一来，我们就可以看到我们是否是同一个请求处理，其他更加强大的功能，有待探究。在这里我们有用到Source Link,确实还是比较方便，但是有一个更方便的工具,就是ReSharper,但是安装ReSharper后，咱们的VS会有一点小卡。先到这里吧，后面有机会再单独记录一下Source Link以及ReSharper神器的强大功能。","link":"/20191226/Net-Core3-x%E4%BD%BF%E7%94%A8NLog%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97.html"},{"title":"golang平滑升级服务","text":"不中断服务进行服务升级 最近在学习go语言，想着用gin+gorm来做一个微信小程序，在gin的github中看到了如何优雅的重启或者停止，因为在生产项目中，如果强行kill掉的话会造成正在执行的业务中断、用户访问被拒绝。显然，平滑的重启或升级我们的应用是多么的重要。 .net的发布过程我做了很多年的.net ，但是从来没有想过如何去平滑更新服务端，也是因为业务要求的可用性不高。一般发布新版本都是采用最笨拙的方式，就是发通知(xx时间升级会暂停服务)-&gt;到点停止服务备份、copy新文件-&gt;启动服务。 java的发布过程在用java做项目的时候，当时就用到了nginx中的upstream来负载均衡，当然，这时候要求的可用性较高，所以在发布服务的时候，就不能再采用简单粗暴的停止-启动大法。我们可以配合nginx -s reload来实现后端服务的灰度发布并且让用户无感知。 golang的发布过程Graceful restart or stopgolang中有很多开源的解决方案：endlessgraceoverseer 实践出真知在这里我们来试试grace(star最多，commits最多)，在github上面有详细的demo和测试步骤。v1 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) v2 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin New Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) 如果是在windows环境下开发，会提示: 1github.com\\facebookgo\\grace\\gracehttp\\http.go:104:53: undefined: syscall.SIGUSR2 貌似是因为grace不支持windows的原因，我们可以暂时不用搭理他，先编译一个二进制文件， 123SET GOARCH=amd64SET GOOS=linuxgo build main.go 把生成好的文件复制到linux上，先启动起来(我是用的nohup ./grace &amp;来启动的)，这时候我们查看pid是多少 1234ps -ef|grep graceroot 11915 11364 0 13:06 pts/0 00:00:00 ./graceroot 11921 11364 0 13:08 pts/0 00:00:00 grep --color=auto grace 此时访问服务结果：这时候，我们把之前的文件备份，将v2的代码编译好并拷贝上去，执行命令 123456kill -USR2 11915这时候在看看应用进程ps -ef|grep graceroot 11928 1 0 13:11 pts/0 00:00:00 ./graceroot 11935 11364 0 13:12 pts/0 00:00:00 grep --color=auto grace pid已经变为11928,此时访问服务结果：[参考]https://github.com/facebookarchive/gracehttps://github.com/gin-gonic/gin","link":"/20191024/golang%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7%E6%9C%8D%E5%8A%A1.html"},{"title":"golang下载妹子图","text":"想用golang下载妹子图吗？点进来看看吧!很方便 闲来无趣，就想着看用golang来做点什么事情，这不，到处都是python下载妹子图,我就想着用golang来弄一个下载妹子图的简单小工具 简单分析页面结构访问https://www.meizitu.com 页面后, 进入到详情页面，可以看到url变为https://www.meizitu.com/a/5511.html ，我们将url中的数字任意修改，发现都能访问，那么，我们暂且就通过手动输入页面索引的方式来访问页面。我们再看看页面结构,通过google浏览器的开发者工具很容易就可以看到： 下载图片刚才我们已经大致的分析了页面结构，接下来 ，我们就开始简单的实现图片下载的功能，在这里我们选用了：colly:用于采集页面和图片uuid:生产UUIDcli:命令行工具包1、我们先初始化一个队列，用于存放需要访问的url 1234var q, _ = queue.New( 2, // Number of consumer threads &amp;queue.InMemoryQueueStorage{MaxSize: 10000}, // Use default queue storage ) 2、初始化需要下载的页面，我用命令行的方式来决定起始页 123456789101112if args := context.Args(); len(args) &gt; 0 { return fmt.Errorf(&quot;invalid command: %q&quot;, args.Get(0)) } start := context.Int(&quot;s&quot;) log.Println(&quot;起始页:&quot;, start) end := context.Int(&quot;e&quot;) log.Println(&quot;截止页:&quot;, end) for i := start; i &lt;= end; i++ { url := fmt.Sprintf(&quot;https://www.meizitu.com/a/%d.html&quot;, i) q.AddURL(url)} 3、初始化一个colly来处理队列中的url,我在OnHTML中，查找页面的postContent&gt;img的dom节点，获取图片的路径，又放在队列中 1234567891011121314151617181920c := colly.NewCollector() c.UserAgent = &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot; c.OnHTML(&quot;.postContent&quot;, func(e *colly.HTMLElement) { //e.Request.Visit(e.Attr(&quot;href&quot;)) e.ForEach(&quot;img&quot;, func(i int, element *colly.HTMLElement) { //e.Request.Visit(element.Attr(&quot;src&quot;)) q.AddURL(element.Attr(&quot;src&quot;)) }) }) c.OnResponse(func(resp *colly.Response) { if strings.Contains(resp.Headers.Get(&quot;Content-Type&quot;), &quot;image/jpeg&quot;) { download(resp.Body) } }) c.OnRequest(func(r *colly.Request) { fmt.Println(&quot;Visiting&quot;, r.URL) }) q.Run(c) 最后的效果：代码很简单，如果需要可以去https://github.com/eyiadmin/meizitu 看看，如果想下载图片，就直接下载exe文件。在命令行输入main -s 1 -e 100即可下载 12345678910111213141516171819202122232425main -s 100 -e 1082019/10/07 14:26:42 起始页: 1002019/10/07 14:26:43 截止页: 108Visiting https://www.meizitu.com/a/100.htmlVisiting https://www.meizitu.com/a/101.htmlVisiting https://www.meizitu.com/a/102.htmlVisiting https://www.meizitu.com/a/103.htmlVisiting https://www.meizitu.com/a/104.htmlVisiting https://www.meizitu.com/a/105.htmlVisiting https://www.meizitu.com/a/106.htmlVisiting https://www.meizitu.com/a/107.htmlVisiting https://www.meizitu.com/a/108.htmlVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/04.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/05.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/06.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/07.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/08.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/09.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/04.jpg","link":"/20191024/golang%E4%B8%8B%E8%BD%BD%E5%A6%B9%E5%AD%90%E5%9B%BE.html"},{"title":"Hexo搭建个人博客锦集","text":"我想很多人都想有一个自己的博客网站，现在开源的博客系统也很多，但是像java，python这种开源的博客系统需要宿主机、申请域名、安装环境等稍稍复杂的操作，当然现在也可以基于阿里或者腾讯云提供的Docker容器服务搭建也是非常方便。那么，还有没有成本更低的搭建方式呢？这时候就需要提到Hexo了，什么是Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。我可以将生产的静态页面托管到Github、Coding、Gitee等代码托管平台上，从而节约我们的服务器费用。 Hexo环境准备我们首先需要安装一下几个环境: Node.js:安装的时候直接下一步即可(默认已勾选Add to PATH) Git 以上两项安装成功后,即可安装 Hexo: 1npm install -g hexo-cli #全局安装 新建博客打开cmd命令行，进入到要创建博客的目录,执行以下命令: 123hexo init &lt;文件夹名&gt; #会在当前目录创建一个文件夹,并下载hexo模版cd &lt;文件夹名&gt; #进入博客文件夹npm install #安装hexo相应依赖 构建成功后的目录如下:启动起来看看效果: 1hexo serve 我们可以看到hexo会自动生成一篇文章，并会提到4个常用命令: 1234hexo new &quot;My New Post&quot; #创建博客,缩写hexo n &quot;My New Post&quot;hexo server #启动hexo,缩写hexo shexo generate #生成静态页面,缩写hexo ghexo deploy #发布到静态托管服务器,缩写hexo d 一般我们发布都是 hexo g &amp; hexo d 一起执行。 配置博客这时候需要去修改根目录下的 _config.yml 配置文件,我们可以参考一下https://hexo.io/zh-cn/docs/configuration 属性名 作用 title 网站标题 subtitle 网站副标题 description 主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词 keywords 网站的关键词。使用半角逗号 , 分隔多个关键词。 author 用于主题显示文章的作者 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。 url 网址,如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/ root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 pretty_urls 改写 permalink 的值来美化 URL pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除,默认:true source_dir 资源文件夹，这个文件夹用来存放内容。默认:source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。默认:public tag_dir 标签文件夹,默认:tags archive_dir 归档文件夹,默认:archives category_dir 分类文件夹,默认:categories code_dir Include code 文件夹，source_dir 下的子目录,默认:downloads/code i18n_dir 国际化（i18n）文件夹,默认: :lang skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。 new_post_name 新文章的文件名称,默认: :title.md default_layout 预设布局,默认: post auto_spacing 在中文和英文之间加入空格,默认: false titlecase 把标题转换为 title case,默认:false external_link 在新标签中打开链接,默认:true external_link.enable 在新标签中打开链接,默认:true external_link.field 对整个网站（site）生效或仅对文章（post）生效,默认:site external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 [] 其他的可以去网站查看，或者自行百度吧,实在是懒得抄了。 配置博客主题Hexo为我们提供了很多主题模版,这里我推荐我喜欢的两个: hexo-theme-butterfly hexo-theme-icarus 更换主题步骤: 下载主题 将主题解压复制到themes文件夹中 修改_config.yml中的theme:属性，属性值为themes中文件夹名，如：theme: butterfly。 如果使用butterfly主题的话，需要安装hexo-renderer-jade(pug的编译工具，内包括了pug的渲染引擎),npm install hexo-renderer-jade 部署到 GitHub Pages 新建一个 repository。如果你希望你的站点能通过 &lt;你的 GitHub 用户名&gt;.github.io 域名访问，你的 repository 应该直接命名为 &lt;你的 GitHub 用户名&gt;.github.io 修改_config.yml:12345deploy: type: git repository: github: https://github.com/eyiadmin/eyiadmin.github.io.git #这里我们选择HTTPS的方式,当然也可以通过SSH方式(后期更加方便) branch: master 因为是git，所以需要npm install --save hexo-deployer-git来安装插件, 发布到GitHub Pages:1hexo g &amp; hexo d 上传成功后就可以在我们的repository中看到上传的静态页面,这时候就可以通过https://&lt;你的 GitHub 用户名&gt;.github.io来访问，如：https://eyiadmin.github.io/ Markdown常用语法标题12345# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题 一级标题二级标题三级标题四级标题五级标题超链接123[超链接名称](超链接地址 &quot;超链接title(鼠标hover显示内容)&quot;) 例如：[农民工学编程](http://blog.52fx.biz &quot;快来看农民工学编程啦&quot;) 农民工学编程 图片12![图片描述(显示在图片下方,可不填)](图片连接地址 &quot;图片title(鼠标hover显示内容)&quot;)![](http://xxnote.52fx.biz/publish.png &quot;发布效果图&quot;) 代码1`单行内容` 多行用内容``` ``` First Blood 123456789Double Kill Trible Kill Quadra Kill Penta Kill Ace 团灭! 未完待续，不定期更新 https://github.com/gohugoio/hugo(Hugo是由Go语言实现的静态网站生成器)https://github.com/jekyll/jekyll(jekyll是由Ruby语言实现的静态网站生成器)https://github.com/hexojs/hexo(Hexo是由Nodejs语言实现的静态网站生成器) https://blog.csdn.net/mqdxiaoxiao/article/details/93378785https://www.jianshu.com/p/25145964abf3","link":"/20191203/hexo-blog.html"},{"title":".net core 3.x使用Swagger","text":".net core3.0问世已经两个多月了，我并没有急着将生产上的项目升级到3.0，因为怕踩坑，这不3.1马上就要出来了，想着core3.x逐渐稳定，所以就开始来琢磨一下，此次就简单是说一下.net core3.0中使丝袜哥(Swagger)生成API文档。 在这里，我使用的开发工具是VS2019,Swashbuckle.AspNetCore 5.0.0-rc4， 安装Swashbuckle.AspNetCore1、首先新建一个Web API项目2、安装swagger,打开程序包管理器控制台执行： 1Install-Package Swashbuckle.AspNetCore -Version 5.0.0-rc4 引用Swagger1、在Startup.cs中引入命名空间 12using Microsoft.OpenApi.Models;using Swashbuckle.AspNetCore.Swagger; 2、在ConfigureServices中添加Swagger 1234services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot; }); }); 3、在Configure中添加Swagger中间件,我们最好放在env.IsDevelopment()中 123456789if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;Demo API&quot;); }); app.UseDeveloperExceptionPage(); } 4、配置完后，运行一下，在浏览器中输入http://localhost:5000/swagger, 看看效果： 为Api添加注释刚才的配置，只是能看到我们的API方法，并且可以发送调试请求，但是没有注释，接下来，我们就给API加上注释1、在想要添加注释的API对应分方法上添加注释,格式如下： 12345678910111213141516/// &lt;summary&gt; /// 获取天气预报信息 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] public IEnumerable&lt;WeatherForecast&gt; Get() { var rng = new Random(); return Enumerable.Range(1, 5).Select(index =&gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)] }) .ToArray(); } 2、在项目属性选项卡中，设置生成中的XML文档输出目录:3、在AddSwaggerGen中添加xml文件路径: 123456services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; } }); var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); swagger.IncludeXmlComments(docXmlPath); }); 4、最终效果: 每次启动都会打开默认的IE浏览器，由于个人喜欢Google浏览器，所以，现在修改vs启动的默认浏览器：另外，每次启动，在浏览中打开的是默认的Controller，我们可以设置一下启动参数，让每次启动都是Swagger目录，就不需要我们每次都手动输入Swagger目录：。 这次写的是Swagger最基本的设置,后面我们会继续学习一些常用的高级功能。","link":"/20191112/net-core-3-0-use-swagger-ui.html"},{"title":"我想用gatsbyjs搞一个静态网站","text":"最近想弄一个生活、办公技巧分项的静态网站，为什么要用静态的呢？成本啊兄dei。静态网页生成有很多工具，hexo、hugo、nuxt等等，很多的。这次呢我想试试gatsbyjs,所以才有了此文,盆友们可以去https://www.gatsbyjs.org/看详细介绍。 gatsbyjs安装在安装gatsbyjs之前，首先得确保Node和Git的环境已经正确安装，未安装的，可以看我之前的博文，或者自行百度，在此不再详述。我直接安装gatsbyjs. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071C:\\Users\\lenovo&gt;npm install -g gatsby-clinpm WARN deprecated core-js@2.6.11: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.C:\\Users\\lenovo\\AppData\\Roaming\\npm\\gatsby -&gt; C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\gatsby-cli\\lib\\index.js&gt; core-js@2.6.11 postinstall C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\gatsby-cli\\node_modules\\core-js&gt; node -e &quot;try{require(&apos;./postinstall&apos;)}catch(e){}&quot;Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!The project needs your help! Please consider supporting of core-js on Open Collective or Patreon:&gt; https://opencollective.com/core-js&gt; https://www.patreon.com/zloirockAlso, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)&gt; gatsby-telemetry@1.1.46 postinstall C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\gatsby-cli\\node_modules\\gatsby-telemetry&gt; node src/postinstall.js || true╔════════════════════════════════════════════════════════════════════════╗║ ║║ Gatsby collects anonymous usage analytics ║║ to help improve Gatsby for all users. ║║ ║║ If you&apos;d like to opt-out, you can use `gatsby telemetry --disable` ║║ To learn more, checkout https://gatsby.dev/telemetry ║║ ║╚════════════════════════════════════════════════════════════════════════╝&gt; gatsby-cli@2.8.22 postinstall C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\gatsby-cli&gt; node scripts/postinstall.js╔════════════════════════════════════════════════════════════════════════╗║ ║║ Gatsby collects anonymous usage analytics ║║ to help improve Gatsby for all users. ║║ ║║ If you&apos;d like to opt-out, you can use `gatsby telemetry --disable` ║║ To learn more, checkout https://gatsby.dev/telemetry ║║ ║╚════════════════════════════════════════════════════════════════════════╝Success!Welcome to the Gatsby CLI! Please visit https://www.gatsbyjs.org/docs/gatsby-cli/ for more information.Usage: gatsby &lt;command&gt; [options]Commands: gatsby develop Start development server. Watches files, rebuilds, and hot reloads if something changes gatsby build Build a Gatsby project. gatsby serve Serve previously built Gatsby site. gatsby info Get environment information for debugging and issue reporting gatsby clean Wipe the local gatsby environment including built assets and cache gatsby repl Get a node repl with context of Gatsby environment, see (https://www.gatsbyjs.org/docs/gatsby-repl/) gatsby new [rootPath] [starter] Create new Gatsby project. gatsby plugin Useful commands relating to Gatsby plugins gatsby telemetry Enable or disable Gatsby anonymous analytics collection.Options: --verbose Turn on verbose output [boolean] [default: false] --no-color, --no-colors Turn off the color in output [boolean] [default: false] --json Turn on the JSON logger [boolean] [default: false] -h, --help Show help [boolean] -v, --version Show the version of the Gatsby CLI and the Gatsby package in the current project [boolean]npm WARN ink@2.6.0 requires a peer of @types/react@&gt;=16.8.0 but none is installed. You must install peer dependencies yourself.npm WARN auto-bind@3.0.0 requires a peer of @types/react@&gt;=16.8.0 but none is installed. You must install peer dependencies yourself.+ gatsby-cli@2.8.22added 376 packages from 164 contributors in 76.778s 可以看看我本机的环境: 123456789101112C:\\Users\\lenovo&gt;gatsby info System: OS: Windows 10 10.0.18362 CPU: (8) x64 Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz Binaries: Node: 13.5.0 - D:\\Program Files\\nodejs\\node.EXE npm: 6.13.4 - D:\\Program Files\\nodejs\\npm.CMD Languages: Python: 3.8.1 Browsers: Edge: 44.18362.449.0 新建网站首先在本机创建一个文件夹用于存放网页，然后执行新建命令gatsby new [sitename] [模版路径]，gatsbyjs会通过git去下载模版并创建项目。创建完成后会自动安装，但是可能会安装失败，因为默认npm的镜像地址会被我们的大型局域网屏蔽，我们可以借助nrm来管理镜像地址。我在安装过程中，遇到了 1unbuild: sill gentlyRm target.inParent = false 简单粗暴的方式就是直接删除node_modules目录，重新安装。如果是windows的话，请事先安装： 1npm install windows-build-tools -g 供gatsby-transformer-sharp编译时用，否则会提示编译失败。最后安装成功: 123456789101112131415161718E:\\gatsbyjs\\happylife&gt;npm install&gt; sharp@0.23.4 install E:\\gatsbyjs\\happylife\\node_modules\\sharp&gt; (node install/libvips &amp;&amp; node install/dll-copy &amp;&amp; prebuild-install) || (node-gyp rebuild &amp;&amp; node install/dll-copy)info sharp Downloading https://github.com/lovell/sharp-libvips/releases/download/v8.8.1/libvips-8.8.1-win32-x64.tar.gzinfo sharp Creating E:\\gatsbyjs\\happylife\\node_modules\\sharp\\build\\Releaseinfo sharp Copying DLLs from E:\\gatsbyjs\\happylife\\node_modules\\sharp\\vendor\\lib to E:\\gatsbyjs\\happylife\\node_modules\\sharp\\build\\Releasenpm WARN tsutils@3.17.1 requires a peer of typescript@&gt;=2.8.0 || &gt;= 3.2.0-dev || &gt;= 3.3.0-dev || &gt;= 3.4.0-dev || &gt;= 3.5.0-dev || &gt;= 3.6.0-dev || &gt;= 3.6.0-beta || &gt;= 3.7.0-dev || &gt;= 3.7.0-beta but none is installed. You must install peer dependencies yourself.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.2 (node_modules\\chokidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.2: wanted {&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;} (current: {&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;})npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.11 (node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.11: wanted {&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;} (current: {&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;})added 41 packages from 91 contributors in 252.487s27 packages are looking for funding run `npm fund` for details 我们来试试gatsbyjs的初步呈现效果,我们通过cmd进入到网站目录执行gatsby develop即可运行 我们来换个主题吧，在https://www.gatsbyjs.org/starters/?v=2可以看到很多风格非常漂亮的模版。我这里选择的是gatsby-starter-hero-blog,进入到gatsby-starter-hero-blog的页面，可以看到如何下载模版: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121E:\\gatsbyjs&gt;gatsby new happylife https://github.com/greglobinski/gatsby-starter-hero-bloginfo Creating new site from git: https://github.com/greglobinski/gatsby-starter-hero-blog.gitCloning into &apos;happylife&apos;...remote: Enumerating objects: 197, done.remote: Counting objects: 100% (197/197), done.remote: Compressing objects: 100% (159/159), done.remote: Total 197 (delta 16), reused 150 (delta 11), pack-reused 0 eceiving objects: 100% (197/197), 8.79 MiB | 71.00 KiReceiving objects: 100% (197/197), 8.83 MiB | 58.00 KiB/s, done.Resolving deltas: 100% (16/16), done.success Created starter directory layoutinfo Installing packages...npm WARN deprecated postcss-cssnext@3.1.0: &apos;postcss-cssnext&apos; has been deprecated in favor of &apos;postcss-preset-env&apos;. Read more at https://moox.io/blog/deprecating-cssnext/npm WARN deprecated bfj-node4@5.3.1: Switch to the `bfj` package for fixes and new features!npm WARN deprecated core-js@2.6.11: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.npm WARN deprecated md5-file@3.2.3: This module is looking for a new maintainer.npm WARN deprecated browserslist@2.11.3: Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.npm WARN deprecated joi@11.4.0: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).npm WARN deprecated core-js@1.2.7: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.npm WARN deprecated browserslist@1.7.7: Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.npm WARN deprecated hoek@4.2.1: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).npm WARN deprecated topo@2.0.2: This version has been deprecated in accordance with the hapi support policy (hapi.im/support). Please upgrade to the latest version to get the best features, bug fixes, and security patches. If you are unable to upgrade at this time, paid support is available for older versions (hapi.im/commercial).npm WARN deprecated circular-json@0.3.3: CircularJSON is in maintenance only, flatted is its successor.npm WARN deprecated @types/vfile-message@2.0.0: This is a stub types definition. vfile-message provides its own type definitions, so you do not need this installed.&gt; deasync@0.1.19 install E:\\gatsbyjs\\happylife\\node_modules\\deasync&gt; node ./build.js`win32-x64-node-13` exists; testingBinary is fine; exiting&gt; sharp@0.23.4 install E:\\gatsbyjs\\happylife\\node_modules\\sharp&gt; (node install/libvips &amp;&amp; node install/dll-copy &amp;&amp; prebuild-install) || (node-gyp rebuild &amp;&amp; node install/dll-copy)info sharp Using cached C:\\Users\\lenovo\\AppData\\Roaming\\npm-cache\\_libvips\\libvips-8.8.1-win32-x64.tar.gzinfo sharp Creating E:\\gatsbyjs\\happylife\\node_modules\\sharp\\build\\Releaseinfo sharp Copying DLLs from E:\\gatsbyjs\\happylife\\node_modules\\sharp\\vendor\\lib to E:\\gatsbyjs\\happylife\\node_modules\\sharp\\build\\Release&gt; sharp@0.23.3 install E:\\gatsbyjs\\happylife\\node_modules\\sharp-cli\\node_modules\\sharp&gt; (node install/libvips &amp;&amp; node install/dll-copy &amp;&amp; prebuild-install) || (node-gyp rebuild &amp;&amp; node install/dll-copy)info sharp Using cached C:\\Users\\lenovo\\AppData\\Roaming\\npm-cache\\_libvips\\libvips-8.8.1-win32-x64.tar.gzinfo sharp Creating E:\\gatsbyjs\\happylife\\node_modules\\sharp-cli\\node_modules\\sharp\\build\\Releaseinfo sharp Copying DLLs from E:\\gatsbyjs\\happylife\\node_modules\\sharp-cli\\node_modules\\sharp\\vendor\\lib to E:\\gatsbyjs\\happylife\\node_modules\\sharp-cli\\node_modules\\sharp\\build\\Release&gt; core-js@2.6.11 postinstall E:\\gatsbyjs\\happylife\\node_modules\\core-js&gt; node -e &quot;try{require(&apos;./postinstall&apos;)}catch(e){}&quot;Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!The project needs your help! Please consider supporting of core-js on Open Collective or Patreon:&gt; https://opencollective.com/core-js&gt; https://www.patreon.com/zloirockAlso, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)&gt; core-js-pure@3.6.2 postinstall E:\\gatsbyjs\\happylife\\node_modules\\core-js-pure&gt; node -e &quot;try{require(&apos;./postinstall&apos;)}catch(e){}&quot;&gt; ejs@2.7.4 postinstall E:\\gatsbyjs\\happylife\\node_modules\\ejs&gt; node ./postinstall.jsThank you for installing EJS: built with the Jake JavaScript build tool (https://jakejs.com/)&gt; gatsby-telemetry@1.1.46 postinstall E:\\gatsbyjs\\happylife\\node_modules\\gatsby-telemetry&gt; node src/postinstall.js || true&gt; cwebp-bin@5.1.0 postinstall E:\\gatsbyjs\\happylife\\node_modules\\cwebp-bin&gt; node lib/install.js √ cwebp pre-build test passed successfully&gt; mozjpeg@6.0.1 postinstall E:\\gatsbyjs\\happylife\\node_modules\\mozjpeg&gt; node lib/install.js √ mozjpeg pre-build test passed successfully&gt; pngquant-bin@5.0.2 postinstall E:\\gatsbyjs\\happylife\\node_modules\\pngquant-bin&gt; node lib/install.js √ pngquant pre-build test passed successfully&gt; gatsby-cli@2.8.23 postinstall E:\\gatsbyjs\\happylife\\node_modules\\gatsby\\node_modules\\gatsby-cli&gt; node scripts/postinstall.js&gt; gatsby@2.18.18 postinstall E:\\gatsbyjs\\happylife\\node_modules\\gatsby&gt; node scripts/postinstall.jsnpm notice created a lockfile as package-lock.json. You should commit this file.npm WARN gatsby-plugin-styled-jsx@3.1.17 requires a peer of styled-jsx@^3.0.2 but none is installed. You must install peer dependencies yourself.npm WARN react-addons-perf@15.4.2 requires a peer of react-dom@^15.4.2 but none is installed. You must install peer dependencies yourself.npm WARN eslint-config-react-app@5.1.0 requires a peer of babel-eslint@10.x but none is installed. You must install peer dependencies yourself.npm WARN eslint-config-react-app@5.1.0 requires a peer of eslint@6.x but none is installed. You must install peer dependencies yourself.npm WARN tsutils@3.17.1 requires a peer of typescript@&gt;=2.8.0 || &gt;= 3.2.0-dev || &gt;= 3.3.0-dev || &gt;= 3.4.0-dev || &gt;= 3.5.0-dev || &gt;= 3.6.0-dev || &gt;= 3.6.0-beta || &gt;= 3.7.0-dev || &gt;= 3.7.0-beta but none is installed. You must install peer dependencies yourself.npm WARN ws@7.2.1 requires a peer of bufferutil@^4.0.1 but none is installed. You must install peer dependencies yourself.npm WARN ws@7.2.1 requires a peer of utf-8-validate@^5.0.2 but none is installed. You must install peer dependencies yourself.npm WARN react-instantsearch-native@5.7.0 requires a peer of react-native@&gt;= 0.32.0 but none is installed. You must install peer dependencies yourself.npm WARN eslint-plugin-graphql@2.1.1 requires a peer of graphql@^0.12.0 || ^0.13.0 but none is installed. You must install peer dependencies yourself.npm WARN gatsby-starter-hero-blog@2.0.0 No repository field.npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@1.2.11 (node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@1.2.11: wanted {&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;} (current: {&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;})npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.2 (node_modules\\chokidar\\node_modules\\fsevents):npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.2: wanted {&quot;os&quot;:&quot;darwin&quot;,&quot;arch&quot;:&quot;any&quot;} (current: {&quot;os&quot;:&quot;win32&quot;,&quot;arch&quot;:&quot;x64&quot;})added 3046 packages from 1481 contributors in 1263.674s56 packages are looking for funding run `npm fund` for detailsinfo Initialising git in happylifeInitialized empty Git repository in E:/gatsbyjs/happylife/.git/info Create initial git commit in happylifeinfoYour new Gatsby site has been successfully bootstrapped. Start developing it by running: cd happylife gatsby develop 我们可以看到其目录结构:可以在content\\meta\\config.js修改网站的一些基本属性，需要新建文章的话，就按content\\posts下面的结构类似就可.详情可以访问https://dev.greglobinski.com/install-blog-starter/查看。我们的菜单可以再src\\components\\Menu\\Menu.js修改: 1234567this.items = [ { to: &quot;/&quot;, label: &quot;Home&quot;, icon: FaHome }, { to: &quot;/category/&quot;, label: &quot;Categories&quot;, icon: FaTag }, { to: &quot;/search/&quot;, label: &quot;Search&quot;, icon: FaSearch }, ...pages, { to: &quot;/contact/&quot;, label: &quot;Contact&quot;, icon: FaEnvelope } ]; 这里的pages是只想content\\pages目录,可以自己按照/No--title/的格式新增菜单。编译上传到七牛云: 1gatsby build &amp;&amp; qshell qupload2 --overwrite=true --rescan-local=true --src-dir=E:\\gatsbyjs\\happylife\\public --bucket=eyiadminxxxxx 最后献上地址:https://live.52fx.biz/ 参考https://www.gatsbyjs.org/docs/gatsby-on-windows/","link":"/20200108/gatsbyjs-publish-web.html"},{"title":".Net Core 3.x 使用Autofac替换默认Ioc容器","text":".net 中的IOC容器也不少，如Autofac、Windsor Castle、Spring.NET、Unity、Ninject等，现在使用Autofac作为IOC容器的较多,据说速度是最快的一个。 那么我们有必要将其应用到我们的项目中，来体验其带给我们的极速快感。 安装Autofac依赖我们需要通过nuget包管理安装两个包: 12AutofacAutofac.Extensions.DependencyInjection 使用Autofac包在Autofac中有多种生命周期: Instance Per Dependency 对于一个服务每次请求都会返回一个唯一的实例. Single Instance 所有的请求都将会返回同一个实例. Instance Per Lifetime Scope 每个生命周期作用域的组件在每个嵌套的生命周期作用域中最多只会有一个单一实例 Instance Per Matching Lifetime Scope 每个匹配生命周期作用域的组件在每个名称匹配的嵌套生命周期作用域中最多只会有一个单一实例. Instance Per Request 每个请求一个实例建立于每个匹配生命周期一个实例之上 Instance Per Owned Owned 隐式关系类型 创建了一个嵌套的生命周期作用域. 使用每次被拥有一个实例注册, 可以把该依赖的作用域绑定到拥有它的实例上. Thread Scope 每个线程就有了它各自的生命周期作用域,在这种多线程场景中, 你必须得注意父级作用域不能在派生出的线程下被释放了 新建一个ITransientDependency空接口123public interface ITransientDependency { } 这里的主要目的是为了标识接口注册不同的声明周期。你们可以根据自己的情况新增不同的标识注入不同的生命周期 新建一个WebModule类继承Autofac的Module1234567891011121314151617public class WebModule : Module { protected override void Load(ContainerBuilder builder) { //获取当前程序集 var dataAccess = Reflection.Assembly.GetExecutingAssembly(); var transientDependencyType = typeof(ITransientDependency); //查找ITransientDependency接口类型程序并注册为每次调用创建一个实例 builder.RegisterAssemblyTypes(dataAccess) .Where(t =&gt; transientDependencyType.IsAssignableFrom(t) &amp;&amp; t != transientDependencyType) .AsImplementedInterfaces().InstancePerLifetimeScope().PropertiesAutowired(); } } 主要是查找程序集，批量注册相应依赖， 配置使用在Program中稍作修改 1234567public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .UseServiceProviderFactory(new AutofacServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); }); 在Startup文件中加入ConfigureContainer方法: 1234public void ConfigureContainer(ContainerBuilder builder) { builder.RegisterModule(new WebModule()); } 至此，我们对Autofac已经配置完成 示例接下来我们新建一个IExampleService示例接口继承ITransientDependency, 1234public interface IExampleService: ITransientDependency { string GetName(string Name); } 新建IExampleService接口实现类: 1234567public class ExampleService : IExampleService { public string GetName(string Name) { return $&quot;My name is {Name}&quot;; } } 新建一个Controller,并注入IExampleService: 123456789101112131415161718192021222324252627namespace Web.Controllers.v1{ [ApiVersion(&quot;1.0&quot;)] [Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] [ApiController] public class ExampleController : ControllerBase { IExampleService _exampleService; public ExampleController(IExampleService exampleService) { _exampleService = exampleService; } /// &lt;summary&gt; /// 查询名字 /// &lt;/summary&gt; /// &lt;param name=&quot;name&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] [Route(&quot;GetName/{Name}&quot;)] public string GetName(string Name) { return _exampleService.GetName(Name); } }} 参考https://autofaccn.readthedocs.io/zh/latest/https://docs.autofac.org/en/latest/","link":"/20191202/net-core3-x-autofac-ioc.html"},{"title":".net core使用Topshelf注册windows服务","text":"Topshelf注册windows服务，方便快捷 我们经常会用一些定时处理的任务，在.net种一般是结合Quartz或者hangfire这两个组件实现定时周期性作业，但是我想把开发好的定时作业注册成windows服务，这样，在服务器重启之后，可以自动运行服务。Topshelf 就可以很方便的开发windows，而且注册安装也很方便。TopShelf的地址：http://topshelf-project.com/我们首先使用netget安装TopShelf： 1Install-Package TopShelf 然后在program.cs中加入如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243var builder = new HostBuilder() .ConfigureAppConfiguration(config =&gt; { config.AddJsonFile(&quot;monitor.json&quot;, optional: true, reloadOnChange: true); }) .ConfigureServices((hostContext, services) =&gt; { services.Configure&lt;Config&gt;(hostContext.Configuration.GetSection(&quot;monitor&quot;)); services.AddSingleton&lt;IHostLifetime, TopshelfLifetime&gt;(); services.AddHostedService&lt;MonitorService&gt;(); });HostFactory.Run(service =&gt; { service.SetServiceName(&quot;服务名&quot;); service.SetDisplayName(&quot;服务显示名称&quot;); service.SetDescription(&quot;服务描述&quot;); service.UseLog4Net(&quot;log4net.config&quot;); service.Service&lt;IHost&gt;(host =&gt; { host.ConstructUsing(() =&gt; builder.Build()); host.WhenStarted(serviceInstance =&gt; { serviceInstance.StartAsync(); }); host.WhenStopped(serviceInstance =&gt; { serviceInstance.StopAsync(); }); }); service.OnException((ex) =&gt; { Console.WriteLine(&quot;Exception thrown - &quot; + ex.Message); }); service.RunAsLocalSystem(); }); } 新建一个类继承IHostedService接口: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MonitorService : IHostedService, IDisposable { private IScheduler scheduler; static readonly LogWriter _log = HostLogger.Get&lt;MonitorService&gt;(); public readonly Config Config; private Timer _timer; Config _config; public MonitorService() { } public MonitorService(IOptions&lt;Config&gt; config) { _config = config?.Value; //Config = _config; } public async Task StartAsync(CancellationToken cancellationToken) { _log.Info(&quot;service starting&quot;); ISchedulerFactory sf = new StdSchedulerFactory(); scheduler = await sf.GetScheduler(); IJobDetail job = JobBuilder.Create&lt;AreaSyncJob&gt;().WithIdentity(&quot;job1&quot;, &quot;group1&quot;).Build(); ITrigger trigger = TriggerBuilder.Create().WithIdentity(&quot;triggger1&quot;, &quot;group1&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.AreaJobCronExpr))).Build(); IJobDetail job1 = JobBuilder.Create&lt;LocationSyncJob&gt;().WithIdentity(&quot;job2&quot;, &quot;group2&quot;).Build(); ITrigger trigger1 = TriggerBuilder.Create().WithIdentity(&quot;triggger2&quot;, &quot;group2&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.LocationCronExpr))).Build(); IJobDetail job2 = JobBuilder.Create&lt;TaskExecAyncJob&gt;().WithIdentity(&quot;job3&quot;, &quot;group3&quot;).Build(); ITrigger trigger2 = TriggerBuilder.Create().WithIdentity(&quot;triggger3&quot;, &quot;group3&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.TaskExecCronExpr))).Build(); IJobDetail job3 = JobBuilder.Create&lt;MonitorJob&gt;().WithIdentity(&quot;job4&quot;, &quot;group4&quot;).Build(); ITrigger trigger3 = TriggerBuilder.Create().WithIdentity(&quot;triggger4&quot;, &quot;group4&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.MonitorCronExpr))).Build(); //启动任务 await scheduler.ScheduleJob(job, trigger); await scheduler.ScheduleJob(job1, trigger1); await scheduler.ScheduleJob(job2, trigger2); await scheduler.ScheduleJob(job3, trigger3); await scheduler.Start(); _log.Info(&quot;service started&quot;); } public Task StopAsync(CancellationToken cancellationToken) { _timer?.Change(Timeout.Infinite, 0); scheduler?.Shutdown(); return Task.CompletedTask; } public void Dispose() { scheduler = null; _timer?.Dispose(); } } StartAsync方法为服务启动时运行。然后编译程序： 1dotnet publish -o ./bin/output -c Release -r win7-x64 执行成功后，会在bin/output目录下生成运行所需要的的程序和依赖DLL。将整个目录复制到指定服务器，cmd进入到程序目录，执行： 1xxxx.exe install 就可以完成服务安装.执行: 1xxxx.exe uninstall 就可以完成服务卸载，非常方便。","link":"/20191031/net-core%E4%BD%BF%E7%94%A8Topshelf%E6%B3%A8%E5%86%8Cwindows%E6%9C%8D%E5%8A%A1.html"},{"title":"nginx搭建https服务","text":"nginx搭建https服务,转发到http后端服务 花了差不多5个小时用golang做了一个短域名服务+简单的微信小程序，在发布的时候需要用过https协议的服务，遂出此文 gin发布https因为是第一次用gin发布一个真实的环境，很多东西也不是很熟，所以只能百度，当时找到gin中间件把端口转换为https协议这篇文章，看了一下，很简单，就尝试着cv实现以下。由于的采用了gin在github提到的Graceful restart or stop功能，简单cv没有实现，就想了一个便捷的方式(毕竟菜嘛)–采用nginx代理一层。 采用nginx部署https安装步骤 123456789101112# 安装依赖yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel# 下载nginxwget http://nginx.org/download/nginx-1.17.4.tar.gz# 解压文件tar -zxvf nginx-1.17.4.tar.gz# 进入nginx源码目录cd nginx-1.17.4# 配置https模块./configure --prefix=/root/nginx --with-http_stub_status_module --with-http_ssl_module# 编译并安装make &amp;&amp; make install 如果上面的步骤没有异常，那么久算安装成功了，下面就开始配置https代理。 1、先把申请下来的证书复制到nginx目录下，我是新建了一个cert的文件目录，2、修改nginx.conf123456789101112131415161718192021server { listen 443 ssl; server_name domain; ssl_certificate /root/nginx/cert/1_domain_bundle.crt; #证书公钥 ssl_certificate_key /root/nginx/cert/2_domain.key; #证书私钥 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDH:AESGCM:HIGH:!RC4:!DH:!MD5:!3DES:!aNULL:!eNULL; ssl_prefer_server_ciphers on; location / { proxy_pass http://0.0.0.0:80; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } } 3、进入到nginx目录执行sbin/nginx执行二进制文件启动nginx服务，如果修改了conf配置文件，则执行sbin/nginx -s reload 刷新配置。至此，nginx服务便搭建好了。在微信小程序开发设置里面配置好https的域名地址，就可以愉快的玩耍了。","link":"/20191024/nginx%E6%90%AD%E5%BB%BAhttps%E6%9C%8D%E5%8A%A1.html"},{"title":"mysql慢查询语句分析总结","text":"我们经常会接触到MySQL，也经常会遇到一些MySQL的性能问题。我们可以借助慢查询日志和explain命令初步分析出SQL语句存在的性能问题 通过SHOW FULL PROCESSLIST查看问题SHOW FULL PROCESSLIST相当于select * from information_schema.processlist可以列出正在运行的连接线程， 说明： id 连接id，可以使用kill+连接id的方式关闭连接(kill 9339) user显示当前用户 host显示连接的客户端IP和端口 db显示进程连接的数据库 command显示当前连接的当前执行的状态，sleep、query、connect time显示当前状态持续的时间(秒) state显示当前连接的sql语句的执行状态，copying to tmp table、sorting result、sending data等 info显示sql语句,如果发现比较耗时的语句可以复制出来使用explain分析。 慢查询日志慢查询日志是MySQL用于记录响应时间超过设置阈值(long_query_time)的SQL语句，默认情况下未开启慢查询日志，需要手动配置。下面我们要记住几个常用的属性: slow_query_log:是否开启慢查询(ON为开启，OFF则为关闭) long_query_time:慢查询阀值，表示SQL语句执行时间超过这个值就会记录,默认为10s slow_query_log_file:慢查询日志存储的文件路径 log_queries_not_using_indexes: 记录没有使用索引查询语句(ON为开启,OFF为关闭) log_output:日志存储方式(FILE表示将日志写入文件,TABLE表示写入数据库中，默认值为FILE,如果存入数据库中，我们可以通过select * from mysql.slow_log的方式去查询，一般性能要求相对较高的建议存文件) 我们可以通过show variables like ‘%关键字%’的方式查询我们设置的属性值我们有两种方式设置我们的属性,一种是set global 属性=值的方式(重启失效)，另一种是配置文件(重启生效)命令方式: 123set global slow_query_log=1;set global long_query_time=1; set global slow_query_log_file=&apos;mysql-slow.log&apos; 配置文件方式: 1234slow_query_log = &apos;ON&apos;slow_query_log_file = D:/Tools/mysql-8.0.16/slow.loglong_query_time = 1log-queries-not-using-indexes pt-qurey-digest分析慢查询语句percona-toolkit包含了很多实用强大的mysql工具包，pt-qurey-digest只是其中一个用于分析慢查询日志是工具。需要去官网下载,使用方法也很简单: 1./pt-query-digest slow2.log &gt;&gt; slow2.txt 即可得出一个分析结果: 12345678910111213141516171819202122232425262728293031323334# Query 9: 0.00 QPS, 0.00x concurrency, ID 0xF914D8CC2938CE6CAA13F8E57DF04B2F at byte 499246# This item is included in the report because it matches --limit.# Scores: V/M = 0.22# Time range: 2019-07-08T03:56:12 to 2019-07-12T00:46:28# Attribute pct total min max avg 95% stddev median# ============ === ======= ======= ======= ======= ======= ======= =======# Count 8 69# Exec time 1 147s 1s 3s 2s 3s 685ms 2s# Lock time 0 140ms 2ms 22ms 2ms 3ms 2ms 2ms# Rows sent 0 0 0 0 0 0 0 0# Rows examine 0 23.96M 225.33k 482.77k 355.65k 462.39k 81.66k 345.04k# Query size 2 17.72k 263 263 263 263 0 263# String:# Databases xxxx# Hosts xx.xxx.xxx.xxx# Users root# Query_time distribution# 1us# 10us# 100us# 1ms# 10ms# 100ms# 1s ################################################################# 10s+# Tables# SHOW TABLE STATUS FROM `xxxx` LIKE &apos;xxxxx_track_exec_channel&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxxxxx_exec_channel`\\G# SHOW TABLE STATUS FROM `xxx` LIKE &apos;xxxxx_TRACK_ASSIGN&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxx_EFFECTIVE_TRACK_ASSIGN`\\G# SHOW TABLE STATUS FROM `xxx` LIKE &apos;xxxx_task_exec&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxx_task_exec`\\GUPDATExxxxxx_effective_track_exec_channel a SET EXEC_CHANNEL_CODE=(SELECT GROUP_CONCAT(DISTINCT(channel_id)) FROM xxxxxx_EFFECTIVE_TRACK_ASSIGN WHERE status in (1,2,4) AND id IN (SELECT assgin_id FROM xxxxxx_task_exec WHERE task_id=a.task_id))\\G explain分析SQL语句上面几点大概的介绍到了几种获取慢查询SQL语句的方式，现在，我们就需要借助explain来分析查找SQL语句慢的原因。explain使用也很简单，直接在SELECT|UPDATE等语句前加上EXPLAIN即可 id表的执行顺序，复制的sql语句往往会分为很多步,序号越大越先执行,id相同执行顺序从上往下 select_type数据读取操作的操作类型: SIMPLE(简单SELECT，不使用UNION或子查询等) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY) UNION(UNION中的第二个或后面的SELECT语句) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select) SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询) DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询) DERIVED(派生表的SELECT, FROM子句的子查询) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) table数据来源于那张表，关联等复杂查询时会用临时虚拟表 type检索数据的方式 system:表只有一行记录 const:通过索引查找并且一次性找到 eq_ref:唯一性索引扫描 ref:非唯一行索引扫描 range:按范围查找 index:遍历索引树 all:全表扫描 possible_keys显示可能使用的索引 Key实际使用的索引 key_len索引的长度，一般来说，长度越短越好 ref列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows估算查找的结果记录条数 ExtraSQL查询的详细信息 Using where:表示使用where条件过滤 Using temporary:使用了临时表暂存结果 Using filesort:说明mysql对数据使用一个外部索引排序。未按照表内的索引顺序进行读取。 Using index:表示select语句中使用了覆盖索引，直接从索引中取值 Using join buffer:使用了连接缓存 Using index condition:表示查询的列有非索引的列 [参考]MySQL Explain详解","link":"/20191126/mysql-slow-explain.html"},{"title":"Hexo静态网页上传到七牛云","text":"很多人都是把Hexo、hugo等工具生成的静态页面都是上传到Github,这样虽然很方便，但是毕竟在国外，而且百度爬虫老是失败，虽然有盆友说可以上传到Gitee上，域名识别不同的访问线路解析不同的空间。我也这样搞过，但是最近发现，好像七牛云可以托管静态页面。那么就来搞搞咯 要上传到七牛云，当然得有个七牛云账号啦，这个没有的自己去搞一下，就不说了。下面我们来说说具体的操作。 配置对象空间 新建一个对象空间 在空间设置中打开【默认首页设置】 安装七牛云上传工具qshell是利用七牛文档上公开的API实现的一个方便开发者测试和使用七牛API服务的命令行工具,下载qshell,下载之后解压， 文件名 描述 qshell_linux_x86 Linux 32位系统 qshell_linux_x64 Linux 64位系统 qshell_windows_x86.exe Windows 32位系统 qshell_windows_x64.exe Windows 64位系统 qshell_darwin_x64 Mac 64位系统，主流的系统 我这里是Win10-X64,所以下载后重命名qshell_windows_x64.exe为qshell.exe,在环境变量中配置qshell文件路径 上传文件到七牛云首选需要添加账号: 1qshell account &lt;Your AccessKey&gt; &lt;Your SecretKey&gt; &lt;Your Name&gt; qshell有qupload配置文件方式和qupload2命令行方式，具体操作去https://github.com/qiniu/qshell查看详细文档，这里我更倾向于命令行: 1qshell qupload2 --src-dir=E:/hexo/hexo/public --bucket=空间名 配置域名 进入域名管理 新增域名,输入域名点击创建 创建成功后，会有一个CNAME，复制CNAME去解析域名: 回到七牛云的内容空间，设置默认域名这时候，我们的博客就可以正常访问了 小技巧:我们可以再package.json自定义一个我们的命令, 如下: 1234567&quot;scripts&quot;: { &quot;build&quot;: &quot;hexo generate&quot;, &quot;clean&quot;: &quot;hexo clean&quot;, &quot;deploy&quot;: &quot;hexo deploy&quot;, &quot;server&quot;: &quot;hexo server&quot;, &quot;d&quot;:&quot;hexo clean &amp; hexo g &amp; hexo d &amp; qshell qupload2 --overwrite=true --rescan-local=true --src-dir=E:/hexo/hexo/public --bucket=七牛云空间名称&quot; }, 这时候我们在命令行执行npm run d 即可清理、生成、上传文件啦","link":"/20191208/upload-blog-2-qiniu.html"},{"title":".net core 3.x Web API使用Swagger添加多版本以及JWT Authorization","text":"很多时候，要给我们的接口升级，但是又怕影响之前的接口业务或者是要开发特定的接口，我们会给接口加上一个版本号，保障老接口依然能稳定运行，例如百度的坐标转换服务 1http://api.map.baidu.com/geoconv/v1/?coords=114.21892734521,29.575429778924&amp;from=1&amp;to=5&amp;ak=你的密钥 //GET请求 在.net core中，想给接口加上版本号，有多种方式: 1、通过URL Path Segment来实现; 2、通过HTTP Headers来实现; 3、通过QueryString来实现;具体的实现可以去百度或者bing。这里暂时只讲swagger doc实现多版本切换。我个人喜欢使用第一种方式。 ApiExplorer组件的使用在实现多版本Web API，我们需要借助一个组件: 1Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer 成功添加依赖包后，就可以在程序中使用相应的API了，首先我们先创建如下的目录结构(大家可随意):接下来，就将我们之前的Controller类上添加相应的特性: 1234//当前Controller的版本号[ApiVersion(&quot;1.0&quot;)]//接口访问路径[Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] 然后在Startup的ConfigureServices中使用ApiExplorer 12services.AddApiVersioning();services.AddVersionedApiExplorer(options =&gt; options.GroupNameFormat = &quot;&apos;v&apos;VVV&quot;); Swagger中多版本API文档下面，我就用Swagger来自动生成多版本文档，为了使我的Startup类相对简洁，我们新建一个ConfigureSwaggerOptions类来放置Swagger的相关配置,完整代码如下： 1234567891011121314151617181920212223242526272829public class ConfigureSwaggerOptions : IConfigureOptions&lt;SwaggerGenOptions&gt; { readonly IApiVersionDescriptionProvider provider; public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) =&gt; this.provider = provider; public void Configure(SwaggerGenOptions options) { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerDoc(description.GroupName, new OpenApiInfo { Description = $&quot;Demo API {description.ApiVersion} Description&quot;, Version = description.ApiVersion.ToString(), Title = $&quot;Demo API 文档{description.ApiVersion}&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; }, License = new OpenApiLicense { Name = &quot;Apache 2.0&quot;, Url = new Uri(&quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;) } }); } var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); options.IncludeXmlComments(docXmlPath); } } 修改Startup类ConfigureServices中: 12services.AddTransient&lt;IConfigureOptions&lt;SwaggerGenOptions&gt;, ConfigureSwaggerOptions&gt;();services.AddSwaggerGen(); Configure中 1234567891011121314151617181920212223242526272829public void Configure(IApplicationBuilder app, IWebHostEnvironment env, IApiVersionDescriptionProvider provider) { if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(options =&gt; { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerEndpoint( $&quot;/swagger/{description.GroupName}/swagger.json&quot;, description.GroupName.ToUpperInvariant()); } }); app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); } 最终效果如下：可以点击Select a definition切换我们不同版本的doc 在Swagger中添加Header Authorization 一般情况下，我们的Web API是使用Jwt来保障接口安全，当然还有很多其他的方式，我只是选择一种相对简单一些的方式。这里只是说怎么在Swagger调试的时候带上我们的Jwt Token，具体的Jwt实现，也请自己实现。 其实Swashbuckle已经给我们提供了很方便的API，只需要配置一下即可: 123456789101112131415161718options.AddSecurityDefinition(&quot;bearer&quot;, new OpenApiSecurityScheme { Type = SecuritySchemeType.Http, In = ParameterLocation.Header, Name = &quot;Authorization&quot;, Scheme = &quot;bearer&quot;, BearerFormat = &quot;JWT&quot;, Description = &quot;JWT Authorization header using the Bearer scheme.&quot;, }); var req = new OpenApiSecurityRequirement(); req.Add(new OpenApiSecurityScheme { Reference = new OpenApiReference { Type = ReferenceType.SecurityScheme, Id = &quot;bearer&quot; } }, new[] { &quot;&quot; }); options.AddSecurityRequirement(req); 效果如下:我们会看到有一个Authorization的按钮，我们点击可以输入我们获取到的Jwt Token,在文本框内不需要输入Bearer关键字，Swagger会自动为我们加上Bearer关键字。在这里也需要注意到Swagger的坑，因为大写的问题可能会导致Authorization无法添加到request请求头中.下面是Swagger的build-request.js 123456789101112131415161718else if (type === &apos;http&apos;) { if (schema.scheme === &apos;basic&apos;) { let scheme = schema.scheme; if (scheme) { scheme = scheme.toLowerCase() } if (scheme === &apos;basic&apos;) { const {username, password} = value const encoded = btoa(`${username}:${password}`) result.headers.Authorization = `Basic ${encoded}` } if (schema.scheme === &apos;bearer&apos;) { if (scheme === &apos;bearer&apos;) { result.headers.Authorization = `Bearer ${value}` } } 大家可以自己去看看代码，我继续说Authorization的设置，点击按钮就会出现设置token的文本框:设置完后，我们的小锁会变为关闭状态:最后就可以通过Swagger UI调用我们的接口，就可以在我们的请求中看到Authorization的参数内容，后端就可以接受处理.当然，Swagger还有其他的自定义UI功能，大家可以去官网查询相关文档。","link":"/20191118/swagger-add-apiversion.html"},{"title":".net core3.x发布到Docker运行","text":"我们开发完之后，需要进行发布部署，一般高端的公司是采用CI/CD方式自动发布，但是我所处的公司都是使用手动发布，之前我都是输入命令的方式: 1dotnet publish -c Release -r win7-x64 -o ./bin/output 执行之后就会在相应目录生成所有dll 随迎时代潮流，我们也该有些骚气的操作了，这次咱们就把.net core3.x采用docker发布，因为我的电脑无法安装docker： 那么就想到要么先publish然后把DLL构建成docker镜像，要么就直接通过源码构建镜像，我就偷偷懒，选择后者。那么首先在vs添加【Docker支持】-&gt;【Linux】就会生成一个Dockerfile: 1234567891011121314151617181920212223242526FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim AS baseWORKDIR /appEXPOSE 80EXPOSE 443FROM mcr.microsoft.com/dotnet/core/sdk:3.0-buster AS build# 相当于cd /srcWORKDIR /src# 将当前本地Web/Web.csproj 复制到/src/Web/目录下COPY [&quot;Web/Web.csproj&quot;, &quot;Web/&quot;]# 还原项目依赖库RUN dotnet restore &quot;Web/Web.csproj&quot;将当前本地目录复制到/srcCOPY . .WORKDIR &quot;/src/Web&quot;RUN dotnet build &quot;Web.csproj&quot; -c Release -o /app/buildFROM build AS publishRUN dotnet publish &quot;Web.csproj&quot; -c Release -o /app/publishFROM base AS finalWORKDIR /app# 从编译阶段的中的publish层镜像拷贝/app/publish目录到/app目录下COPY --from=publish /app/publish .COPY [&quot;Web/Web.xml&quot;, &quot;.&quot;]ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] 如果你是提前编译好的，那么可以将Dockerfile修改一下: 12345678FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim EXPOSE 80EXPOSE 443COPY . /appWORKDIR /appENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] 我们将整个源码复制到Centos服务器上,cd到dockerfile目录执行命令: 1docker build -t core3.x-swagger -f Dockerfile . 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071Sending build context to Docker daemon 40.45kBStep 1/17 : FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim AS base ---&gt; 880d85db3775Step 2/17 : WORKDIR /app ---&gt; Using cache ---&gt; 2686a6832749Step 3/17 : EXPOSE 80 ---&gt; Using cache ---&gt; f910a2eacda4Step 4/17 : EXPOSE 443 ---&gt; Using cache ---&gt; a157473c89eeStep 5/17 : FROM mcr.microsoft.com/dotnet/core/sdk:3.0-buster AS build ---&gt; a345b68a725eStep 6/17 : WORKDIR /src ---&gt; Using cache ---&gt; 8b2a2b0743f5Step 7/17 : COPY [&quot;Web/Web.csproj&quot;, &quot;Web/&quot;] ---&gt; 29f558699c69Step 8/17 : RUN dotnet restore &quot;Web/Web.csproj&quot; ---&gt; Running in 31e08f04df6c Restore completed in 1.4 min for /src/Web/Web.csproj.Removing intermediate container 31e08f04df6c ---&gt; ed0f20f4056aStep 9/17 : COPY . . ---&gt; 1999712c7eceStep 10/17 : WORKDIR &quot;/src/Web&quot; ---&gt; Running in 6d81af8f98dcRemoving intermediate container 6d81af8f98dc ---&gt; b31d42182d2aStep 11/17 : RUN dotnet build &quot;Web.csproj&quot; -c Release -o /app/build ---&gt; Running in b2c16188ce9aMicrosoft (R) Build Engine version 16.3.2+e481bbf88 for .NET CoreCopyright (C) Microsoft Corporation. All rights reserved. Restore completed in 29.82 ms for /src/Web/Web.csproj. Web -&gt; /app/build/Web.dllBuild succeeded. 0 Warning(s) 0 Error(s)Time Elapsed 00:00:04.89Removing intermediate container b2c16188ce9a ---&gt; b249fe8e976bStep 12/17 : FROM build AS publish ---&gt; b249fe8e976bStep 13/17 : RUN dotnet publish &quot;Web.csproj&quot; -c Release -o /app/publish ---&gt; Running in 43766cf2eb2dMicrosoft (R) Build Engine version 16.3.2+e481bbf88 for .NET CoreCopyright (C) Microsoft Corporation. All rights reserved. Restore completed in 35.91 ms for /src/Web/Web.csproj. Web -&gt; /src/Web/bin/Release/netcoreapp3.0/Web.dll Web -&gt; /app/publish/Removing intermediate container 43766cf2eb2d ---&gt; e07c5fc08616Step 14/17 : FROM base AS final ---&gt; a157473c89eeStep 15/17 : WORKDIR /app ---&gt; Running in 3ab7aca5e289Removing intermediate container 3ab7aca5e289 ---&gt; 0b7196de9a3fStep 16/17 : COPY --from=publish /app/publish . ---&gt; 6178981834aeStep 17/17 : ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] ---&gt; Running in 488f804c2854Removing intermediate container 488f804c2854 ---&gt; 5aa2ed7e047fSuccessfully built 5aa2ed7e047fSuccessfully tagged core3.x-swagger:latest 生成之后便可以查询到我们的镜像文件: 123[root@VM_175_142_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcore3.x-swagger latest 5aa2ed7e047f 2 minutes ago 237MB 我们可以运行我们的image镜像文件了： 12# 将容器80端口映射到宿主机的9999端口docker run --name swagger -d -p 9999:80 core3.x-swagger 但是当我访问的时候并没有给我惊喜，而是令人头皮发麻的服务端500错误,那么我们就去看看容器的日志吧: 1docker logs 083d0c79c078 错误日志如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980info: Microsoft.Hosting.Lifetime[0] Now listening on: http://[::]:80info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down.info: Microsoft.Hosting.Lifetime[0] Hosting environment: Productioninfo: Microsoft.Hosting.Lifetime[0] Content root path: /appfail: Microsoft.AspNetCore.Server.Kestrel[13] Connection id &quot;0HLRJSUAI4BAT&quot;, Request id &quot;0HLRJSUAI4BAT:00000001&quot;: An unhandled exception was thrown by the application.System.IO.FileNotFoundException: Could not find file &apos;/app/Web.xml&apos;.File name: &apos;/app/Web.xml&apos; at Interop.ThrowExceptionForIoErrno(ErrorInfo errorInfo, String path, Boolean isDirectory, Func`2 errorRewriter) at Microsoft.Win32.SafeHandles.SafeFileHandle.Open(String path, OpenFlags flags, Int32 mode) at System.IO.FileStream.OpenHandle(FileMode mode, FileShare share, FileOptions options) at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options) at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize) at System.Xml.XmlDownloadManager.GetStream(Uri uri, ICredentials credentials, IWebProxy proxy, RequestCachePolicy cachePolicy) at System.Xml.XmlUrlResolver.GetEntity(Uri absoluteUri, String role, Type ofObjectToReturn) at System.Xml.XmlTextReaderImpl.OpenUrl() at System.Xml.XmlTextReaderImpl.Read() at System.Xml.XPath.XPathDocument.LoadFromReader(XmlReader reader, XmlSpace space) at System.Xml.XPath.XPathDocument..ctor(String uri, XmlSpace space) at System.Xml.XPath.XPathDocument..ctor(String uri) at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.&lt;&gt;c__DisplayClass23_0.&lt;IncludeXmlComments&gt;b__0() at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.IncludeXmlComments(SwaggerGenOptions swaggerGenOptions, Func`1 xmlDocFactory, Boolean includeControllerXmlComments) at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.IncludeXmlComments(SwaggerGenOptions swaggerGenOptions, String filePath, Boolean includeControllerXmlComments) at Microsoft.Extensions.Options.OptionsFactory`1.Create(String name) at Microsoft.Extensions.Options.OptionsManager`1.&lt;&gt;c__DisplayClass5_0.&lt;Get&gt;b__0() at System.Lazy`1.ViaFactory(LazyThreadSafetyMode mode) at System.Lazy`1.ExecutionAndPublication(LazyHelper executionAndPublication, Boolean useDefaultConstructor) at System.Lazy`1.CreateValue() at System.Lazy`1.get_Value() at Microsoft.Extensions.Options.OptionsCache`1.GetOrAdd(String name, Func`1 createOptions) at Microsoft.Extensions.Options.OptionsManager`1.Get(String name) at Microsoft.Extensions.Options.OptionsManager`1.get_Value() at Swashbuckle.AspNetCore.SwaggerGen.ConfigureSchemaGeneratorOptions..ctor(IServiceProvider serviceProvider, IOptions`1 swaggerGenOptionsAccessor) at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions) at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitIEnumerable(IEnumerableCallSite enumerableCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitNoCache(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.&lt;&gt;c__DisplayClass1_0.&lt;RealizeService&gt;b__0(ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType) at Microsoft.AspNetCore.Builder.UseMiddlewareExtensions.GetService(IServiceProvider sp, Type type, Type middleware) at lambda_method(Closure , Object , HttpContext , IServiceProvider ) at Microsoft.AspNetCore.Builder.UseMiddlewareExtensions.&lt;&gt;c__DisplayClass4_1.&lt;UseMiddleware&gt;b__2(HttpContext context) at Microsoft.AspNetCore.Mvc.Versioning.ApiVersioningMiddleware.InvokeAsync(HttpContext context) at Microsoft.AspNetCore.HostFiltering.HostFilteringMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.Hosting.HostingApplication.ProcessRequestAsync(Context context) at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests[TContext](IHttpApplication`1 application)fail: Microsoft.AspNetCore.Server.Kestrel[13] 很明显，是因为publish的时候没有把我们的Web.xml文件复制进去,那么我们在Dockerfile中添加一条 1COPY [&quot;Web/Web.xml&quot;, &quot;.&quot;] 在把之前是容器删除掉: 1docker rm 083d0c79c078 然后重新build一次 1docker build -t core3.x-swagger -f Dockerfile . 重启启动容器,很好，是想要的结果: 123[root@VM_175_142_centos Swagger.Demo]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb475841bece6 core3.x-swagger &quot;dotnet Web.dll&quot; 3 minutes ago Up 3 minutes 443/tcp, 0.0.0.0:9999-&gt;80/tcp swagger 后面，我们尝试使用腾讯云容器服务（Tencent Kubernetes Engine ，TKE）或者阿里容器服务 Kubernetes 版（简称 ACK）来部署我们的Docker镜像","link":"/20191128/net-core3-x-publish.html"},{"title":"微信小程序上传图片到七牛云","text":"微信小程序上传图片到七牛云,小程序Webview嵌入H5上传图片&amp;原生小程序上传图片 最近在帮朋友做微信小程序，没有选择mpvue，因为时间紧加上不熟悉，怕遇到坑不能快速处理，拖了进度，所以采用了原生小程序+webview的方式做了第一版。 小程序webview上传图片因为涉及到H5，所以图片上传这块就用到了微信中的jssdk， 第一步是wx.config配置前端代码如下: 123456789101112131415161718192021222324252627282930313233343536373839abp.services.app.wxAccess.getOfficialAccountJsdkConfig().done(function (data) { if (data) { var appId = data.appId; var timestamp = data.timestamp; var nonceStr = data.noncestr; var signature = data.signature; wx.config({ debug: false, //调试模式 当为tru时，开启调试模式 appId: appId, timestamp: timestamp.toString(), //签名时间戳 nonceStr: nonceStr, //生成签名的随机串 signature: signature, //签名 jsApiList: [&apos;chooseImage&apos;, &apos;uploadImage&apos;], success: function () { alert(&quot;配置成功&quot;); }, fail: function () { alert(&quot;配置失败&quot;); } }); wx.ready(function () { // 在这里调用 API wx.checkJsApi({ jsApiList: [ &apos;chooseImage&apos;, &apos;uploadImage&apos; ], success: function (res) { //console.log(JSON.stringify(res)); } }); }); wx.error(function(res){ alert(JSON.stringify(res)); }); } }); 后端代码： 1234567891011121314151617181920212223242526272829303132/// &lt;summary&gt;/// 获取公众号JsdkConfig/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public async Task&lt;Dtos.GetOfficialAccountJsdkConfigOutput&gt; GetOfficialAccountJsdkConfig() { var input = new Dtos.GetAccessInput { AppId = _appConfiguration[&quot;WechatOfficialAccount:AppId&quot;], Secret = _appConfiguration[&quot;WechatOfficialAccount:Secret&quot;] }; var noncestr = Guid.NewGuid().ToString(&quot;N&quot;); var jsapi = await GetJsapiTicket(input); //var timestamp = (DateTime.Now.Ticks - new DateTime(1970, 1, 1, 0, 0, 0, 0).Ticks) / 10000000; var timestamp = new Helper.UnixTime().DateTimeToUnix(DateTime.Now); //var url = Request.UrlReferrer.OriginalString; var url = _iHttpContextAccessor.HttpContext.Request.Headers[Microsoft.Net.Http.Headers.HeaderNames.Referer].ToString(); var shaStr = $&quot;jsapi_ticket={jsapi.Permit}&amp;noncestr={noncestr}&amp;timestamp={timestamp}&amp;url={url}&quot;; var signature = new Helper.Encrypt().Sha1Encrypt(shaStr); return new Dtos.GetOfficialAccountJsdkConfigOutput { AppId = input.AppId, Noncestr = noncestr, Timestamp = timestamp, Signature = signature }; } 第二步就是调用jssdk前端js代码如下： 123456789101112131415161718192021222324252627282930313233wx.chooseImage({ count: 9, needResult: 1, sizeType: [&apos;original&apos;, &apos;compressed&apos;], // 可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], // 可以指定来源是相册还是相机，默认二者都有 success: function (data) { //localIds = data.localIds[0]; // 返回选定照片的本地ID列表，localId可以作为img标签的src属性显示图片 for (var localId = 0; localId &lt;= data.localIds.length - 1; localId++) { if (isIOS) { wx.getLocalImgData({ localId: data.localIds[localId], // 图片的localID success: function (res) { // var localData = res.localData; // localData是图片的base64数据，可以用img标签显示 //console.log(localData); } }); } else { } } }, fail: function (res) { alert(JSON.stringify(res)); //alterShowMessage(&quot;操作提示&quot;, JSON.stringify(res), &quot;1&quot;, &quot;确定&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;); } }); jssdk中，如果是iOS的话，前端无法直接使用localIds资源id做展示，需要调用wx.getLocalImgData方法来获取图片的base64编码 提交前端选择的图片到服务端并由服务的上传到七牛云前端部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546wx.uploadImage({ //获取图片媒体ID localId: localIds[erp.common.idx].toString(), // 需要上传的图片的本地ID isShowProgressTips: 1, // 默认为1，显示进度提示 success: function (res) { //获取成功 // 上传序号，上传一张 累计 +1 erp.common.idx++; //存储图片媒体ID，用，号分割 // serverIds += res.serverId + &apos;,&apos;; erp.common.serverIdsArr.push(res.serverId); if (erp.common.idx &lt; localIds.length) { //本地图片ID 还没全部获取完图片媒体ID //调用上传递归函数 erp.common.wxUploadImg(localIds, callback); } else { //上传序号归零 erp.common.idx = 0; //服务器csrf 验证字符串，如果后端框架没开启csrf，则不需要 //alert(erp.common.serverIdsArr); abp.services.app.wxAccess.uploadMediaToQiniu({ WxMediaIds: mediaIds }).done(function (data) { var imageUrl = []; for (var index = 0; index &lt;= data.qiniuFiles.length - 1; index++) { imageUrl.push(data.qiniuFiles[index].qiniuUrl); } $.hideLoading(); callback &amp;&amp; callback(imageUrl); }).always(function(){ $.hideLoading(); }); //serverIds = &apos;&apos;; erp.common.serverIdsArr.length = 0; return true; } }, fail: function (res) { //获取多媒体id失败 返回错误代码 alert(&quot;上传失败，msg：&quot; + JSON.stringify(res)); } }); 后端部分代码: 1234567891011121314151617181920212223242526272829303132333435/// &lt;summary&gt;/// 上传文件到七牛/// &lt;/summary&gt;/// &lt;param name=&quot;input&quot;&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;//[RemoteService(false)]public async Task&lt;Dtos.UploadMediaToQiniuOutput&gt; UploadMediaToQiniu(Dtos.UploadMediaToQiniuInput input){ var output = new Dtos.UploadMediaToQiniuOutput(); if (input.WxMediaIds.Count &gt; 0) { output.QiniuFiles = new System.Collections.Generic.List&lt;Dtos.QiniuFile&gt;(); var access_token = await GetOfficialAccountAccessToken(); var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var prefixPath = _appConfiguration[&quot;Qny:prefixPath&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); foreach (var mediaId in input.WxMediaIds) { var url = $&quot;https://api.weixin.qq.com/cgi-bin/media/get?access_token={access_token.Permit}&amp;media_id={mediaId}&quot;; var fileKey = qiniuStorage.UploadStream(url); var fileUrl = $&quot;{prefixPath}/{fileKey}&quot;; output.QiniuFiles.Add(new Dtos.QiniuFile { QiniuUrl = fileUrl, WxMediaId = mediaId }); } } return output;} 原生小程序上传图片到七牛云后面考虑到一些交互上面的问题，就把原来的webview方式改成了全原生的模式。采用原生的方式，在图片上传上面就好处理多了，只需要实现获取到七牛云用于上传的token，然后使用wx.uploadFile即可上传。服务端获取token代码： 12345678910111213/// &lt;summary&gt;/// 获取七牛token/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public QiniuTokenOutputDto GetQiniuUpToken(){ var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); var output = new QiniuTokenOutputDto() { UpToken = qiniuStorage.CreateUploadToken() }; return output;} 小程序端部分代码: 12345678910111213141516171819202122232425262728293031323334353637383940411、获取token2、调用小程序API，选择图片。 wx.chooseImage({ count: 9-this.data.cardImgList.length, //默认9 sizeType: [&apos;original&apos;, &apos;compressed&apos;], //可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], //从相册选择 success: (res) =&gt; { res.tempFilePaths.forEach((item,index)=&gt;{ that.upload2Qiniu(item); }); } }); } /*** 图片上传七牛云*/ upload2Qiniu(tempFilePaths) { let token = this.data.token; var that = this; wx.uploadFile({ url: &apos;https://up-z0.qiniup.com&apos;, name: &apos;file&apos;, filePath: tempFilePaths, header: { &quot;Content-Type&quot;: &quot;multipart/form-data&quot; }, formData: { token: that.data.upToken, }, success: function (res) { let data = JSON.parse(res.data) //data.hash图片的资源名，可直接通过域名加资源名访问 // to do ... }, fail: function (res) { console.log(res) } }); } 如果需要更详细的资料，那么就请自行百度or谷歌吧","link":"/20191024/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E5%88%B0%E4%B8%83%E7%89%9B%E4%BA%91.html"},{"title":"基于redis key失效机制实现状态实时更新","text":"基于redis key失效事件通知机制来处理状态实时更新 在我们的业务中，有这样一个场景，在手机端实时采集用用户经纬度，判断用户是否在某个场景(小区、商场等)内,如果再场景内则变更用户任务状态为”执行中”，当用户离开场景超过20分钟，需要将用户任务状态更改为”离场”状态。 一般，我们更新状态，要么定时去扫描数据库，要么就是触发某个事件，在最开始，有想到几种方案：1、定时（采用quartz定时执行作业，去扫描数据库）2、用hangfire、rabbitmq等实现延迟执行3、redis key失效事件，实时处理经过评估，最后选择了redis key失效机制来处理这个业务。 redis key失效事件监听redis自2.8之后就提供Keyspace Notifications功能，允许客户订阅Pub/Sub。 开启事件通知默认情况下，redis是没有开启事件通知的，所以我们需要手动配置： 12打开redis.conf配置文件搜索notify-keyspace-events，该配置默认是被注释掉的，需要将其修改为notify-keyspace-events Ex ,然后重启便可生效 值说明: 1234567891011# K 键空间通知，以__keyspace@&lt;db&gt;__为前缀# E 键事件通知，以__keysevent@&lt;db&gt;__为前缀# g del , expipre , rename 等类型无关的通用命令的通知, ...# $ String命令# l List命令# s Set命令# h Hash命令# z 有序集合命令# x 过期事件（每次key过期时生成）# e 驱逐事件（当key在内存满了被清除时生成）# A g$lshzxe的别名，因此”AKE”意味着所有的事件 spring boot实现消息监听器类pom.xml: 12345678910111213141516171819202122 &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.12&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Componentpublic class RedisMsgPubSubListener extends JedisPubSub { private Logger logger = LoggerFactory.getLogger(getClass()); @Autowired ITaskService taskService; @Override public void unsubscribe() { super.unsubscribe(); } @Override public void unsubscribe(String... channels) { super.unsubscribe(channels); } @Override public void subscribe(String... channels) { super.subscribe(channels); } @Override public void psubscribe(String... patterns) { super.psubscribe(patterns); } @Override public void punsubscribe() { super.punsubscribe(); } @Override public void punsubscribe(String... patterns) { super.punsubscribe(patterns); } @Override public void onMessage(String channel, String message) { System.out.println(&quot;channel:&quot; + channel + &quot;receives message :&quot; + message); String key = message; } @Override public void onPMessage(String pattern, String channel, String message) { } @Override public void onSubscribe(String channel, int subscribedChannels) { } @Override public void onPUnsubscribe(String pattern, int subscribedChannels) { } @Override public void onPSubscribe(String pattern, int subscribedChannels) { } @Override public void onUnsubscribe(String channel, int subscribedChannels) { }} 创建一个Runner： 123456789101112131415161718192021public class RedisApplicationRunner implements ApplicationRunner { @Autowired RedisMsgPubSubListener redisMsgPubSubListener; @Autowired JedisPool jedisPool; @Override public void run(ApplicationArguments applicationArguments) throws Exception { Jedis jedis = jedisPool.getResource();// jedis.set(&quot;zhcj:mobile:13548074395:2018122222212&quot;,&quot;1&quot;);// jedis.expire(&quot;zhcj:mobile:13548074395:2018122222212&quot;,10); jedis.subscribe(redisMsgPubSubListener, &quot;__keyevent@0__:expired&quot;); }} 最终效果:","link":"/20191024/%E5%9F%BA%E4%BA%8Eredis-key%E5%A4%B1%E6%95%88%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0.html"},{"title":"使用Lombok简化java代码","text":"Lombok是一款提高javaer开发效率的插件工具，特别是在繁多是bean类中的getter、setter，使用Lombok可以使用注解的方式省去了添加getter、setter的时间 在使用Lombok之前，需要在IDE上安装插件，eclipse安装步骤稍微多一点，具体请自行百度或者去官方查看https://projectlombok.org/features/configuration，IntelliJ安装就相对来说比较方便，直接在插件中心搜索Lombok,安装Lombok Plugin即可。接下来，我们在程序中引入jar包： 1234567&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 我们平时的POJO类一般都是这样写: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { } public String getUserName() { return this.userName; } public void setUserName(String userName) { this.userName = userName; } public String getOperator() { return this.operator; } public void setOperator(String operator) { this.operator = operator; } public String getSource() { return this.source; } public void setSource(String source) { this.source = source; } public String getDisplayName() { return this.displayName; } public void setDisplayName(String displayName) { this.displayName = displayName; } public String getFilePath() { return this.filePath; } public void setFilePath(String filePath) { this.filePath = filePath; } public String getCreator() { return this.creator; } public void setCreator(String creator) { this.creator = creator; } public Timestamp getStartTime() { return this.startTime; } public void setStartTime(Timestamp startTime) { this.startTime = startTime; } public Timestamp getCreateTime() { return this.createTime; } public void setCreateTime(Timestamp createTime) { this.createTime = createTime; } public long getFileSize() { return this.fileSize; } public void setFileSize(long fileSize) { this.fileSize = fileSize; }} 如果属性更多的话，添加getter、setter就需要花更多的时间。如果使用Lombok插件的话，不仅可以节省时间，而且代码也更加简洁: 1234567891011121314151617181920public class DataFileDownloadAudit { @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private Timestamp startTime; @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { }} 这样只是给属性加getter、setter，我们也可以用@Data来继续简化: 123456789101112@Datapublic class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime;} 这两种方式有什么差异呢？@Getter和@Setter是作用在bean属性上，可以自动生成getter、setter方法，@Data是作用在类上，他结合了@ToString, @EqualsAndHashCode, @Getter,@Setter,@RequiredArgsConstructor注解的功能。这仅仅说了Lombok两个常用的注解，总的来说，它会给我们带来更加简洁的代码和快速的开发效率，其他更加强大的功能可以去https://projectlombok.org/features/all自行查看。","link":"/20191106/%E4%BD%BF%E7%94%A8Lombok%E7%AE%80%E5%8C%96java%E4%BB%A3%E7%A0%81.html"},{"title":"没有java源代码如何修改bug","text":"有时候遇到比较老的产品，公司的产品组也不提供维护了，更可恨的是，源代码也不给。在这种情况，遇到有bug，怎么办呢？ 我们项目组一直在维护着一个2013年基于公司老产品开发的项目，既然是产品，公司产品弄死不肯定提供老产品的代码，原因大概是因为代码管理混乱，已经找不到我们项目的代码了。 这个bug出现在数据授权的时候，按常规组织授权后，下级用户居然能看到上级用户数据，我们的数据授权原理是：获取授权用户所在层级，并获取当前的授权组织表，将组织表数据和当前用户进行匹配，并记录在授权表，然后，用户在查询数据的时候就读取授权表拼接in语句去数据库查询。当出现这个问题的时候，显然是不允许的，这时候，我们的检查步骤是：1、检查用户组织表2、检查授权表3、检查最终执行sql语句通过以上步骤，最终发现是在做sql拼接成in的条件的时候出现的问题，这时候，就只有进入到代码里面一探究竟，由于没有源代码，就只有借用各种反编译工具：1、Java Decompiler2、Jadclipse3、jad4、jd-gui…..等等，还有很多其他的，这里，我选用的是jd-gui，如果是用的idea作为IDE的话，可以直接查看。借助反编译工具反编译出来的代码如下： 12345678910111213141516171819202122static boolean userIsDept(JdbcTemplate sysJdbcTemplate, final String dept, String userId) { String sql = SQLProvider.getSQL(&quot;query.all.sub.dept&quot;); List&lt;String&gt; depts = (List)sysJdbcTemplate.query(sql, new PreparedStatementSetter() { public void setValues(PreparedStatement ps) throws SQLException { ps.setString(1, dept); ps.setString(2, dept); } }, new ResultSetExtractor&lt;List&lt;String&gt;&gt;() { public List&lt;String&gt; extractData(ResultSet rs) throws SQLException, DataAccessException { ArrayList trs = new ArrayList(); while(rs.next()) { trs.add(rs.getString(&quot;DEPT_ID&quot;)); } return trs; } }); String userDeptSql = SQLProvider.getSQL(&quot;query.user.dept&quot;); String userDeptId = (String)sysJdbcTemplate.queryForObject(userDeptSql, String.class, new Object[]{userId}); return depts.contains(userDeptId); } 经过分析，发现该处的组织id过多加载，因为在授权表中已经将当前用户所属组织的授权内容全量写进去，这儿过多加载，其实把父组织的授权内容也一并拼接到了in条件内，所以出现这种情况。最后，我通过idea新建一个java项目，把项目的依赖包添加进去，新建了一个同包名、同类名的类，将代码copy进新类，稍作修改，就可导出一个jar包。然后将class文件复制到原来的jar包中覆盖即可，在这里，一定要注意JDK版本，否者会报错。","link":"/20191105/%E6%B2%A1%E6%9C%89java%E6%BA%90%E4%BB%A3%E7%A0%81%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9bug.html"},{"title":"高德地图和google地图整合","text":"整合百度和google地图 因为高德地图的卫星地图不全，但是在高德地图没有的地方，google地图却有，所以客户有一个需求，就是当高德地图显示”无卫星地图”的时候，就显示google地图的图片。 求助万能的百度当然，因为对地图api不是很熟悉，所以就只有百度和看高德官方文档，但是都没有找到合适的解决方案，有看到叠加地图图层并自定义图片路径，这显然不适合我目前的场景，另外一个就是通过API来叠加地图，结合api判断大概的x-y-z的数值范围来加载不同的切片路径. 1234567891011google = new AMap.TileLayer({ map: map, zIndex: 70, //图块取图地址 getTileUrl: function (x, y, z) { //console.log(arguments); if (x &gt;= 12931 &amp;&amp; y &gt;= 3364 &amp;&amp; z &gt;= 16) return &quot;http://mt0.google.cn/vt/lyrs=s&amp;hl=zh-CN&amp;gl=cn&amp;x=&quot; + x + &quot;&amp;y=&quot; + y + &quot;&amp;z=&quot; + z + &quot;&amp;s=Galile&quot;; } }); 当然，这种方式解决起来并不优雅，而且客户也反馈过，很多地方google有卫星地图但是现在依然没有，因为如果要加载得更细，就要判断更多的xyz，所以处理起来也不方便。 突发奇想之后，突然想到，为何不在服务端来判断当前切片是否是正常的卫星地图切片，如果不是则去请求google地图的切片，采用这种方式的话，那么就需要修改jsapi，但是高德并不提供离线的js api，怎么办呢？ 当然办法是肯定有的，就是自己去下载一个高德js api，然后把卫星地图模式所指向的地址改为自己的服务端地址即可，项目中就引用自己下载的离线js。js api修改代码： 123456在离线js中查询关键字:autonavi.com/appmaptile?style=6可以找到这样的地址:http://webst0{1,2,3,4}.is.autonavi.com/appmaptile?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z]将其修改为自己的代理地址:http://211.137.xxx.xxx/map/?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z] 其他调用方式不变，使用这种方式之后，融合率几乎是99.99%，如果高德和google结合后还是有无卫星地图的情况，那我暂时也没想到比较好的处理方式了。最终效果如下:","link":"/20191024/%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BE%E5%92%8Cgoogle%E5%9C%B0%E5%9B%BE%E6%95%B4%E5%90%88.html"},{"title":"进程守护神器-PM2","text":"PM2是一个守护进程管理器，它可以帮助你管理和保持应用程序24/7在线,与PM2类似是进程守护工具还有Supervisor、Forever等，在此，我们先学习一下PM2。 安装PM2有两种方式，第一种就是基于NPM安装: 1npm install pm2 -g 另外一种就是直接下载: 1wget -qO- https://getpm2.com/install.sh | bash 我才用的后者: 12345678910[root@VM_175_142_centos ~]# wget -qO- https://getpm2.com/install.sh | bash&gt; Welcome to the PM2 auto installer┌─────┬───────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │└─────┴───────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2] Setting changedModule: pm2$ pm2 set pm2:autosave truePM2 Successfully installed 提示我们安装成功，我们来检验一下: 12[root@VM_175_142_centos ~]# pm2 -v4.2.1 这证明我们安装成功了。 PM2常用命令我们先来归纳一下常用的命令,后面部分会进入到实践操作环节。 pm2 start [Node.js, Python, Ruby, binaries in $PATH] #启动应用 pm2 [list|ls|status] #列出所有应用程序管理的状态 pm2 stop &lt;app_name|namespace|id|’all’|json_conf&gt; #停止应用 pm2 restart &lt;app_name|namespace|id|’all’|json_conf&gt; #重启应用 pm2 delete &lt;app_name|namespace|id|’all’|json_conf&gt; #删除应用 pm2 describe &lt;id|app_name&gt; #查看应用详细信息 pm2 monit #应用监控信息 pm2 logs #查看应用日志 pm2 install #安装应用模块 pm2 ecosystem #生成配置文件 升级PM2: npm install pm2@latest -g #下载最新版本的PM2 pm2 update #在内存中更新PM2 露一手我的centos有一个go程序，我们来solo一番。启动我们的应用 123456789[root@VM_175_142_centos shorturl]# pm2 start main[PM2] Starting /root/shorturl/main in fork_mode (1 instance)[PM2] Done.┌─────┬─────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼─────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 24044 │ 0s │ 0 │ online │ 0% │ 1.5mb │ root │ disabled │└─────┴─────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 查看我们的应用 1234567[root@VM_175_142_centos shorturl]# pm2 list┌─────┬─────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼─────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 24044 │ 68s │ 0 │ online │ 0% │ 20.1mb │ root │ disabled │└─────┴─────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 重启应用 12345678910[root@VM_175_142_centos shorturl]# pm2 restart mainUse --update-env to update environment variables[PM2] Applying action restartProcessId on app [main](ids: [ 0 ])[PM2] [main](0) ✓┌─────┬─────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼─────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 2078 │ 0s │ 1 │ online │ 0% │ 1.5mb │ root │ disabled │└─────┴─────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 停止应用 123456789[root@VM_175_142_centos shorturl]# pm2 stop main[PM2] Applying action stopProcessId on app [main](ids: [ 0 ])[PM2] [main](0) ✓┌─────┬─────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼─────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 0 │ 0 │ 1 │ stopped │ 0% │ 0b │ root │ disabled │└─────┴─────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 可以看到我们的应用状态为stopped,我们可以查看我们的日志 12345678910111213141516171819[root@VM_175_142_centos shorturl]# pm2 logs main[TAILING] Tailing last 15 lines for [main] process (change the value with --lines option)/root/.pm2/logs/main-out.log last 15 lines:/root/.pm2/logs/main-error.log last 15 lines:0|main | time=&quot;2019-12-12T13:31:55+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:33:01+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:33:01+08:00&quot; level=info msg=&quot;Server shutdown&quot;0|main | time=&quot;2019-12-12T13:34:12+08:00&quot; level=info msg=&quot;Creating DB with [ bolt ]&quot;0|main | time=&quot;2019-12-12T13:34:12+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:50:30+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:50:30+08:00&quot; level=info msg=&quot;Server shutdown&quot;0|main | time=&quot;2019-12-12T13:52:26+08:00&quot; level=info msg=&quot;Creating DB with [ bolt ]&quot;0|main | time=&quot;2019-12-12T13:52:26+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Server shutdown&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Creating DB with [ bolt ]&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:55:17+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:55:17+08:00&quot; level=info msg=&quot;Server shutdown&quot; 查看前10行的日志 1234567891011121314 [root@VM_175_142_centos shorturl]# pm2 logs main --lines 10[TAILING] Tailing last 10 lines for [main] process (change the value with --lines option)/root/.pm2/logs/main-out.log last 10 lines:/root/.pm2/logs/main-error.log last 10 lines:0|main | time=&quot;2019-12-12T13:50:30+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:50:30+08:00&quot; level=info msg=&quot;Server shutdown&quot;0|main | time=&quot;2019-12-12T13:52:26+08:00&quot; level=info msg=&quot;Creating DB with [ bolt ]&quot;0|main | time=&quot;2019-12-12T13:52:26+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Server shutdown&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Creating DB with [ bolt ]&quot;0|main | time=&quot;2019-12-12T13:54:47+08:00&quot; level=info msg=&quot;Server running at [ http://0.0.0.0:80 ], with domain [ https://52fx.biz ]&quot;0|main | time=&quot;2019-12-12T13:55:17+08:00&quot; level=info msg=&quot;Shuting down the server&quot;0|main | time=&quot;2019-12-12T13:55:17+08:00&quot; level=info msg=&quot;Server shutdown&quot; 查看应用状态 1234567 [root@VM_175_142_centos shorturl]# pm2 status main┌─────┬─────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼─────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 0 │ 0 │ 1 │ stopped │ 0% │ 0b │ root │ disabled │└─────┴─────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 查看监控 12345678910111213141516171819202122232425262728293031 [root@VM_175_142_centos shorturl]# pm2 monit ┌─ Process List ─────────────────────────────────────────┐┌── main Logs ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐│[ 0] main Mem: 19 MB CPU: 0 % online ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ ││ │└────────────────────────────────────────────────────────┘└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘┌─ Custom Metrics ───────────────────────────────────────┐┌─ Metadata ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┐│ ││ App Name main ││ ││ Namespace default ││ ││ Version N/A ││ ││ Restarts 1 ││ ││ Uptime 31s ││ ││ Script path /root/shorturl/main │└────────────────────────────────────────────────────────┘└──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┘ left/right: switch boards | up/down/mouse: scroll | Ctrl-C: exit PM2配置方式启动 12 [root@VM_175_142_centos shorturl]# pm2 ecosystem File /root/shorturl/ecosystem.config.js generated 会生成一个名为ecosystem.config.js的模版配置文件，我们稍作修改： 123456789101112131415161718192021222324252627282930 module.exports = { apps : [{ name: &apos;short&apos;, script: &apos;main&apos;, // Options reference: https://pm2.keymetrics.io/docs/usage/application-declaration/ args: &apos;config ./config.yml&apos;, instances: 1, autorestart: true, watch: false, max_memory_restart: &apos;1G&apos;, env: { NODE_ENV: &apos;development&apos; }, env_production: { NODE_ENV: &apos;production&apos; } }], deploy : { production : { user : &apos;node&apos;, host : &apos;212.83.163.1&apos;, ref : &apos;origin/master&apos;, repo : &apos;git@github.com:repo.git&apos;, path : &apos;/var/www/production&apos;, &apos;post-deploy&apos; : &apos;npm install &amp;&amp; pm2 reload ecosystem.config.js --env production&apos; } }};运行: 12345678910[root@VM_175_142_centos shorturl]# pm2 start ecosystem.config.js[PM2][WARN] Applications short not running, starting...[PM2] App [short] launched (1 instances)┌─────┬──────────┬─────────────┬─────────┬─────────┬──────────┬────────┬──────┬───────────┬──────────┬──────────┬──────────┬──────────┐│ id │ name │ namespace │ version │ mode │ pid │ uptime │ ↺ │ status │ cpu │ mem │ user │ watching │├─────┼──────────┼─────────────┼─────────┼─────────┼──────────┼────────┼──────┼───────────┼──────────┼──────────┼──────────┼──────────┤│ 0 │ main │ default │ N/A │ fork │ 0 │ 0 │ 1 │ stopped │ 0% │ 0b │ root │ disabled ││ 1 │ short │ default │ N/A │ fork │ 9525 │ 0s │ 0 │ online │ 0% │ 1.5mb │ root │ disabled │└─────┴──────────┴─────────────┴─────────┴─────────┴──────────┴────────┴──────┴───────────┴──────────┴──────────┴──────────┴──────────┘[PM2][WARN] Current process list running is not in sync with saved list. Type &apos;pm2 save&apos; to synchronize or enable autosync via &apos;pm2 set pm2:autodump true&apos; 具体的参数说明，可以去官网查阅. 未完待续，后面又更多骚操作，会继续更新该文档","link":"/20191212/%E8%BF%9B%E7%A8%8B%E5%AE%88%E6%8A%A4%E7%A5%9E%E5%99%A8-PM2.html"},{"title":"Vue自定义组件","text":"现在比较流行的就是组件化、模块化，因为这可以给我们带来快速和方便、提高开发效率。在React、Angular、Vue已经为自定义可复用组件提供了方便快捷的方式，这就是我们今天要说的内容-在Vue中如何自定义可复用组件。 简单示例全局定义注册首先，我们先在main.js定义一个简单的全局组件: 123Vue.component(&apos;MyComponent&apos;, { template: &apos;&lt;span&gt;自定义组件&lt;/span&gt;&apos;}) 局部注册定义我们直接在HelloWorld.vue定义我们的组件: 12345678910111213141516&lt;script&gt;let myComponent={ template: &apos;&lt;span&gt;自定义组件&lt;/span&gt;&apos;}export default { components:{ &quot;MyComponent&quot;:myComponent }, name: &apos;HelloWorld&apos;, data () { return { msg: &apos;Welcome to Your Vue.js App&apos; } }}&lt;/script&gt; 组件使用在HelloWorld.vue引入我们自定义的组件: 12345&lt;template&gt; &lt;div class=&quot;hello&quot;&gt; &lt;my-component&gt;&lt;/my-component&gt; &lt;/div&gt;&lt;/template&gt; 最后我们可以看到：这里组件的名字支持： 短横线,如:my-component,用法:&lt;my-component&gt;&lt;/my-component&gt; 小驼峰,如:myComponent,用法:&lt;my-component&gt;&lt;/my-component&gt; 大驼峰,如:MyComponent,用法:&lt;my-component&gt;&lt;/my-component&gt; 组件Prop属性既然自定组件，那么肯定会有一些属性字段需要动态绑定值，这里我们就要借助Prop来实现我们的组件属性。我們先來熟悉一下Prop屬性的用法: 數組類型,如:props: ['authorName','age']; 對象,對象方式支持指定屬性的值類型:1234props: { authorName: String, age:Number, } 對象方式支持屬性值驗證，如：1234props: { authorName: {type:String,required: true}, age:{type:Number,default: 100}, } 這裡的類型支持一下幾種: String Number Boolean Array Object Date Function Symbol HTML 中的特性名是大小写不敏感的，所以浏览器会把所有大写字符解释为小写字符。这意味着当你使用 DOM 中的模板时，camelCase (驼峰命名法) 的 prop 名需要使用其等价的 kebab-case (短横线分隔命名) 命名。 Prop示例我們將上面的組件稍作修改: 123456789let myComponent = { template: &quot;&lt;span&gt;自定义组件的作者:{{authorName}},年齡:{{age}}歲&lt;/span&gt;&quot;, props: { authorName: String, age:Number, }}; &lt;my-component author-name=&quot;eyiadmin&quot; age=&quot;1024&quot;&gt;&lt;/my-component&gt; 最終呈現:.我們剛才的值的靜態屬性值,如果我們想動態綁定屬性值怎麼做呢？直接上代碼: 1234567891011121314151617export default { components: { myComponent: myComponent }, name: &quot;HelloWorld&quot;, data() { return { msg: &quot;Welcome to Your Vue.js App&quot;, name:&apos;eyiadmin&apos;, age:1024 }; }};&lt;my-component v-bind:author-name=&quot;name&quot; v-bind:age=&quot;age&quot;&gt;&lt;/my-component&gt;或者這樣&lt;my-component :author-name=&quot;name&quot; :age=&quot;age&quot;&gt;&lt;/my-component&gt; 傳入對象我們把屬性值當做對象傳遞，這樣我們就需要做一些調整: 12345678910111213141516171819export default { components: { myComponent: myComponent }, name: &quot;HelloWorld&quot;, data() { return { msg: &quot;Welcome to Your Vue.js App&quot;, authorInfo: { authorName: &quot;eyiadmin&quot;, age: 1024 } }; }};# 指定對象屬性值&lt;my-component :author-name=&quot;authorInfo.authorName&quot; :age=&quot;authorInfo.age&quot;&gt;&lt;/my-component&gt;# 傳遞整個對象&lt;my-component v-bind=&quot;authorInfo&quot;&gt;&lt;/my-component&gt; 最終效果和上面一樣，就不再附效果圖。在Vue的Prop類型只支持单向数据流，即父级 prop 的更新会向下流动到子组件中，但是反过来则不行。但是我們會有場景用到子組件改變父組件的值，這個我們後面再說。 組件插槽Vue的slot有什麼用呢？剛才我們在自定義組件的時候，我們的使用方式是這樣的： 1&lt;my-component :author-name=&quot;authorInfo.authorName&quot; :age=&quot;authorInfo.age&quot;&gt;&lt;/my-component&gt; 但是我們不能這樣: 123&lt;my-component :author-name=&quot;authorInfo.authorName&quot; :age=&quot;authorInfo.age&quot;&gt;hello world&lt;/my-component&gt;或者&lt;my-component :author-name=&quot;authorInfo.authorName&quot; :age=&quot;authorInfo.age&quot;&gt;&lt;my-component :author-name=&quot;authorInfo.authorName&quot; :age=&quot;authorInfo.age&quot;&gt;&lt;/my-component&gt;&lt;/my-component&gt; 顯然，有時候我們是希望能不能不能這樣的變為可以這樣。這時候slot就可以發揮作用了。我們將我們的組件模版稍作調整: 1template: &quot;&lt;span&gt;自定义组件的作者:{{authorName}},年齡:{{age}}歲&lt;br/&gt;&lt;slot&gt;&lt;/slot&gt;&lt;/span&gt;&quot; 這下我們就可以這樣用： 1234567891011121314151617181920212223export default { components: { myComponent: myComponent }, name: &quot;HelloWorld&quot;, data() { return { msg: &quot;Welcome to Your Vue.js App&quot;, authorInfo: { authorName: &quot;eyiadmin&quot;, age:1024 }, childInfo: { authorName: &quot;eyiadmin_child&quot;, age:100 } }; }}; &lt;my-component v-bind=&quot;authorInfo&quot;&gt; &lt;my-component v-bind=&quot;childInfo&quot;&gt;&lt;/my-component&gt; &lt;/my-component&gt; 我就可以看到,我們再來簡單看看element的使用方式，就拿我們常用的header為例: 123456789101112131415161718&lt;template&gt; &lt;header class=&quot;el-header&quot; :style=&quot;{ height }&quot;&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/header&gt;&lt;/template&gt;&lt;script&gt; export default { name: &apos;ElHeader&apos;, componentName: &apos;ElHeader&apos;, props: { height: { type: String, default: &apos;60px&apos; } } };&lt;/script&gt; 在Header的index.js中來註冊,這個註冊是按需引入的時候註冊。 12345678import Header from &apos;./src/main&apos;;/* istanbul ignore next */Header.install = function(Vue) { Vue.component(Header.name, Header);};export default Header; 我們可以在src/index.js看到全局註冊的方式: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288/* Automatically generated by &apos;./build/bin/build-entry.js&apos; */import Pagination from &apos;../packages/pagination/index.js&apos;;import Dialog from &apos;../packages/dialog/index.js&apos;;import Autocomplete from &apos;../packages/autocomplete/index.js&apos;;import Dropdown from &apos;../packages/dropdown/index.js&apos;;import DropdownMenu from &apos;../packages/dropdown-menu/index.js&apos;;import DropdownItem from &apos;../packages/dropdown-item/index.js&apos;;import Menu from &apos;../packages/menu/index.js&apos;;import Submenu from &apos;../packages/submenu/index.js&apos;;import MenuItem from &apos;../packages/menu-item/index.js&apos;;import MenuItemGroup from &apos;../packages/menu-item-group/index.js&apos;;import Input from &apos;../packages/input/index.js&apos;;import InputNumber from &apos;../packages/input-number/index.js&apos;;import Radio from &apos;../packages/radio/index.js&apos;;import RadioGroup from &apos;../packages/radio-group/index.js&apos;;import RadioButton from &apos;../packages/radio-button/index.js&apos;;import Checkbox from &apos;../packages/checkbox/index.js&apos;;import CheckboxButton from &apos;../packages/checkbox-button/index.js&apos;;import CheckboxGroup from &apos;../packages/checkbox-group/index.js&apos;;import Switch from &apos;../packages/switch/index.js&apos;;import Select from &apos;../packages/select/index.js&apos;;import Option from &apos;../packages/option/index.js&apos;;import OptionGroup from &apos;../packages/option-group/index.js&apos;;import Button from &apos;../packages/button/index.js&apos;;import ButtonGroup from &apos;../packages/button-group/index.js&apos;;import Table from &apos;../packages/table/index.js&apos;;import TableColumn from &apos;../packages/table-column/index.js&apos;;import DatePicker from &apos;../packages/date-picker/index.js&apos;;import TimeSelect from &apos;../packages/time-select/index.js&apos;;import TimePicker from &apos;../packages/time-picker/index.js&apos;;import Popover from &apos;../packages/popover/index.js&apos;;import Tooltip from &apos;../packages/tooltip/index.js&apos;;import MessageBox from &apos;../packages/message-box/index.js&apos;;import Breadcrumb from &apos;../packages/breadcrumb/index.js&apos;;import BreadcrumbItem from &apos;../packages/breadcrumb-item/index.js&apos;;import Form from &apos;../packages/form/index.js&apos;;import FormItem from &apos;../packages/form-item/index.js&apos;;import Tabs from &apos;../packages/tabs/index.js&apos;;import TabPane from &apos;../packages/tab-pane/index.js&apos;;import Tag from &apos;../packages/tag/index.js&apos;;import Tree from &apos;../packages/tree/index.js&apos;;import Alert from &apos;../packages/alert/index.js&apos;;import Notification from &apos;../packages/notification/index.js&apos;;import Slider from &apos;../packages/slider/index.js&apos;;import Loading from &apos;../packages/loading/index.js&apos;;import Icon from &apos;../packages/icon/index.js&apos;;import Row from &apos;../packages/row/index.js&apos;;import Col from &apos;../packages/col/index.js&apos;;import Upload from &apos;../packages/upload/index.js&apos;;import Progress from &apos;../packages/progress/index.js&apos;;import Spinner from &apos;../packages/spinner/index.js&apos;;import Message from &apos;../packages/message/index.js&apos;;import Badge from &apos;../packages/badge/index.js&apos;;import Card from &apos;../packages/card/index.js&apos;;import Rate from &apos;../packages/rate/index.js&apos;;import Steps from &apos;../packages/steps/index.js&apos;;import Step from &apos;../packages/step/index.js&apos;;import Carousel from &apos;../packages/carousel/index.js&apos;;import Scrollbar from &apos;../packages/scrollbar/index.js&apos;;import CarouselItem from &apos;../packages/carousel-item/index.js&apos;;import Collapse from &apos;../packages/collapse/index.js&apos;;import CollapseItem from &apos;../packages/collapse-item/index.js&apos;;import Cascader from &apos;../packages/cascader/index.js&apos;;import ColorPicker from &apos;../packages/color-picker/index.js&apos;;import Transfer from &apos;../packages/transfer/index.js&apos;;import Container from &apos;../packages/container/index.js&apos;;import Header from &apos;../packages/header/index.js&apos;;import Aside from &apos;../packages/aside/index.js&apos;;import Main from &apos;../packages/main/index.js&apos;;import Footer from &apos;../packages/footer/index.js&apos;;import Timeline from &apos;../packages/timeline/index.js&apos;;import TimelineItem from &apos;../packages/timeline-item/index.js&apos;;import Link from &apos;../packages/link/index.js&apos;;import Divider from &apos;../packages/divider/index.js&apos;;import Image from &apos;../packages/image/index.js&apos;;import Calendar from &apos;../packages/calendar/index.js&apos;;import Backtop from &apos;../packages/backtop/index.js&apos;;import InfiniteScroll from &apos;../packages/infinite-scroll/index.js&apos;;import PageHeader from &apos;../packages/page-header/index.js&apos;;import CascaderPanel from &apos;../packages/cascader-panel/index.js&apos;;import Avatar from &apos;../packages/avatar/index.js&apos;;import Drawer from &apos;../packages/drawer/index.js&apos;;import Popconfirm from &apos;../packages/popconfirm/index.js&apos;;import locale from &apos;element-ui/src/locale&apos;;import CollapseTransition from &apos;element-ui/src/transitions/collapse-transition&apos;;const components = [ Pagination, Dialog, Autocomplete, Dropdown, DropdownMenu, DropdownItem, Menu, Submenu, MenuItem, MenuItemGroup, Input, InputNumber, Radio, RadioGroup, RadioButton, Checkbox, CheckboxButton, CheckboxGroup, Switch, Select, Option, OptionGroup, Button, ButtonGroup, Table, TableColumn, DatePicker, TimeSelect, TimePicker, Popover, Tooltip, Breadcrumb, BreadcrumbItem, Form, FormItem, Tabs, TabPane, Tag, Tree, Alert, Slider, Icon, Row, Col, Upload, Progress, Spinner, Badge, Card, Rate, Steps, Step, Carousel, Scrollbar, CarouselItem, Collapse, CollapseItem, Cascader, ColorPicker, Transfer, Container, Header, Aside, Main, Footer, Timeline, TimelineItem, Link, Divider, Image, Calendar, Backtop, PageHeader, CascaderPanel, Avatar, Drawer, Popconfirm, CollapseTransition];const install = function(Vue, opts = {}) { locale.use(opts.locale); locale.i18n(opts.i18n); components.forEach(component =&gt; { Vue.component(component.name, component); }); Vue.use(InfiniteScroll); Vue.use(Loading.directive); Vue.prototype.$ELEMENT = { size: opts.size || &apos;&apos;, zIndex: opts.zIndex || 2000 }; Vue.prototype.$loading = Loading.service; Vue.prototype.$msgbox = MessageBox; Vue.prototype.$alert = MessageBox.alert; Vue.prototype.$confirm = MessageBox.confirm; Vue.prototype.$prompt = MessageBox.prompt; Vue.prototype.$notify = Notification; Vue.prototype.$message = Message;};/* istanbul ignore if */if (typeof window !== &apos;undefined&apos; &amp;&amp; window.Vue) { install(window.Vue);}export default { version: &apos;2.13.0&apos;, locale: locale.use, i18n: locale.i18n, install, CollapseTransition, Loading, Pagination, Dialog, Autocomplete, Dropdown, DropdownMenu, DropdownItem, Menu, Submenu, MenuItem, MenuItemGroup, Input, InputNumber, Radio, RadioGroup, RadioButton, Checkbox, CheckboxButton, CheckboxGroup, Switch, Select, Option, OptionGroup, Button, ButtonGroup, Table, TableColumn, DatePicker, TimeSelect, TimePicker, Popover, Tooltip, MessageBox, Breadcrumb, BreadcrumbItem, Form, FormItem, Tabs, TabPane, Tag, Tree, Alert, Notification, Slider, Icon, Row, Col, Upload, Progress, Spinner, Message, Badge, Card, Rate, Steps, Step, Carousel, Scrollbar, CarouselItem, Collapse, CollapseItem, Cascader, ColorPicker, Transfer, Container, Header, Aside, Main, Footer, Timeline, TimelineItem, Link, Divider, Image, Calendar, Backtop, InfiniteScroll, PageHeader, CascaderPanel, Avatar, Drawer, Popconfirm}; 當我們在main.js使用Vue.use注册插件的时候，就会执行對應的install方法來註冊我們的組件。當然，自定義組件還有很多東西沒有說，今天在忙著吧一百多億的數據遷移到其他數據庫，有點小忙，所有其他的東西後面我們再來細說，比如自定義組件中的自定義事件等。大家如果有深入研究的興趣，可以去https://cn.vuejs.org/，在結合一個開源的UI框架邊學習邊分析源碼，對學習的幫助比較大，例如可以結合element的源碼來一起學習。","link":"/20200103/Vue%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BB%84%E4%BB%B6.html"},{"title":"Vue入门","text":"现在前端比较火的三大家就Vue、React、Angular，当然现在逐渐兴趣和完善的Fullter,现在也有一些大厂开始用Fullter来开发应用了。但是我还是希望等它再成熟一点之后再开始入手，这样可以少采一些坑嘛。这次，我们先来总结一下Vue的一些基础知识，为什么要学Vue呢，因为它易用、灵活、高效. 环境准备我们首先需要安装Node.js,去Nodejs官网下载,安装很方便直接下一步即可:验证是否安装成功: 1234C:\\Users\\lenovo&gt;node -vv13.5.0C:\\Users\\lenovo&gt;npm -v6.13.4 使用npm安装vue-cli脚手架构建工具: 12345678C:\\Users\\lenovo&gt;npm install -g vue-clinpm WARN deprecated vue-cli@2.9.6: This package has been deprecated in favour of @vue/clinpm WARN deprecated coffee-script@1.12.7: CoffeeScript on NPM has moved to &quot;coffeescript&quot; (no hyphen)C:\\Users\\lenovo\\AppData\\Roaming\\npm\\vue -&gt; C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\vue-cli\\bin\\vueC:\\Users\\lenovo\\AppData\\Roaming\\npm\\vue-init -&gt; C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\vue-cli\\bin\\vue-initC:\\Users\\lenovo\\AppData\\Roaming\\npm\\vue-list -&gt; C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\vue-cli\\bin\\vue-list+ vue-cli@2.9.6added 4 packages from 1 contributor, removed 1022 packages and updated 237 packages in 162.365s 当然，npm会因为网络问题，会下载很慢甚至导致失败。这里可以使用cnpm或者nvm来更改镜像地址。为了方便，我们还是选择cnpm吧,在cmd中安装cnpm: 1234 C:\\Users\\lenovo&gt; npm install -g cnpm --registry=http://registry.npm.taobao.orgC:\\Users\\lenovo\\AppData\\Roaming\\npm\\cnpm -&gt; C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\cnpm\\bin\\cnpm+ cnpm@6.1.1added 31 packages from 27 contributors, removed 29 packages, updated 119 packages and moved 1 package in 130.257s 12345678910C:\\Users\\lenovo&gt;cnpm -vcnpm@6.1.1 (C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\cnpm\\lib\\parse_argv.js)npm@6.13.4 (C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\cnpm\\node_modules\\npm\\lib\\npm.js)node@13.5.0 (D:\\Program Files\\nodejs\\node.exe)npminstall@3.25.2 (C:\\Users\\lenovo\\AppData\\Roaming\\npm\\node_modules\\cnpm\\node_modules\\npminstall\\lib\\index.js)prefix=C:\\Users\\lenovo\\AppData\\Roaming\\npmwin32 x64 10.0.18362registry=https://r.npm.taobao.orgC:\\Users\\lenovo&gt;vue -V2.9.6 创建项目我们先来看一下vue命令工具: 12345678910111213C:\\Users\\lenovo&gt;vue -helpUsage: vue &lt;command&gt; [options]Options: -V, --version output the version number -h, --help output usage informationCommands: init 从模板生成新项目 list 列出可用的模板 build prototype a new project create (for v3 warning only) help [cmd] display help for [cmd] 我这里创建一个名为myresume: 1234567891011121314151617181920212223242526E:\\vue&gt;vue init webpack myresume? Project name myresume? Project description A Vue.js project? Author eyiadmin &lt;326076105@qq.com&gt;? Vue build standalone? Install vue-router? Yes? Use ESLint to lint your code? Yes? Pick an ESLint preset Standard? Set up unit tests No? Setup e2e tests with Nightwatch? No? Should we run `npm install` for you after the project has been created? (recommended) no vue-cli · Generated &quot;myresume&quot;.# Project initialization finished!# ========================To get started: cd myresume npm install (or if using yarn: yarn) npm run lint -- --fix (or for yarn: yarn run lint --fix) npm run devDocumentation can be found at https://vuejs-templates.github.io/webpack 一般默认既可以，在最后的Should we runnpm installfor you after the project has been created，我选择No,在模版创建好后，自己手动安装。 123456789101112131415161718192021222324252627282930313233E:\\vue&gt;cd myresumeE:\\vue\\myresume&gt;cnpm install| [30/47] Installing url-loader@^0.5.8platform unsupported babel-loader@7.1.5 › webpack@3.12.0 › watchpack@1.6.0 › chokidar@2.1.8 › fsevents@^1.2.7 Package require os(darwin) not compatible with your platform(win32)| [30/47] Installing postcss-normalize-unicode@^4.0.1[fsevents@^1.2.7] optional install error: Package require os(darwin) not compatible with your platform(win32)√ Installed 47 packages√ Linked 805 latest versions[1/3] scripts.postinstall babel-loader@7.1.5 › webpack@3.12.0 › uglifyjs-webpack-plugin@^0.4.6 run &quot;node lib/post_install.js&quot;, root: &quot;E:\\\\vue\\\\myresume\\\\node_modules\\\\_uglifyjs-webpack-plugin@0.4.6@uglifyjs-webpack-plugin&quot;[1/3] scripts.postinstall babel-loader@7.1.5 › webpack@3.12.0 › uglifyjs-webpack-plugin@^0.4.6 finished in 556ms[2/3] scripts.postinstall babel-plugin-transform-runtime@6.23.0 › babel-runtime@6.26.0 › core-js@^2.4.0 run &quot;node -e \\&quot;try{require(&apos;./postinstall&apos;)}catch(e){}\\&quot;&quot;, root: &quot;E:\\\\vue\\\\myresume\\\\node_modules\\\\_core-js@2.6.11@core-js&quot;Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library!The project needs your help! Please consider supporting of core-js on Open Collective or Patreon:&gt; https://opencollective.com/core-js&gt; https://www.patreon.com/zloirockAlso, the author of core-js ( https://github.com/zloirock ) is looking for a good job -)[2/3] scripts.postinstall babel-plugin-transform-runtime@6.23.0 › babel-runtime@6.26.0 › core-js@^2.4.0 finished in 216ms[3/3] scripts.postinstall webpack-bundle-analyzer@2.13.1 › ejs@^2.5.7 run &quot;node ./postinstall.js&quot;, root: &quot;E:\\\\vue\\\\myresume\\\\node_modules\\\\_ejs@2.7.4@ejs&quot;Thank you for installing EJS: built with the Jake JavaScript build tool (https://jakejs.com/)[3/3] scripts.postinstall webpack-bundle-analyzer@2.13.1 › ejs@^2.5.7 finished in 136ms√ Run 3 scriptspeerDependencies link ajv@5.5.2 in E:\\vue\\myresume\\node_modules\\_ajv-keywords@2.1.1@ajv-keywords unmet with E:\\vue\\myresume\\node_modules\\ajv(6.10.2)deprecate autoprefixer@7.2.6 › browserslist@^2.11.3 Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.deprecate css-loader@0.28.11 › cssnano@3.10.0 › autoprefixer@6.7.7 › browserslist@^1.7.6 Browserslist 2 could fail on reading Browserslist &gt;3.0 config used in other tools.deprecate eslint@4.19.1 › file-entry-cache@2.0.0 › flat-cache@1.3.4 › circular-json@^0.3.1 CircularJSON is in maintenance only, flatted is its successor.deprecate babel-plugin-transform-runtime@6.23.0 › babel-runtime@6.26.0 › core-js@^2.4.0 core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3.deprecate webpack-bundle-analyzer@2.13.1 › bfj-node4@^5.2.0 Switch to the `bfj` package for fixes and new features!Recently updated (since 2019-12-24): 5 packages (detail see file E:\\vue\\myresume\\node_modules\\.recently_updates.txt) Today: → optimize-css-assets-webpack-plugin@3.2.1 › cssnano@4.1.10 › postcss@^7.0.0(7.0.26) (08:11:16)√ All packages installed (1005 packages installed from npm registry, used 56s(network 52s), speed 66.01kB/s, json 852(1.95MB), tarball 1.4MB) 安装完成后就可以初步看看我们的项目模版: 1234567891011E:\\vue\\myresume&gt;npm run dev&gt; myresume@1.0.0 dev E:\\vue\\myresume&gt; webpack-dev-server --inline --progress --config build/webpack.dev.conf.js 13% building modules 33/37 modules 4 active ...yresume\\src\\components\\HelloWorld.vue{ parser: &quot;babylon&quot; } is deprecated; we now treat it as { parser: &quot;babel&quot; }. 95% emitting DONE Compiled successfully in 3332ms 下午6:20:31 I Your application is running here: http://localhost:8080 在浏览器访问http://localhost:8080/#/ 基础介绍模板语法Vue.js 使用了基于 HTML 的模板语法，允许开发者声明式地将 DOM 绑定至底层 Vue 实例的数据。所有 Vue.js 的模板都是合法的 HTML ，所以能被遵循规范的浏览器和 HTML 解析器解析。在底层的实现上，Vue 将模板编译成虚拟 DOM 渲染函数。结合响应系统，Vue 能够智能地计算出最少需要重新渲染多少组件，并把 DOM 操作次数减到最少。 文本数据绑定最常见的形式就是使用Mustache语法 (双大括号) 的文本插值： 1&lt;span&gt;我会变: {{ msg }}&lt;/span&gt; Mustache标签将会被替代为对应数据对象上 msg 属性的值。无论何时，绑定的数据对象上 msg 属性发生了改变，插值处的内容都会更新。通过使用 v-once 指令，你也能执行一次性地插值，当数据改变时，插值处的内容不会更新。但请留心这会影响到该节点上的其它数据绑定： 1&lt;span v-once&gt;我不会改变: {{ msg }}&lt;/span&gt; 我们来看看这二者的效果: 原始 HTML双大括号会将数据解释为普通文本，而非 HTML 代码。为了输出真正的 HTML，你需要使用 v-html 指令： 123456789101112&lt;p&gt;Using mustaches: {{ rawHtml }}&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt;&lt;script&gt;export default { name: &apos;HelloWorld&apos;, data () { return { rawHtml:&apos;&lt;span&gt;html代码&lt;/span&gt;&apos; } }}&lt;/script&gt; 这个 span 的内容将会被替换成为属性值 rawHtml，直接作为 HTML——会忽略解析属性值中的数据绑定。注意，你不能使用 v-html 来复合局部模板，因为 Vue 不是基于字符串的模板引擎。反之，对于用户界面 (UI)，组件更适合作为可重用和可组合的基本单位。你的站点上动态渲染的任意 HTML 可能会非常危险，因为它很容易导致 XSS 攻击。请只对可信内容使用 HTML 插值，绝不要对用户提供的内容使用插值。 特性Mustache 语法不能作用在 HTML 特性上，遇到这种情况应该使用 v-bind 指令： 1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 对于布尔特性 (它们只要存在就意味着值为 true)，v-bind 工作起来略有不同，在这个例子中： 1&lt;button v-bind:disabled=&quot;isButtonDisabled&quot;&gt;Button&lt;/button&gt; 如果 isButtonDisabled 的值是 null、undefined 或 false，则 disabled 特性甚至不会被包含在渲染出来的 &lt;button&gt; 元素中。 使用 JavaScript 表达式迄今为止，在我们的模板中，我们一直都只绑定简单的属性键值。但实际上，对于所有的数据绑定，Vue.js 都提供了完全的 JavaScript 表达式支持。 1234567891011121314151617181920{{ number + 1 }}{{ ok ? &apos;YES&apos; : &apos;NO&apos; }}{{ message.split(&apos;&apos;).reverse().join(&apos;&apos;) }}&lt;div v-bind:id=&quot;&apos;list-&apos; + id&quot;&gt;&lt;/div&gt;&lt;script&gt;export default { name: &apos;HelloWorld&apos;, data () { return { id:1, ok:1, message:&apos;reverse&apos;, number:1, } }}&lt;/script&gt; 这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。 12345&lt;!-- 这是语句，不是表达式 --&gt;{{ var a = 1 }}&lt;!-- 流控制也不会生效，请使用三元表达式 --&gt;{{ if (ok) { return message } }} 模板表达式都被放在沙盒中，只能访问全局变量的一个白名单，如 Math 和 Date 。你不应该在模板表达式中试图访问用户定义的全局变量。 指令指令 (Directives) 是带有 v- 前缀的特殊特性。指令特性的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。回顾我们在介绍中看到的例子： 1234567891011&lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt;&lt;script&gt;export default { name: &apos;HelloWorld&apos;, data () { return { seen:true } }}&lt;/script&gt; 这里，v-if 指令将根据表达式 seen 的值的真假来插入/移除 &lt;p&gt; 元素。 参数一些指令能够接收一个“参数”，在指令名称之后以冒号表示。例如，v-bind 指令可以用于响应式地更新 HTML 特性： 1&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt; 在这里 href 是参数，告知 v-bind 指令将该元素的 href 特性与表达式 url 的值绑定。 另一个例子是 v-on 指令，它用于监听 DOM 事件： 12345678910111213141516 &lt;a v-on:click=&quot;doSomething&quot;&gt;hello vue&lt;/a&gt; &lt;script&gt;export default { name: &apos;HelloWorld&apos;, data () { return { } }, methods:{ doSomething:function(){ alert(&quot;hello vue&quot;); } }}&lt;/script&gt; 在这里参数是监听的事件名。我们也会更详细地讨论事件处理。 动态参数2.6.0 新增 从 2.6.0 开始，可以用方括号括起来的 JavaScript 表达式作为一个指令的参数： 1234&lt;!--注意，参数表达式的写法存在一些约束，如之后的“对动态参数表达式的约束”章节所述。--&gt;&lt;a v-bind:属性名=&quot;url&quot;&gt; ... &lt;/a&gt; 这里的属性名 会被作为一个 JavaScript 表达式进行动态求值，求得的值将会作为最终的参数来使用。例如，如果你的 Vue 实例有一个 data 属性 属性名，其值为 “href”，那么这个绑定将等价于 v-bind:href。示例: 1234567891011&lt;a v-bind:href=&quot;url&quot;&gt; baidu &lt;/a&gt;export default { name: &apos;HelloWorld&apos;, data () { return { url:&quot;https://www.baidu.com&quot; } }, }&lt;/script&gt; 同样地，你可以使用动态参数为一个动态的事件名绑定处理函数： 1&lt;a v-on:事件名=&quot;doSomething&quot;&gt; ... &lt;/a&gt; 在这个示例中，当 事件名 的值为 “focus” 时，v-on:事件名 将等价于 v-on:focus。 对动态参数的值的约束动态参数预期会求出一个字符串，异常情况下值为 null。这个特殊的 null 值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告。 对动态参数表达式的约束动态参数表达式有一些语法约束，因为某些字符，如空格和引号，放在 HTML attribute 名里是无效的。例如： 12&lt;!-- 这会触发一个编译警告 --&gt;&lt;a v-bind:[&apos;foo&apos; + bar]=&quot;value&quot;&gt; ... &lt;/a&gt; 变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。 在 DOM 中使用模板时 (直接在一个 HTML 文件里撰写模板)，还需要避免使用大写字符来命名键名，因为浏览器会把 attribute 名全部强制转为小写： 12345&lt;!--在 DOM 中使用模板时这段代码会被转换为 `v-bind:[someattr]`。除非在实例中有一个名为“someattr”的 property，否则代码不会工作。--&gt;&lt;a v-bind:[someAttr]=&quot;value&quot;&gt; ... &lt;/a&gt; 修饰符修饰符 (modifier) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： 1&lt;form v-on:submit.prevent=&quot;onSubmit&quot;&gt;...&lt;/form&gt; 在接下来对 v-on 和 v-for 等功能的探索中，你会看到修饰符的其它例子。 缩写v- 前缀作为一种视觉提示，用来识别模板中 Vue 特定的特性。当你在使用 Vue.js 为现有标签添加动态行为 (dynamic behavior) 时，v- 前缀很有帮助，然而，对于一些频繁用到的指令来说，就会感到使用繁琐。同时，在构建由 Vue 管理所有模板的单页面应用程序 (SPA - single page application) 时，v- 前缀也变得没那么重要了。因此，Vue 为 v-bind 和 v-on 这两个最常用的指令，提供了特定简写： 1234567891011121314v-bind 缩写&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;...&lt;/a&gt;…v-on 缩写&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;...&lt;/a&gt; 它们看起来可能与普通的 HTML 略有不同，但 : 与 @ 对于特性名来说都是合法字符，在所有支持 Vue 的浏览器都能被正确地解析。而且，它们不会出现在最终渲染的标记中。缩写语法是完全可选的。 Class 与 Style 绑定我们可以传给 v-bind:class 一个对象，以动态地切换 class： 1&lt;div v-bind:class=&quot;{ active: isActive }&quot;&gt;&lt;/div&gt; 上面的语法表示 active 这个 class 存在与否将取决于数据属性 isActive 的 truthiness. 你可以在对象中传入更多属性来动态切换多个 class。此外，v-bind:class 指令也可以与普通的 class 属性共存。当有如下模板: 1234&lt;div class=&quot;static&quot; v-bind:class=&quot;{ active: isActive, &apos;text-danger&apos;: hasError }&quot;&gt;&lt;/div&gt; 和如下 data： 1234data: { isActive: true, hasError: false} 结果渲染为： 1&lt;div class=&quot;static active&quot;&gt;&lt;/div&gt; 当 isActive 或者 hasError 变化时，class 列表将相应地更新。例如，如果 hasError 的值为 true，class 列表将变为 “static active text-danger”。 绑定的数据对象不必内联定义在模板里： 1234567&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;data: { classObject: { active: true, &apos;text-danger&apos;: false }} 渲染的结果和上面一样。我们也可以在这里绑定一个返回对象的计算属性。这是一个常用且强大的模式： 12345678910111213&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt;data: { isActive: true, error: null},computed: { classObject: function () { return { active: this.isActive &amp;&amp; !this.error, &apos;text-danger&apos;: this.error &amp;&amp; this.error.type === &apos;fatal&apos; } }} 数组语法我们可以把一个数组传给 v-bind:class，以应用一个 class 列表： 12345&lt;div v-bind:class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt;data: { activeClass: &apos;active&apos;, errorClass: &apos;text-danger&apos;} 渲染为： 1&lt;div class=&quot;active text-danger&quot;&gt;&lt;/div&gt; 如果你也想根据条件切换列表中的 class，可以用三元表达式： 1&lt;div v-bind:class=&quot;[isActive ? activeClass : &apos;&apos;, errorClass]&quot;&gt;&lt;/div&gt; 这样写将始终添加 errorClass，但是只有在 isActive 是 truthy[1] 时才添加 activeClass。 不过，当有多个条件 class 时这样写有些繁琐。所以在数组语法中也可以使用对象语法： 1&lt;div v-bind:class=&quot;[{ active: isActive }, errorClass]&quot;&gt;&lt;/div&gt; 条件渲染v-if 指令用于条件性地渲染一块内容。这块内容只会在指令的表达式返回 truthy 值的时候被渲染。 1&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt; 也可以用 v-else 添加一个else 块： 12&lt;h1 v-if=&quot;awesome&quot;&gt;Vue is awesome!&lt;/h1&gt;&lt;h1 v-else&gt;Oh no 😢&lt;/h1&gt; 你可以使用 v-else 指令来表示v-if 的”else 块”： 123456&lt;div v-if=&quot;Math.random() &gt; 0.5&quot;&gt; Now you see me&lt;/div&gt;&lt;div v-else&gt; Now you don&apos;t&lt;/div&gt; v-else 元素必须紧跟在带 v-if或者 v-else-if(2.1.0 新增) 的元素的后面，否则它将不会被识别。v-else-if，顾名思义，充当 v-if 的”else-if 块”，可以连续使用： 123456789101112&lt;div v-if=&quot;type === &apos;A&apos;&quot;&gt; A&lt;/div&gt;&lt;div v-else-if=&quot;type === &apos;B&apos;&quot;&gt; B&lt;/div&gt;&lt;div v-else-if=&quot;type === &apos;C&apos;&quot;&gt; C&lt;/div&gt;&lt;div v-else&gt; Not A/B/C&lt;/div&gt; 类似于v-else，v-else-if 也必须紧跟在带 v-if 或者 v-else-if 的元素之后。 该问的内容是从https://cn.vuejs.org/v2/guide/拷贝来的，然后自己在验证一下。","link":"/20200101/Vue%E5%85%A5%E9%97%A8.html"},{"title":"shell脚本学习","text":"Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但读者朋友要知道，shell 和 shell script 是两个不同的概念。由于习惯的原因，简洁起见，本文出现的 “shell编程” 都是指 shell 脚本编程，不是指开发 shell 自身。 以上内容来源于runoob 上半年花了一个多月时间修改一个开源的BI项目(Redash),改完后,由于没有使用也就暂时告一段落，就在昨天，一个客户说想找一个开源的BI系统，我们就给他推荐这个工具，因为它简单、方便、快捷，而且也比较受欢迎。但是客户对Docker不熟悉，就给他大致的讲了一个怎么在 Windows搭建一个测试环境。后来，突然想看看Redash的Dockerfile文件，看到里面的执行文件： 12ENTRYPOINT [&quot;/app/bin/docker-entrypoint&quot;]CMD [&quot;server&quot;] docker-entrypoint是一个shell脚本，但是因为自己对shell的使用还未入门，所以就着这个机会，去简单了解一下。我们先看一下docker-entrypoint中的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#!/bin/bashset -ecelery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS}scheduler() { echo &quot;Starting RQ scheduler...&quot; exec /app/manage.py rq scheduler}dev_scheduler() { echo &quot;Starting dev RQ scheduler...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq scheduler}worker() { echo &quot;Starting RQ worker...&quot; exec /app/manage.py rq worker $QUEUES}dev_worker() { echo &quot;Starting dev RQ worker...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq worker $QUEUES}dev_celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair}server() { # Recycle gunicorn workers every n-th request. See http://docs.gunicorn.org/en/stable/settings.html#max-requests for more details. MAX_REQUESTS=${MAX_REQUESTS:-1000} MAX_REQUESTS_JITTER=${MAX_REQUESTS_JITTER:-100} exec /usr/local/bin/gunicorn -b 0.0.0.0:5000 --name redash -w${REDASH_WEB_WORKERS:-4} redash.wsgi:app --max-requests $MAX_REQUESTS --max-requests-jitter $MAX_REQUESTS_JITTER}create_db() { exec /app/manage.py database create_tables}celery_healthcheck() { exec /usr/local/bin/celery inspect ping --app=redash.worker -d celery@$HOSTNAME}rq_healthcheck() { exec /app/manage.py rq healthcheck}help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}tests() { export REDASH_DATABASE_URL=&quot;postgresql://postgres@postgres/tests&quot; if [ $# -eq 0 ]; then TEST_ARGS=tests/ else TEST_ARGS=$@ fi exec pytest $TEST_ARGS}case &quot;$1&quot; in worker) shift worker ;; server) shift server ;; scheduler) shift scheduler ;; dev_scheduler) shift dev_scheduler ;; celery_worker) shift celery_worker ;; dev_celery_worker) shift dev_celery_worker ;; dev_worker) shift dev_worker ;; rq_healthcheck) shift rq_healthcheck ;; celery_healthcheck) shift celery_healthcheck ;; dev_server) export FLASK_DEBUG=1 exec /app/manage.py runserver --debugger --reload -h 0.0.0.0 ;; debug) export FLASK_DEBUG=1 export REMOTE_DEBUG=1 exec /app/manage.py runserver --debugger --no-reload -h 0.0.0.0 ;; shell) exec /app/manage.py shell ;; create_db) create_db ;; manage) shift exec /app/manage.py $* ;; tests) shift tests $@ ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac #!/bin/bash的作用我们可以再很多sh脚本里面看到#!/bin/bash这段代码，那么它有什么作用呢?shell是一种脚本命令语言，它有多种解析器，例如：/bin/csh、/bin/perl、/bin/bash、bin/sh等等，那么在在第一行加上#!/bin/bash，就是告诉系统这个脚本需要bin/bash解释器来执行。 set -e的作用set -e的作用是：当命令的返回值为非零状态时，则立即退出脚本的执行，防止导致一个致命的错误，而这些错误本应该在之前就被处理掉。set -e 命令用法总结如下： 当命令的返回值为非零状态时，则立即退出脚本的执行。 作用范围只限于脚本执行的当前进行，不作用于其创建的子进程（https://blog.csdn.net/fc34235/article/details/76598448 ）。 另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。shell 中的 set -e 和 set +e的区别 shell 函数shell函数的定义格式如下： 12345[ function ] funname [()]{ action; [return int;]} 函数定义可以带function funname() 定义，也可以直接funname() 定义,不带任何参数。函数返回值可加return也可以不加，不加则以最后一条命令运行结果作为返回值。 12345678celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS} shell变量12# 如果WORKERS_COUNT未定义或者为空字符串，则返回默认值，否则返回WORKERS_COUNT的值WORKERS_COUNT=${WORKERS_COUNT:-2} 注意，变量名和等号之间不能有空格,而且还需要遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 使用一个定义过的变量，只要在变量名前面加美元符号即可。例如: 1$WORKERS_COUNT或者${WORKERS_COUNT} shell 参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n,n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： 123456789101112131415161718#!/bin/bash# author:菜鸟教程# url:www.runoob.comecho &quot;Shell 传递参数实例！&quot;;echo &quot;执行的文件名：$0&quot;;echo &quot;第一个参数为：$1&quot;;echo &quot;第二个参数为：$2&quot;;echo &quot;第三个参数为：$3&quot;;为脚本设置可执行权限，并执行脚本，输出结果如下所示：$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：./test.sh第一个参数为：1第二个参数为：2第三个参数为：3 123456789$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数。如&quot;$*&quot;用「&quot;」括起来的情况、以&quot;$1 $2 … $n&quot;的形式输出所有参数。$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如&quot;$@&quot;用「&quot;」括起来的情况、以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 这里直接copy runoob的内容 shell case 用法12345678910111213case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac shift命令：在shell中，经常可能会遇到多参数传递，例如$1,$2,…$9，借助shift命令可以访问更多传递的参数case语句： 以case开头，esac结尾； 取值后面必须为单词in 匹配一个值与一个模式以”)”(右括号)结束 双分号 “;;” 表示命令序列结束； 默认模式使用”*)”表示，在不满足前面的模式后，执行默认模式后的命令示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; echo &quot;$WORKERS_COUNT&quot; }help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac 效果如下:123[root@VM_175_142_centos ~]# ./shell_echo.sh workerStarting 2 workers for queues: queries,scheduled_queries...2 结束这里只是借助redash的sh脚本来简单了解了一下shell的一些常用命令及语法，当然，shell的强大之处肯定不止于此，后面再遇到的时候，再来学习。大家也可以去runoob系统的学习一下","link":"/20191114/shell-command.html"}],"tags":[{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"Go基础","slug":"Go基础","link":"/tags/Go%E5%9F%BA%E7%A1%80/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Datax","slug":"Datax","link":"/tags/Datax/"},{"name":"数据同步","slug":"数据同步","link":"/tags/%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5/"},{"name":"Tool","slug":"Tool","link":"/tags/Tool/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"ECMAScript","slug":"ECMAScript","link":"/tags/ECMAScript/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"Docker命令","slug":"Docker命令","link":"/tags/Docker%E5%91%BD%E4%BB%A4/"},{"name":".net core","slug":"net-core","link":"/tags/net-core/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"k8s","slug":"k8s","link":"/tags/k8s/"},{"name":"ack","slug":"ack","link":"/tags/ack/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":".net","slug":"net","link":"/tags/net/"},{"name":"微信公众号","slug":"微信公众号","link":"/tags/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Swagger","slug":"Swagger","link":"/tags/Swagger/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"autofac","slug":"autofac","link":"/tags/autofac/"},{"name":"mysql explain","slug":"mysql-explain","link":"/tags/mysql-explain/"},{"name":"Gis","slug":"Gis","link":"/tags/Gis/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"redash","slug":"redash","link":"/tags/redash/"}],"categories":[{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"Tool","slug":"Tool","link":"/categories/Tool/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"JavaScript","slug":"JavaScript","link":"/categories/JavaScript/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":".net core","slug":"net-core","link":"/categories/net-core/"},{"name":"Nginx","slug":"Nginx","link":"/categories/Nginx/"},{"name":".net","slug":"net","link":"/categories/net/"},{"name":"Vue","slug":"Vue","link":"/categories/Vue/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":"Gis","slug":"Gis","link":"/categories/Gis/"},{"name":"shell","slug":"shell","link":"/categories/shell/"}]}
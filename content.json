{"pages":[{"title":"关于我","text":"我是一个大龄低学历程序猿，虽然不是非常热爱代码，但是还是喜欢折腾，如果有兴趣交流，可以加我QQ:188781475","link":"/about/index.html"},{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"Docker常用命令整理","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 Docker基础命令docker images 查看当前下载镜像列表 12345[root@VM_175_142_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhwdsl2/ipsec-vpn-server latest 62e5a169190a 7 months ago 206MBpostgres latest 30bf4f039abe 8 months ago 312MBredis latest 0f88f9be5839 8 months ago 95MB docker search {镜像名} (镜像仓库中的镜像)docker pull {镜像名}:{版本号} (拉取指定版本镜像,如果不指定版本， 将默认使用 latest 镜像)docker run -t -i {镜像名} (启动镜像,如果主机不存在，会自动下载镜像) 123456789101112131415161718192021222324252627282930313233343536373839404142-d, --detach=false， 设置容器上前台运行还是后台运行，默认为false后台运行-i, --interactive=false， 打开STDIN，用于控制台交互-t, --tty=false， 分配tty设备，可以支持终端登录，默认为false-u, --user=&quot;&quot;， 设置容器的用户-a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=&quot;&quot; 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=&quot;&quot; 指定容器的内存上限 -P, --publish-all=false， 指定容器暴露的端口-p, --publish=[]， 指定容器暴露的端口-h, --hostname=&quot;&quot;， 指定容器的主机名-v, --volume=[]， 给容器挂载存储卷，挂载到容器的某个目录--volumes-from=[]， 给容器挂载其他容器上的卷，挂载到容器的某个目录--cap-add=[]， 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities--cap-drop=[]， 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities--cidfile=&quot;&quot;， 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法--cpuset=&quot;&quot;， 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU--device=[]， 添加主机设备给容器，相当于设备直通--dns=[]， 指定容器的dns服务器--dns-search=[]， 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件--entrypoint=&quot;&quot;， 覆盖image的入口点--env-file=[]， 指定环境变量文件，文件格式为每行一个环境变量--expose=[]， 指定容器暴露的端口，即修改镜像的暴露端口--link=[]， 指定容器间的关联，使用其他容器的IP、env等信息--lxc-conf=[]， 指定容器的配置文件，只有在指定--exec-driver=lxc时使用--name=&quot;&quot;， 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字--net=&quot;bridge&quot; 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge),但是不进行配置--privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=&quot;no&quot; 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 docker run -d --name=nginx nginx:latest -p 宿主机端口:容器端口 -v 宿主机目录:容器目录 docker ps #查看正在运行的容器docker ps -l #查看最后退出的容器的IDdocker ps -a #查看所有的容器，包括退出的。docker logs {容器ID|容器名称} #查询某个容器的所有操作记录。docker logs -f {容器ID|容器名称} #实时查看容易的操作记录。 1234docker rm$(docker ps -a -q) #删除所有容器docker rm {容器ID|容器名} #删除单个容器docker rmi {镜像ID} #删除单个镜像docker rmi$(docker images | grep none | awk &apos;{print $3}&apos; | sort -r) #删除所有镜像 docker stop {容器ID|容器名} #停止某个容器docker start {容器ID|容器名} #启动某个容器docker kill {容器ID|容器名} #杀掉某个容器 docker export {容器ID|容器名} -o /root/文件名.tar(或者docker export {容器ID|容器名} &gt; /root/文件名.tar) #导出docker import {容器文件} {镜像名}:{tag} #导入后生成的是镜像不是容器，docker load也可以导入，其中两者人区别如下： 12docker load 保留了容器的完整记录docker import 仅保存容器当时的快照状态，在导入的时候自己定义标签、名称等元数据 docker container inspect {容器ID|容器名} #返回容器的ID、创建时间、路径、状态、镜像等信息 docker container stats {容器ID|容器名} #查看容器的CPU、内存、存储、网络等资源的使用情况可以使用 docker cp {宿主机目录} {容器ID}:{容器目录} #将宿主机内的指定目录文件传输至容器内部的指定目录 docker cp {容器ID}:{容器目录} {宿主机目录} #将容器内部的指定目录文件复制到宿主机指定目录 docker commit {容器ID} {镜像名}:{tag} #将容器重新打包成镜像 1234567-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 docker push {镜像名|镜像ID} #推送在镜像仓库 Dockerfile文件参数 FROM #指定基础镜像，必须为第一个命令 MAINTAINER #作者信息 RUN #构建镜像时执行的命令 ADD #复制文件到容器中 COPY #复制文本到容器中COPY &lt;源路径&gt;… &lt;目标路径&gt; 1ADD和COPY的差别：ADD命令tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，COPY不会自动解压文件，也不能访问网络资源 CMD #容器启动时执行的命令。shell 格式： CMD &lt;命令&gt; exec 格式： CMD [“可执行文件”, “参数1”, “参数2”…] ENTRYPOINT #配置容器 LABEL #为镜像添加元数据 ENV #设置环境变量 EXPOSE #指定外界交互的容器端口EXPOSE &lt;端口1&gt; [&lt;端口2&gt;…] VOLUME #指定持久化目录VOLUME [“&lt;路径1&gt;”, “&lt;路径2&gt;”…] WORKDIR #工作目录，自动cd到执行目录 示例： 123456789101112 # FROM代表此次构建的镜像的基础镜像基础,可在镜像名后带版本号，不带版本号默认latestFROM python# COPY是拷贝宿主机文件到镜像中COPY ./spider /work# RUN则是在镜像中执行命令，有时候可能需要安装依赖环境，也可以在run中执行RUN ls /work# 切换工作目录，相当于cd workWORKDIR /work#EXPOSE 外界交互的端口EXPOSE 8080# CMD是镜像启动后默认执行，CMD加中括号等同于exec执行命令，不加中括号等同于 sh -c 执行命令CMD [&quot;python&quot;,&quot;spider.py&quot;] docker build ocnfig #用于检查dockerfile文件是否有误 docker build . -t spider:v1.0 #构建镜像，构建好之后可以使用docker images命令进行查询 Docker-compose.yml文件配置build：定义镜像生成，可以指定Dockerfile构建，在up 启动之时执行构建任务 image：指定镜像启动容器，如果镜像不存在会自动拉去最新镜像 environment：环境变量和配置 ports：端口映射，将容器端口映射在宿主机 depends_on：指定依赖关系。适用于需要按顺序启动的服务，会先启动所依赖的镜像 volumes：挂载宿主机目录或者数据容器卷 volumes_from: 从容器挂载 context：指定Dockerfile文件或者是远程网络文件 args：构建参数，这些参数只能在构建过程中访问 container_name：指定容器名称 links: 链接其他容器 command: 启动执行命令 示例： 123456789101112131415161718192021version: &quot;3&quot;services: pgsql: image: postgres ports: - &quot;15432:5432&quot; environment: POSTGRES_PASSWORD: scyd! volumes: - ./data/postgresql_data1:/var/lib/postgresql/data restart: always redis: image: redis command: redis-server --requirepass scyd! ports: - &quot;16379:6379&quot; volumes: - ./data/redis_data1:/data restart: always 执行docker-compose ps： 12345[root@VM_175_142_centos ~]# docker-compose ps Name Command State Ports -------------------------------------------------------------------------------root_pgsql_1 docker-entrypoint.sh postgres Up 0.0.0.0:15432-&gt;5432/tcproot_redis_1 docker-entrypoint.sh redis ... Up 0.0.0.0:16379-&gt;6379/tcp 容器名：{目录名}{服务名}{容器序号} 从1开始 docker-compose up -d #构建并启动容器,首次运行会执行docker-compose build 1234-d：后台进程--scale：指定服务运行的容器个数（如果服务有对外的端口就不能指定多个容器，因为端口已经被占用） Eg：docker-compose up -d --scale web=1 --scale redis=2 docker-compose exec {服务名称} bash #登录到某个容器中 docker-compose down #删除所有容器,镜像 docker-compose ps #显示所有容器 docker-compose restart {服务名称} #重新启动容器 docker-compose build {服务名称} #构建镜像 。 docker-compose build –no-cache {服务名称} #不带缓存的构建。 docker-compose logs {服务名称} #查看容器的日志 docker-compose logs -f {服务名称} #查看容器的实时日志 docker-compose rm {服务名称} #删除compose服务 docker-compose kill {服务名称} #kill compose服务 docker-compose stop {服务名称} #重启compose服务 docker-compose start {服务名称} #启动容器 docker-compose config -q #验证yml文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息 docker-compose run {服务名} {cmd} #在某个服务上运行shell命令","link":"/2019/11/08/Docker-compose-ymal/"},{"title":"借助alibaba Driud SQL Parser组件处理sql语句","text":"Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。 先来看看我们要达到的效果:这个项目的目的是让业务用户通过手动拖拽自己想要的字段即可展示、分析、下载数据，之前的流程是先添加数据源-&gt;在系统中导入表-&gt;配置分析模型-选择分析模型展示数据。这里的分析模型其实就是通过拖拽表类配置表与表之间是关联关系。然后拖拽字段后，前端就发送选择的字段表达式和过滤条件表达式到后端，通过配置是分析模型关系，解析出相应数据库的SQL语句发送到数据库执行。现在有一种场景，就是用户能只需要查询单张表，如果这样也需要去配置分析模型，那么就增加了复杂度。所以，需要给用户提供一种直接通过数据源直接选择未建立关联关系的原表来查询、分析、下载数据。由于项目是没有源代码，而且之前的解析那一块都是基于分析模型，内部逻辑比较复杂。所以我选择了一种相对来说要方便一点的方式就是通过Driud来解析生成SQL语句。我们都知道Druid是一个JDBC组件库，包括数据库连接池、SQL Parser等组件,我们一般都是拿来做JDBC连接池和SQL语句监控使用。这里，我只是把这次SQL Parser组件的使用过程记录一下。感兴趣的朋友可以去看看Druid 使用手册 Druid_SQL_AST学习什么是ASTAST是abstract syntax tree的缩写，也就是抽象语法树。和所有的Parser一样，Druid Parser会生成一个抽象语法树。 在Druid SQL Parser中有哪些AST节点类型在Druid中，AST节点类型主要包括SQLObject、SQLExpr、SQLStatement三种抽象类型。 123456789package com.alibaba.druid.sql.ast; interface SQLObject {}interface SQLExpr extends SQLObject {}interface SQLStatement extends SQLObject {} interface SQLTableSource extends SQLObject {}class SQLSelect extends SQLObject {}class SQLSelectQueryBlock extends SQLObject {} 常用的SQLExpr有哪些123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.alibaba.druid.sql.ast.expr; // SQLName是一种的SQLExpr的Expr，包括SQLIdentifierExpr、SQLPropertyExpr等public interface SQLName extends SQLExpr {} // 例如 ID = 3 这里的ID是一个SQLIdentifierExprclass SQLIdentifierExpr implements SQLExpr, SQLName { String name;} // 例如 A.ID = 3 这里的A.ID是一个SQLPropertyExprclass SQLPropertyExpr implements SQLExpr, SQLName { SQLExpr owner; String name;} // 例如 ID = 3 这是一个SQLBinaryOpExpr// left是ID (SQLIdentifierExpr)// right是3 (SQLIntegerExpr)class SQLBinaryOpExpr implements SQLExpr { SQLExpr left; SQLExpr right; SQLBinaryOperator operator;} // 例如 select * from where id = ?，这里的?是一个SQLVariantRefExpr，name是&apos;?&apos;class SQLVariantRefExpr extends SQLExprImpl { String name;} // 例如 ID = 3 这里的3是一个SQLIntegerExprpublic class SQLIntegerExpr extends SQLNumericLiteralExpr implements SQLValuableExpr { Number number; // 所有实现了SQLValuableExpr接口的SQLExpr都可以直接调用这个方法求值 @Override public Object getValue() { return this.number; }} // 例如 NAME = &apos;jobs&apos; 这里的&apos;jobs&apos;是一个SQLCharExprpublic class SQLCharExpr extends SQLTextLiteralExpr implements SQLValuableExpr{ String text;} 常用的SQLStatemment最常用的Statement当然是SELECT/UPDATE/DELETE/INSERT，他们分别是 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.alibaba.druid.sql.ast.statement; class SQLSelectStatement implements SQLStatement { SQLSelect select;}class SQLUpdateStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLUpdateSetItem&gt; items; SQLExpr where;}class SQLDeleteStatement implements SQLStatement { SQLTableSource tableSource; SQLExpr where;}class SQLInsertStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLExpr&gt; columns; SQLSelect query;}2.3. SQLTableSource常见的SQLTableSource包括SQLExprTableSource、SQLJoinTableSource、SQLSubqueryTableSource、SQLWithSubqueryClause.Entryclass SQLTableSourceImpl extends SQLObjectImpl implements SQLTableSource { String alias;} // 例如 select * from emp where i = 3，这里的from emp是一个SQLExprTableSource// 其中expr是一个name=emp的SQLIdentifierExprclass SQLExprTableSource extends SQLTableSourceImpl { SQLExpr expr;} // 例如 select * from emp e inner join org o on e.org_id = o.id// 其中left &apos;emp e&apos; 是一个SQLExprTableSource，right &apos;org o&apos;也是一个SQLExprTableSource// condition &apos;e.org_id = o.id&apos;是一个SQLBinaryOpExprclass SQLJoinTableSource extends SQLTableSourceImpl { SQLTableSource left; SQLTableSource right; JoinType joinType; // INNER_JOIN/CROSS_JOIN/LEFT_OUTER_JOIN/RIGHT_OUTER_JOIN/... SQLExpr condition;} // 例如 select * from (select * from temp) a，这里第一层from(...)是一个SQLSubqueryTableSourceSQLSubqueryTableSource extends SQLTableSourceImpl { SQLSelect select;} /* 例如WITH RECURSIVE ancestors AS ( SELECT * FROM org UNION SELECT f.* FROM org f, ancestors a WHERE f.id = a.parent_id)SELECT *FROM ancestors; 这里的ancestors AS (...) 是一个SQLWithSubqueryClause.Entry*/class SQLWithSubqueryClause { static class Entry extends SQLTableSourceImpl { SQLSelect subQuery; }}2.4. SQLSelect &amp; SQLSelectQuerySQLSelectStatement包含一个SQLSelect，SQLSelect包含一个SQLSelectQuery，都是组成的关系。SQLSelectQuery有主要的两个派生类，分别是SQLSelectQueryBlock和SQLUnionQuery。class SQLSelect extends SQLObjectImpl { SQLWithSubqueryClause withSubQuery; SQLSelectQuery query;} interface SQLSelectQuery extends SQLObject {} class SQLSelectQueryBlock implements SQLSelectQuery { List&lt;SQLSelectItem&gt; selectList; SQLTableSource from; SQLExprTableSource into; SQLExpr where; SQLSelectGroupByClause groupBy; SQLOrderBy orderBy; SQLLimit limit;} class SQLUnionQuery implements SQLSelectQuery { SQLSelectQuery left; SQLSelectQuery right; SQLUnionOperator operator; // UNION/UNION_ALL/MINUS/INTERSECT} SQLCreateTableStatement建表语句包含了一系列方法，用于方便各种操作 1234567891011121314public class SQLCreateTableStatement extends SQLStatementImpl implements SQLDDLStatement, SQLCreateStatement { SQLExprTableSource tableSource; List&lt;SQLTableElement&gt; tableElementList; Select select; // 忽略大小写的查找SQLCreateTableStatement中的SQLColumnDefinition public SQLColumnDefinition findColumn(String columName) {} // 忽略大小写的查找SQLCreateTableStatement中的column关联的索引 public SQLTableElement findIndex(String columnName) {} // 是否外键依赖另外一个表 public boolean isReferenced(String tableName) {}} 怎样产生AST通过SQLUtils产生List1234import com.alibaba.druid.util.JdbcConstants; String dbType = JdbcConstants.MYSQL;List&lt;SQLStatement&gt; statementList = SQLUtils.parseStatements(sql, dbType); 通过SQLUtils产生SQLExpr12String dbType = JdbcConstants.MYSQL;SQLExpr expr = SQLUtils.toSQLExpr(&quot;id=3&quot;, dbType); 怎样打印AST节点通过SQLUtils工具类打印节点123456789package com.alibaba.druid.sql; public class SQLUtils { // 可以将SQLExpr/SQLStatement打印为String类型 static String toSQLString(SQLObject sqlObj, String dbType); // 可以将一个&amp;lt;SQLStatement&amp;gt;打印为String类型 static String toSQLString(List&lt;SQLStatement&gt; statementList, String dbType);} 在Select语句中添加Group by这个先简单的做一个场景，依然拿本次这个项目来说，在前端发送SUM、COUNT等聚合表达式的SQL时，我们需要在语句后面添加Group by。 123456789101112131415161718192021222324252627282930313233343536373839404142public static String getSql(String sql, int offset, int count) { List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, JdbcConstants.MYSQL); SQLSelectStatement sqlSelectStatement = (SQLSelectStatement) stmtList.get(0); SQLSelectQuery sqlSelectQuery = sqlSelectStatement.getSelect().getQuery(); MySqlSchemaStatVisitor visitor = new MySqlSchemaStatVisitor(); sqlSelectStatement.accept(visitor); if (sqlSelectQuery instanceof SQLSelectQueryBlock) { SQLSelectQueryBlock sqlSelectQueryBlock = (SQLSelectQueryBlock) sqlSelectQuery; List&lt;TableStat.Column&gt; cols = new ArrayList&lt;&gt;(visitor.getColumns()); SQLExpr where = sqlSelectQueryBlock.getWhere(); // 获取字段列表 List&lt;SQLSelectItem&gt; selectItems = sqlSelectQueryBlock.getSelectList(); int idx = 0; boolean hasAggregate = false; SQLSelectGroupByClause sqlSelectGroupByClause = new SQLSelectGroupByClause(); //判断是否有聚合函数 for (int selectIdx = 0; selectIdx &lt;= selectItems.size() - 1; selectIdx++) { if (selectItems.get(selectIdx).getExpr() instanceof SQLAggregateExpr) { hasAggregate = true; break; } } if (hasAggregate) { //添加SQLSelectGroupByClause字段 for (int colIndex = 0; colIndex &lt;= cols.size() - 1; colIndex++) { if (cols.get(colIndex).isSelect()) { sqlSelectGroupByClause.addItem(SQLUtils.toSQLExpr(cols.get(colIndex).toString(), JdbcConstants.MYSQL)); } } } sqlSelectQueryBlock.setGroupBy(sqlSelectGroupByClause); if (count &gt;= 1) { return PagerUtils.limit(sqlSelectStatement.toString(), JdbcConstants.MYSQL, offset, count); } return sqlSelectStatement.toString(); } return &quot;&quot;; } 输入sql语句： 1SELECT SUM(`address`) `address`,SUM(`address1`) `address1` FROM `demo` WHERE 1 = 1 最终结果: 1234SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1 生成分页 12345SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1LIMIT 1, 100 Druid支持多种数据库的sql解析,在JdbcConstants中可以看到 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public interface JdbcConstants { String JTDS = &quot;jtds&quot;; String MOCK = &quot;mock&quot;; String HSQL = &quot;hsql&quot;; String DB2 = &quot;db2&quot;; String DB2_DRIVER = &quot;com.ibm.db2.jcc.DB2Driver&quot;; String POSTGRESQL = &quot;postgresql&quot;; String POSTGRESQL_DRIVER = &quot;org.postgresql.Driver&quot;; String SYBASE = &quot;sybase&quot;; String SQL_SERVER = &quot;sqlserver&quot;; String SQL_SERVER_DRIVER = &quot;com.microsoft.jdbc.sqlserver.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_SQLJDBC4 = &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_JTDS = &quot;net.sourceforge.jtds.jdbc.Driver&quot;; String ORACLE = &quot;oracle&quot;; String ORACLE_DRIVER = &quot;oracle.jdbc.OracleDriver&quot;; String ORACLE_DRIVER2 = &quot;oracle.jdbc.driver.OracleDriver&quot;; String ALI_ORACLE = &quot;AliOracle&quot;; String ALI_ORACLE_DRIVER = &quot;com.alibaba.jdbc.AlibabaDriver&quot;; String MYSQL = &quot;mysql&quot;; String MYSQL_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String MYSQL_DRIVER_6 = &quot;com.mysql.cj.jdbc.Driver&quot;; String MYSQL_DRIVER_REPLICATE = &quot;com.mysql.jdbc.&quot;; String MARIADB = &quot;mariadb&quot;; String MARIADB_DRIVER = &quot;org.mariadb.jdbc.Driver&quot;; String DERBY = &quot;derby&quot;; String HBASE = &quot;hbase&quot;; String HIVE = &quot;hive&quot;; String HIVE_DRIVER = &quot;org.apache.hive.jdbc.HiveDriver&quot;; String H2 = &quot;h2&quot;; String H2_DRIVER = &quot;org.h2.Driver&quot;; String DM = &quot;dm&quot;; String DM_DRIVER = &quot;dm.jdbc.driver.DmDriver&quot;; String KINGBASE = &quot;kingbase&quot;; String KINGBASE_DRIVER = &quot;com.kingbase.Driver&quot;; String GBASE = &quot;gbase&quot;; String GBASE_DRIVER = &quot;com.gbase.jdbc.Driver&quot;; String XUGU = &quot;xugu&quot;; String XUGU_DRIVER = &quot;com.xugu.cloudjdbc.Driver&quot;; String OCEANBASE = &quot;oceanbase&quot;; String OCEANBASE_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String INFORMIX = &quot;informix&quot;; /** * 阿里云odps */ String ODPS = &quot;odps&quot;; String ODPS_DRIVER = &quot;com.aliyun.odps.jdbc.OdpsDriver&quot;; String TERADATA = &quot;teradata&quot;; String TERADATA_DRIVER = &quot;com.teradata.jdbc.TeraDriver&quot;; /** * Log4JDBC */ String LOG4JDBC = &quot;log4jdbc&quot;; String LOG4JDBC_DRIVER = &quot;net.sf.log4jdbc.DriverSpy&quot;; String PHOENIX = &quot;phoenix&quot;; String PHOENIX_DRIVER = &quot;org.apache.phoenix.jdbc.PhoenixDriver&quot;; String ENTERPRISEDB = &quot;edb&quot;; String ENTERPRISEDB_DRIVER = &quot;com.edb.Driver&quot;; String KYLIN = &quot;kylin&quot;; String KYLIN_DRIVER = &quot;org.apache.kylin.jdbc.Driver&quot;; String SQLITE = &quot;sqlite&quot;; String SQLITE_DRIVER = &quot;org.sqlite.JDBC&quot;; String ALIYUN_ADS = &quot;aliyun_ads&quot;; String ALIYUN_DRDS = &quot;aliyun_drds&quot;; String PRESTO = &quot;presto&quot;; String PRESTO_DRIVER = &quot;com.facebook.presto.jdbc.PrestoDriver&quot;; String ELASTIC_SEARCH = &quot;elastic_search&quot;; String ELASTIC_SEARCH_DRIVER = &quot;com.alibaba.xdriver.elastic.jdbc.ElasticDriver&quot;; String CLICKHOUSE = &quot;clickhouse&quot;; String CLICKHOUSE_DRIVER = &quot;ru.yandex.clickhouse.ClickHouseDriver&quot;;} github","link":"/2019/11/20/Driud-SqlParse/"},{"title":"Nginx HTTP/TCP代理配置","text":"众所周知，nginx是一款高性能的反向代理工具，在之前nginx只能代理应用层的应用，如果是要做TCP即网络第4层的代理就只有借助HaProxy等工具，在nginx1.9版本之后即可支持TCP的代理。下面，我们来展现一下nginx强大的代理能力。 我们的网络有内网和办公网还有互联网，首先所有项目部署在内网，使用只能在生产网(需要开通特殊策略)，特殊情况下，可以申请互联网的网络，但是比较麻烦，而且，我们进入生产服务器必须在内网的环境下通过堡垒机才能登陆，现在多个生产部署多个系统，但是映射到办公网只有个IP且只有一个端口。此时，我们就需要用到反向代理实现系统的访问。 Nginx基本配置说明 nginx有强大的url匹配功能，下面，我们一起来了解一下nginx的优先级匹配。以下是匹配语法模版 1234location [=|~|~*|^~] /uri/ { root html; index index.html index.htm;} 说明： 1234567= 表示精确匹配^~ 表示uri以某个常规字符串开头~ 表示区分大小写的正则匹配~* 表示不区分大小写的正则匹配 !~ 表示区分大小写不匹配的正则!~* 表示不区分大小写不匹配的正则/ 通用匹配，相当于根目录可以匹配到任何请求 优先级: 精确匹配&gt;普通匹配&gt;正则匹配 nginx对http进行反向代理： 123location / { proxy_pass http://127.0.0.1; } Nginx Http反向代理实践配置下面是我们为解决上面的问题所做的配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //HTTP代理 location / { proxy_pass http://xx.xx.xxx.xxx:8081/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /Insight { proxy_pass http://xx.xxx.x.xxx:8083/BingoInsight; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /etl{ proxy_pass http://xx.xxx.x.xxx:8080/etl; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header Host $host:$server_port; #这里是重点,这样配置才不会丢失端口} //websocket 代理 location /gateone/{ proxy_pass http://xx.xx.xx.xx:58080/gateone/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; client_max_body_size 300m; proxy_http_version 1.1; proxy_redirect off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;} ...... Nginx 代理转发TCP配置 我又有另外一个场景，也是内网和办公网的交互，但是这个场景不需要那么严格，可以直连服务器，但是我们是想在办公网直连数据库。这显然形成了一个屏障 这种情况下，我们想要连接到数据库就只有做一个TCP四层代理。我们就可以借助nginx upstream的功能实现TCP转发。配置如下 123456789upstream proxy_redis{ server xx.xxx.xx.xxx:6379;} server { listen 6379; #监听端口 proxy_pass proxy_redis; #转发请求} 然后刷新一下nginx配置: 1nginx -s reload 此时连接代理服务器响应的端口，就可以将TCP请求转发到实际服务器。 官方文档nginx下载地址","link":"/2019/11/08/Nginx-agent-configuration/"},{"title":"Go在Windows下编译linux可执行二进制文件","text":"完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？ 完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？我们需要修改几个参数： 1234SET CGO_ENABLED=0SET GOARCH=amd64SET GOOS=linuxgo build main.go 一次执行以上命令，就可以在项目目录生成一个二进制文件，所修改的变量值仅对当前窗口有效，可以如果我们每次都需要输入这些命令的话，着实还是有些繁琐，那么，我们可以新建一个bat文件，将命令复制到bat文件中，以后每次就只需要执行这个bat文件即可。如果又想编译成Windows文件，要么就是关闭窗口重新打开，要么就是修改变量值： 1234SET CGO_ENABLED=1SET GOARCH=SET GOOS=windowsgo build main.go","link":"/2019/11/03/Go%E5%9C%A8Windows%E4%B8%8B%E7%BC%96%E8%AF%91linux%E5%8F%AF%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"},{"title":"Linux中inode引起的故障","text":"inode是什么？ ETL脚本调度故障今日一大早，用户群就炸了，很多人说脚本调度无法运行，一直是未开始状态，起初，我并未引起重视，猜想可能是pieline服务阻塞引起的，由于情况紧急，就直接进入到tomcat manager进行reload操作，但是奇怪的是，reload之后，大批量的作业都直接终止掉，查看日志，发现是ETL脚本日志创建失败， 遂想到，肯定是文件系统占满，就开始rm一部分，然后，df -h，发现还有160+G，以为问题就解决掉了，但是没过多久，依然有很多未开始的作业。 df -i 解围因为对linux使用不是很熟，也只会ps -ef、cd、kill等常用命令，在百度中得知一个命令df -i，执行命令后，发现使用率100%，原来，真正的原因是：etl工具每天产生的小文件过多，把inode占满，导致工具无法创建日志文件。既然找到原因，当然就只有找到目录，将历史文件给rm掉 df的用法df命令一般用于查看磁盘空间大小，du -sh 查看当前目录使用大小。df -h 大文件占用大量的磁盘容量。df -i 过多的文件占用了大量的inode号。 [参考]linux命令df中df -h和df -i的区别","link":"/2019/10/24/Linux%E4%B8%ADinode%E5%BC%95%E8%B5%B7%E7%9A%84%E6%95%85%E9%9A%9C/"},{"title":".net core 3.x使用Swagger","text":".net core3.0问世已经两个多月了，我并没有急着将生产上的项目升级到3.0，因为怕踩坑，这不3.1马上就要出来了，想着core3.x逐渐稳定，所以就开始来琢磨一下，此次就简单是说一下.net core3.0中使丝袜哥(Swagger)生成API文档。 在这里，我使用的开发工具是VS2019,Swashbuckle.AspNetCore 5.0.0-rc4， 安装Swashbuckle.AspNetCore1、首先新建一个Web API项目2、安装swagger,打开程序包管理器控制台执行： 1Install-Package Swashbuckle.AspNetCore -Version 5.0.0-rc4 引用Swagger1、在Startup.cs中引入命名空间 12using Microsoft.OpenApi.Models;using Swashbuckle.AspNetCore.Swagger; 2、在ConfigureServices中添加Swagger 1234services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot; }); }); 3、在Configure中添加Swagger中间件,我们最好放在env.IsDevelopment()中 123456789if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;Demo API&quot;); }); app.UseDeveloperExceptionPage(); } 4、配置完后，运行一下，在浏览器中输入http://localhost:5000/swagger, 看看效果： 为Api添加注释刚才的配置，只是能看到我们的API方法，并且可以发送调试请求，但是没有注释，接下来，我们就给API加上注释1、在想要添加注释的API对应分方法上添加注释,格式如下： 12345678910111213141516/// &lt;summary&gt; /// 获取天气预报信息 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] public IEnumerable&lt;WeatherForecast&gt; Get() { var rng = new Random(); return Enumerable.Range(1, 5).Select(index =&gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)] }) .ToArray(); } 2、在项目属性选项卡中，设置生成中的XML文档输出目录:3、在AddSwaggerGen中添加xml文件路径: 123456services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; } }); var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); swagger.IncludeXmlComments(docXmlPath); }); 4、最终效果: 每次启动都会打开默认的IE浏览器，由于个人喜欢Google浏览器，所以，现在修改vs启动的默认浏览器：另外，每次启动，在浏览中打开的是默认的Controller，我们可以设置一下启动参数，让每次启动都是Swagger目录，就不需要我们每次都手动输入Swagger目录：。 这次写的是Swagger最基本的设置,后面我们会继续学习一些常用的高级功能。","link":"/2019/11/12/net-core-3-0-use-swagger-ui/"},{"title":"golang平滑升级服务","text":"不中断服务进行服务升级 最近在学习go语言，想着用gin+gorm来做一个微信小程序，在gin的github中看到了如何优雅的重启或者停止，因为在生产项目中，如果强行kill掉的话会造成正在执行的业务中断、用户访问被拒绝。显然，平滑的重启或升级我们的应用是多么的重要。 .net的发布过程我做了很多年的.net ，但是从来没有想过如何去平滑更新服务端，也是因为业务要求的可用性不高。一般发布新版本都是采用最笨拙的方式，就是发通知(xx时间升级会暂停服务)-&gt;到点停止服务备份、copy新文件-&gt;启动服务。 java的发布过程在用java做项目的时候，当时就用到了nginx中的upstream来负载均衡，当然，这时候要求的可用性较高，所以在发布服务的时候，就不能再采用简单粗暴的停止-启动大法。我们可以配合nginx -s reload来实现后端服务的灰度发布并且让用户无感知。 golang的发布过程Graceful restart or stopgolang中有很多开源的解决方案：endlessgraceoverseer 实践出真知在这里我们来试试grace(star最多，commits最多)，在github上面有详细的demo和测试步骤。v1 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) v2 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin New Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) 如果是在windows环境下开发，会提示: 1github.com\\facebookgo\\grace\\gracehttp\\http.go:104:53: undefined: syscall.SIGUSR2 貌似是因为grace不支持windows的原因，我们可以暂时不用搭理他，先编译一个二进制文件， 123SET GOARCH=amd64SET GOOS=linuxgo build main.go 把生成好的文件复制到linux上，先启动起来(我是用的nohup ./grace &amp;来启动的)，这时候我们查看pid是多少 1234ps -ef|grep graceroot 11915 11364 0 13:06 pts/0 00:00:00 ./graceroot 11921 11364 0 13:08 pts/0 00:00:00 grep --color=auto grace 此时访问服务结果：这时候，我们把之前的文件备份，将v2的代码编译好并拷贝上去，执行命令 123456kill -USR2 11915这时候在看看应用进程ps -ef|grep graceroot 11928 1 0 13:11 pts/0 00:00:00 ./graceroot 11935 11364 0 13:12 pts/0 00:00:00 grep --color=auto grace pid已经变为11928,此时访问服务结果：[参考]https://github.com/facebookarchive/gracehttps://github.com/gin-gonic/gin","link":"/2019/10/24/golang%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7%E6%9C%8D%E5%8A%A1/"},{"title":"golang下载妹子图","text":"想用golang下载妹子图吗？点进来看看吧!很方便 闲来无趣，就想着看用golang来做点什么事情，这不，到处都是python下载妹子图,我就想着用golang来弄一个下载妹子图的简单小工具 简单分析页面结构访问https://www.meizitu.com 页面后, 进入到详情页面，可以看到url变为https://www.meizitu.com/a/5511.html ，我们将url中的数字任意修改，发现都能访问，那么，我们暂且就通过手动输入页面索引的方式来访问页面。我们再看看页面结构,通过google浏览器的开发者工具很容易就可以看到： 下载图片刚才我们已经大致的分析了页面结构，接下来 ，我们就开始简单的实现图片下载的功能，在这里我们选用了：colly:用于采集页面和图片uuid:生产UUIDcli:命令行工具包1、我们先初始化一个队列，用于存放需要访问的url 1234var q, _ = queue.New( 2, // Number of consumer threads &amp;queue.InMemoryQueueStorage{MaxSize: 10000}, // Use default queue storage ) 2、初始化需要下载的页面，我用命令行的方式来决定起始页 123456789101112if args := context.Args(); len(args) &gt; 0 { return fmt.Errorf(&quot;invalid command: %q&quot;, args.Get(0)) } start := context.Int(&quot;s&quot;) log.Println(&quot;起始页:&quot;, start) end := context.Int(&quot;e&quot;) log.Println(&quot;截止页:&quot;, end) for i := start; i &lt;= end; i++ { url := fmt.Sprintf(&quot;https://www.meizitu.com/a/%d.html&quot;, i) q.AddURL(url)} 3、初始化一个colly来处理队列中的url,我在OnHTML中，查找页面的postContent&gt;img的dom节点，获取图片的路径，又放在队列中 1234567891011121314151617181920c := colly.NewCollector() c.UserAgent = &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot; c.OnHTML(&quot;.postContent&quot;, func(e *colly.HTMLElement) { //e.Request.Visit(e.Attr(&quot;href&quot;)) e.ForEach(&quot;img&quot;, func(i int, element *colly.HTMLElement) { //e.Request.Visit(element.Attr(&quot;src&quot;)) q.AddURL(element.Attr(&quot;src&quot;)) }) }) c.OnResponse(func(resp *colly.Response) { if strings.Contains(resp.Headers.Get(&quot;Content-Type&quot;), &quot;image/jpeg&quot;) { download(resp.Body) } }) c.OnRequest(func(r *colly.Request) { fmt.Println(&quot;Visiting&quot;, r.URL) }) q.Run(c) 最后的效果：代码很简单，如果需要可以去https://github.com/eyiadmin/meizitu 看看，如果想下载图片，就直接下载exe文件。在命令行输入main -s 1 -e 100即可下载 12345678910111213141516171819202122232425main -s 100 -e 1082019/10/07 14:26:42 起始页: 1002019/10/07 14:26:43 截止页: 108Visiting https://www.meizitu.com/a/100.htmlVisiting https://www.meizitu.com/a/101.htmlVisiting https://www.meizitu.com/a/102.htmlVisiting https://www.meizitu.com/a/103.htmlVisiting https://www.meizitu.com/a/104.htmlVisiting https://www.meizitu.com/a/105.htmlVisiting https://www.meizitu.com/a/106.htmlVisiting https://www.meizitu.com/a/107.htmlVisiting https://www.meizitu.com/a/108.htmlVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/04.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/05.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/06.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/07.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/08.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/09.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/04.jpg","link":"/2019/10/24/golang%E4%B8%8B%E8%BD%BD%E5%A6%B9%E5%AD%90%E5%9B%BE/"},{"title":".net core使用Topshelf注册windows服务","text":"Topshelf注册windows服务，方便快捷 我们经常会用一些定时处理的任务，在.net种一般是结合Quartz或者hangfire这两个组件实现定时周期性作业，但是我想把开发好的定时作业注册成windows服务，这样，在服务器重启之后，可以自动运行服务。Topshelf 就可以很方便的开发windows，而且注册安装也很方便。TopShelf的地址：http://topshelf-project.com/我们首先使用netget安装TopShelf： 1Install-Package TopShelf 然后在program.cs中加入如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243var builder = new HostBuilder() .ConfigureAppConfiguration(config =&gt; { config.AddJsonFile(&quot;monitor.json&quot;, optional: true, reloadOnChange: true); }) .ConfigureServices((hostContext, services) =&gt; { services.Configure&lt;Config&gt;(hostContext.Configuration.GetSection(&quot;monitor&quot;)); services.AddSingleton&lt;IHostLifetime, TopshelfLifetime&gt;(); services.AddHostedService&lt;MonitorService&gt;(); });HostFactory.Run(service =&gt; { service.SetServiceName(&quot;服务名&quot;); service.SetDisplayName(&quot;服务显示名称&quot;); service.SetDescription(&quot;服务描述&quot;); service.UseLog4Net(&quot;log4net.config&quot;); service.Service&lt;IHost&gt;(host =&gt; { host.ConstructUsing(() =&gt; builder.Build()); host.WhenStarted(serviceInstance =&gt; { serviceInstance.StartAsync(); }); host.WhenStopped(serviceInstance =&gt; { serviceInstance.StopAsync(); }); }); service.OnException((ex) =&gt; { Console.WriteLine(&quot;Exception thrown - &quot; + ex.Message); }); service.RunAsLocalSystem(); }); } 新建一个类继承IHostedService接口: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MonitorService : IHostedService, IDisposable { private IScheduler scheduler; static readonly LogWriter _log = HostLogger.Get&lt;MonitorService&gt;(); public readonly Config Config; private Timer _timer; Config _config; public MonitorService() { } public MonitorService(IOptions&lt;Config&gt; config) { _config = config?.Value; //Config = _config; } public async Task StartAsync(CancellationToken cancellationToken) { _log.Info(&quot;service starting&quot;); ISchedulerFactory sf = new StdSchedulerFactory(); scheduler = await sf.GetScheduler(); IJobDetail job = JobBuilder.Create&lt;AreaSyncJob&gt;().WithIdentity(&quot;job1&quot;, &quot;group1&quot;).Build(); ITrigger trigger = TriggerBuilder.Create().WithIdentity(&quot;triggger1&quot;, &quot;group1&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.AreaJobCronExpr))).Build(); IJobDetail job1 = JobBuilder.Create&lt;LocationSyncJob&gt;().WithIdentity(&quot;job2&quot;, &quot;group2&quot;).Build(); ITrigger trigger1 = TriggerBuilder.Create().WithIdentity(&quot;triggger2&quot;, &quot;group2&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.LocationCronExpr))).Build(); IJobDetail job2 = JobBuilder.Create&lt;TaskExecAyncJob&gt;().WithIdentity(&quot;job3&quot;, &quot;group3&quot;).Build(); ITrigger trigger2 = TriggerBuilder.Create().WithIdentity(&quot;triggger3&quot;, &quot;group3&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.TaskExecCronExpr))).Build(); IJobDetail job3 = JobBuilder.Create&lt;MonitorJob&gt;().WithIdentity(&quot;job4&quot;, &quot;group4&quot;).Build(); ITrigger trigger3 = TriggerBuilder.Create().WithIdentity(&quot;triggger4&quot;, &quot;group4&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.MonitorCronExpr))).Build(); //启动任务 await scheduler.ScheduleJob(job, trigger); await scheduler.ScheduleJob(job1, trigger1); await scheduler.ScheduleJob(job2, trigger2); await scheduler.ScheduleJob(job3, trigger3); await scheduler.Start(); _log.Info(&quot;service started&quot;); } public Task StopAsync(CancellationToken cancellationToken) { _timer?.Change(Timeout.Infinite, 0); scheduler?.Shutdown(); return Task.CompletedTask; } public void Dispose() { scheduler = null; _timer?.Dispose(); } } StartAsync方法为服务启动时运行。然后编译程序： 1dotnet publish -o ./bin/output -c Release -r win7-x64 执行成功后，会在bin/output目录下生成运行所需要的的程序和依赖DLL。将整个目录复制到指定服务器，cmd进入到程序目录，执行： 1xxxx.exe install 就可以完成服务安装.执行: 1xxxx.exe uninstall 就可以完成服务卸载，非常方便。","link":"/2019/10/31/net-core%E4%BD%BF%E7%94%A8Topshelf%E6%B3%A8%E5%86%8Cwindows%E6%9C%8D%E5%8A%A1/"},{"title":"AccessibilityService自动刷视频","text":"使用AccessibilityService实现自动刷视频，赚点小钱 最近很多人在推精简版的快手、抖音等app来赚钱，邀请人之后，可得佣金，每天刷视频也可以的金币换RMB，所以一些闲来无事的人就整体拿着手机刷刷刷，那么有没有什么自动的方式，让我们解放双手呢？Android自动化测试的框架比较多，大家可以自行百度。下面就介绍几种常用的： 模拟MotionEvent这个功能只能给自己本身的app发送Event，无法跨App。 Instrumentation现在有很多基于Instrumentation的自动化测试框架，但是也无法跨App操作，如果想要跨App的话，就只有获得root权限或者系统签名。这两种方式都有些麻烦。 ADB命令需要在PC端执行adb命令，那么就需要USB连接到电脑上，在PC端发送input的shell脚本命令，如果再手机端执行input tap等命令，也需要root权限。操作还是很麻烦 AccessibilityService服务现在很多复制工具都是基于AccessibilityService开发的，通过给予一定的权限，监听手机端的动作，然后查找相应节点，向指定节点发送相应的指令。为了节约时间，我在百度找到一篇文章AccessibilityService实现文本的自动全选黏贴、点击、滑动。利用dispatchGesture+AccessibilityService来实现自动刷新视频，我将其稍作修改，就可以对刷抖音、快手、趣多多等app进行跨应用刷视频，这样一来省了不少时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private void slideVertical(int startSlideRatio, int stopSlideRatio) { sliderCount++; int screenHeight = ScreenUtils.getScreenHeight(getApplicationContext()); int screenWidth = ScreenUtils.getScreenWidth(getApplicationContext()); L.e(&quot;屏幕：&quot; + (screenHeight - (screenHeight / 10)) + &quot;/&quot; + (screenHeight - (screenHeight - (screenHeight / 10))) + &quot;/&quot; + screenWidth / 2); Path path = new Path(); int start = (screenHeight / 20) * startSlideRatio; int stop = (screenHeight / 20) * stopSlideRatio; L.e(&quot;屏幕：&quot; + start + &quot;/&quot; + stop + &quot;/&quot; + screenWidth / 2); path.moveTo(screenWidth / 2, start);//如果只是设置moveTo就是点击 path.lineTo(screenWidth / 2, stop);//如果设置这句就是滑动 StringBuffer sb = new StringBuffer(); sb.append(&quot;滑动次数&quot; + sliderCount + &quot;次\\n&quot;); sb.append(&quot;滑动时间&quot; + Utils.formatUTC(System.currentTimeMillis(),null) + &quot;\\n&quot;); sb.append(&quot;开始位置&quot; + start + &quot;\\n&quot;); sb.append(&quot;结束位置&quot; + stop + &quot;\\n&quot;); Intent mIntent = new Intent(MainActivity.RECEIVER_ACTION); mIntent.putExtra(&quot;result&quot;, sb.toString()); //发送广播 sendBroadcast(mIntent); GestureDescription.Builder builder = new GestureDescription.Builder(); GestureDescription gestureDescription = builder .addStroke(new GestureDescription. StrokeDescription(path, 200, 200)) .build(); dispatchGesture(gestureDescription, new GestureResultCallback() { @Override public void onCompleted(GestureDescription gestureDescription) { super.onCompleted(gestureDescription); L.w(&quot;滑动结束&quot; + gestureDescription.getStrokeCount()); } @Override public void onCancelled(GestureDescription gestureDescription) { super.onCancelled(gestureDescription); L.w(&quot;滑动取消&quot;); } }, null); } 效果图:","link":"/2019/10/24/AccessibilityService%E8%87%AA%E5%8A%A8%E5%88%B7%E8%A7%86%E9%A2%91/"},{"title":"nginx搭建https服务","text":"nginx搭建https服务,转发到http后端服务 花了差不多5个小时用golang做了一个短域名服务+简单的微信小程序，在发布的时候需要用过https协议的服务，遂出此文 gin发布https因为是第一次用gin发布一个真实的环境，很多东西也不是很熟，所以只能百度，当时找到gin中间件把端口转换为https协议这篇文章，看了一下，很简单，就尝试着cv实现以下。由于的采用了gin在github提到的Graceful restart or stop功能，简单cv没有实现，就想了一个便捷的方式(毕竟菜嘛)–采用nginx代理一层。 采用nginx部署https安装步骤 123456789101112# 安装依赖yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel# 下载nginxwget http://nginx.org/download/nginx-1.17.4.tar.gz# 解压文件tar -zxvf nginx-1.17.4.tar.gz# 进入nginx源码目录cd nginx-1.17.4# 配置https模块./configure --prefix=/root/nginx --with-http_stub_status_module --with-http_ssl_module# 编译并安装make &amp;&amp; make install 如果上面的步骤没有异常，那么久算安装成功了，下面就开始配置https代理。 1、先把申请下来的证书复制到nginx目录下，我是新建了一个cert的文件目录，2、修改nginx.conf123456789101112131415161718192021server { listen 443 ssl; server_name domain; ssl_certificate /root/nginx/cert/1_domain_bundle.crt; #证书公钥 ssl_certificate_key /root/nginx/cert/2_domain.key; #证书私钥 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDH:AESGCM:HIGH:!RC4:!DH:!MD5:!3DES:!aNULL:!eNULL; ssl_prefer_server_ciphers on; location / { proxy_pass http://0.0.0.0:80; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } } 3、进入到nginx目录执行sbin/nginx执行二进制文件启动nginx服务，如果修改了conf配置文件，则执行sbin/nginx -s reload 刷新配置。至此，nginx服务便搭建好了。在微信小程序开发设置里面配置好https的域名地址，就可以愉快的玩耍了。","link":"/2019/10/24/nginx%E6%90%AD%E5%BB%BAhttps%E6%9C%8D%E5%8A%A1/"},{"title":"基于redis key失效机制实现状态实时更新","text":"基于redis key失效事件通知机制来处理状态实时更新 在我们的业务中，有这样一个场景，在手机端实时采集用用户经纬度，判断用户是否在某个场景(小区、商场等)内,如果再场景内则变更用户任务状态为”执行中”，当用户离开场景超过20分钟，需要将用户任务状态更改为”离场”状态。 一般，我们更新状态，要么定时去扫描数据库，要么就是触发某个事件，在最开始，有想到几种方案：1、定时（采用quartz定时执行作业，去扫描数据库）2、用hangfire、rabbitmq等实现延迟执行3、redis key失效事件，实时处理经过评估，最后选择了redis key失效机制来处理这个业务。 redis key失效事件监听redis自2.8之后就提供Keyspace Notifications功能，允许客户订阅Pub/Sub。 开启事件通知默认情况下，redis是没有开启事件通知的，所以我们需要手动配置： 12打开redis.conf配置文件搜索notify-keyspace-events，该配置默认是被注释掉的，需要将其修改为notify-keyspace-events Ex ,然后重启便可生效 值说明: 1234567891011# K 键空间通知，以__keyspace@&lt;db&gt;__为前缀# E 键事件通知，以__keysevent@&lt;db&gt;__为前缀# g del , expipre , rename 等类型无关的通用命令的通知, ...# $ String命令# l List命令# s Set命令# h Hash命令# z 有序集合命令# x 过期事件（每次key过期时生成）# e 驱逐事件（当key在内存满了被清除时生成）# A g$lshzxe的别名，因此”AKE”意味着所有的事件 spring boot实现消息监听器类pom.xml: 12345678910111213141516171819202122 &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.12&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Componentpublic class RedisMsgPubSubListener extends JedisPubSub { private Logger logger = LoggerFactory.getLogger(getClass()); @Autowired ITaskService taskService; @Override public void unsubscribe() { super.unsubscribe(); } @Override public void unsubscribe(String... channels) { super.unsubscribe(channels); } @Override public void subscribe(String... channels) { super.subscribe(channels); } @Override public void psubscribe(String... patterns) { super.psubscribe(patterns); } @Override public void punsubscribe() { super.punsubscribe(); } @Override public void punsubscribe(String... patterns) { super.punsubscribe(patterns); } @Override public void onMessage(String channel, String message) { System.out.println(&quot;channel:&quot; + channel + &quot;receives message :&quot; + message); String key = message; } @Override public void onPMessage(String pattern, String channel, String message) { } @Override public void onSubscribe(String channel, int subscribedChannels) { } @Override public void onPUnsubscribe(String pattern, int subscribedChannels) { } @Override public void onPSubscribe(String pattern, int subscribedChannels) { } @Override public void onUnsubscribe(String channel, int subscribedChannels) { }} 创建一个Runner： 123456789101112131415161718192021public class RedisApplicationRunner implements ApplicationRunner { @Autowired RedisMsgPubSubListener redisMsgPubSubListener; @Autowired JedisPool jedisPool; @Override public void run(ApplicationArguments applicationArguments) throws Exception { Jedis jedis = jedisPool.getResource();// jedis.set(&quot;zhcj:mobile:13548074395:2018122222212&quot;,&quot;1&quot;);// jedis.expire(&quot;zhcj:mobile:13548074395:2018122222212&quot;,10); jedis.subscribe(redisMsgPubSubListener, &quot;__keyevent@0__:expired&quot;); }} 最终效果:","link":"/2019/10/24/%E5%9F%BA%E4%BA%8Eredis-key%E5%A4%B1%E6%95%88%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0/"},{"title":"微信小程序上传图片到七牛云","text":"微信小程序上传图片到七牛云,小程序Webview嵌入H5上传图片&amp;原生小程序上传图片 最近在帮朋友做微信小程序，没有选择mpvue，因为时间紧加上不熟悉，怕遇到坑不能快速处理，拖了进度，所以采用了原生小程序+webview的方式做了第一版。 小程序webview上传图片因为涉及到H5，所以图片上传这块就用到了微信中的jssdk， 第一步是wx.config配置前端代码如下: 123456789101112131415161718192021222324252627282930313233343536373839abp.services.app.wxAccess.getOfficialAccountJsdkConfig().done(function (data) { if (data) { var appId = data.appId; var timestamp = data.timestamp; var nonceStr = data.noncestr; var signature = data.signature; wx.config({ debug: false, //调试模式 当为tru时，开启调试模式 appId: appId, timestamp: timestamp.toString(), //签名时间戳 nonceStr: nonceStr, //生成签名的随机串 signature: signature, //签名 jsApiList: [&apos;chooseImage&apos;, &apos;uploadImage&apos;], success: function () { alert(&quot;配置成功&quot;); }, fail: function () { alert(&quot;配置失败&quot;); } }); wx.ready(function () { // 在这里调用 API wx.checkJsApi({ jsApiList: [ &apos;chooseImage&apos;, &apos;uploadImage&apos; ], success: function (res) { //console.log(JSON.stringify(res)); } }); }); wx.error(function(res){ alert(JSON.stringify(res)); }); } }); 后端代码： 1234567891011121314151617181920212223242526272829303132/// &lt;summary&gt;/// 获取公众号JsdkConfig/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public async Task&lt;Dtos.GetOfficialAccountJsdkConfigOutput&gt; GetOfficialAccountJsdkConfig() { var input = new Dtos.GetAccessInput { AppId = _appConfiguration[&quot;WechatOfficialAccount:AppId&quot;], Secret = _appConfiguration[&quot;WechatOfficialAccount:Secret&quot;] }; var noncestr = Guid.NewGuid().ToString(&quot;N&quot;); var jsapi = await GetJsapiTicket(input); //var timestamp = (DateTime.Now.Ticks - new DateTime(1970, 1, 1, 0, 0, 0, 0).Ticks) / 10000000; var timestamp = new Helper.UnixTime().DateTimeToUnix(DateTime.Now); //var url = Request.UrlReferrer.OriginalString; var url = _iHttpContextAccessor.HttpContext.Request.Headers[Microsoft.Net.Http.Headers.HeaderNames.Referer].ToString(); var shaStr = $&quot;jsapi_ticket={jsapi.Permit}&amp;noncestr={noncestr}&amp;timestamp={timestamp}&amp;url={url}&quot;; var signature = new Helper.Encrypt().Sha1Encrypt(shaStr); return new Dtos.GetOfficialAccountJsdkConfigOutput { AppId = input.AppId, Noncestr = noncestr, Timestamp = timestamp, Signature = signature }; } 第二步就是调用jssdk前端js代码如下： 123456789101112131415161718192021222324252627282930313233wx.chooseImage({ count: 9, needResult: 1, sizeType: [&apos;original&apos;, &apos;compressed&apos;], // 可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], // 可以指定来源是相册还是相机，默认二者都有 success: function (data) { //localIds = data.localIds[0]; // 返回选定照片的本地ID列表，localId可以作为img标签的src属性显示图片 for (var localId = 0; localId &lt;= data.localIds.length - 1; localId++) { if (isIOS) { wx.getLocalImgData({ localId: data.localIds[localId], // 图片的localID success: function (res) { // var localData = res.localData; // localData是图片的base64数据，可以用img标签显示 //console.log(localData); } }); } else { } } }, fail: function (res) { alert(JSON.stringify(res)); //alterShowMessage(&quot;操作提示&quot;, JSON.stringify(res), &quot;1&quot;, &quot;确定&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;); } }); jssdk中，如果是iOS的话，前端无法直接使用localIds资源id做展示，需要调用wx.getLocalImgData方法来获取图片的base64编码 提交前端选择的图片到服务端并由服务的上传到七牛云前端部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546wx.uploadImage({ //获取图片媒体ID localId: localIds[erp.common.idx].toString(), // 需要上传的图片的本地ID isShowProgressTips: 1, // 默认为1，显示进度提示 success: function (res) { //获取成功 // 上传序号，上传一张 累计 +1 erp.common.idx++; //存储图片媒体ID，用，号分割 // serverIds += res.serverId + &apos;,&apos;; erp.common.serverIdsArr.push(res.serverId); if (erp.common.idx &lt; localIds.length) { //本地图片ID 还没全部获取完图片媒体ID //调用上传递归函数 erp.common.wxUploadImg(localIds, callback); } else { //上传序号归零 erp.common.idx = 0; //服务器csrf 验证字符串，如果后端框架没开启csrf，则不需要 //alert(erp.common.serverIdsArr); abp.services.app.wxAccess.uploadMediaToQiniu({ WxMediaIds: mediaIds }).done(function (data) { var imageUrl = []; for (var index = 0; index &lt;= data.qiniuFiles.length - 1; index++) { imageUrl.push(data.qiniuFiles[index].qiniuUrl); } $.hideLoading(); callback &amp;&amp; callback(imageUrl); }).always(function(){ $.hideLoading(); }); //serverIds = &apos;&apos;; erp.common.serverIdsArr.length = 0; return true; } }, fail: function (res) { //获取多媒体id失败 返回错误代码 alert(&quot;上传失败，msg：&quot; + JSON.stringify(res)); } }); 后端部分代码: 1234567891011121314151617181920212223242526272829303132333435/// &lt;summary&gt;/// 上传文件到七牛/// &lt;/summary&gt;/// &lt;param name=&quot;input&quot;&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;//[RemoteService(false)]public async Task&lt;Dtos.UploadMediaToQiniuOutput&gt; UploadMediaToQiniu(Dtos.UploadMediaToQiniuInput input){ var output = new Dtos.UploadMediaToQiniuOutput(); if (input.WxMediaIds.Count &gt; 0) { output.QiniuFiles = new System.Collections.Generic.List&lt;Dtos.QiniuFile&gt;(); var access_token = await GetOfficialAccountAccessToken(); var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var prefixPath = _appConfiguration[&quot;Qny:prefixPath&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); foreach (var mediaId in input.WxMediaIds) { var url = $&quot;https://api.weixin.qq.com/cgi-bin/media/get?access_token={access_token.Permit}&amp;media_id={mediaId}&quot;; var fileKey = qiniuStorage.UploadStream(url); var fileUrl = $&quot;{prefixPath}/{fileKey}&quot;; output.QiniuFiles.Add(new Dtos.QiniuFile { QiniuUrl = fileUrl, WxMediaId = mediaId }); } } return output;} 原生小程序上传图片到七牛云后面考虑到一些交互上面的问题，就把原来的webview方式改成了全原生的模式。采用原生的方式，在图片上传上面就好处理多了，只需要实现获取到七牛云用于上传的token，然后使用wx.uploadFile即可上传。服务端获取token代码： 12345678910111213/// &lt;summary&gt;/// 获取七牛token/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public QiniuTokenOutputDto GetQiniuUpToken(){ var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); var output = new QiniuTokenOutputDto() { UpToken = qiniuStorage.CreateUploadToken() }; return output;} 小程序端部分代码: 12345678910111213141516171819202122232425262728293031323334353637383940411、获取token2、调用小程序API，选择图片。 wx.chooseImage({ count: 9-this.data.cardImgList.length, //默认9 sizeType: [&apos;original&apos;, &apos;compressed&apos;], //可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], //从相册选择 success: (res) =&gt; { res.tempFilePaths.forEach((item,index)=&gt;{ that.upload2Qiniu(item); }); } }); } /*** 图片上传七牛云*/ upload2Qiniu(tempFilePaths) { let token = this.data.token; var that = this; wx.uploadFile({ url: &apos;https://up-z0.qiniup.com&apos;, name: &apos;file&apos;, filePath: tempFilePaths, header: { &quot;Content-Type&quot;: &quot;multipart/form-data&quot; }, formData: { token: that.data.upToken, }, success: function (res) { let data = JSON.parse(res.data) //data.hash图片的资源名，可直接通过域名加资源名访问 // to do ... }, fail: function (res) { console.log(res) } }); } 如果需要更详细的资料，那么就请自行百度or谷歌吧","link":"/2019/10/24/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E5%88%B0%E4%B8%83%E7%89%9B%E4%BA%91/"},{"title":"使用Lombok简化java代码","text":"Lombok是一款提高javaer开发效率的插件工具，特别是在繁多是bean类中的getter、setter，使用Lombok可以使用注解的方式省去了添加getter、setter的时间 在使用Lombok之前，需要在IDE上安装插件，eclipse安装步骤稍微多一点，具体请自行百度或者去官方查看https://projectlombok.org/features/configuration，IntelliJ安装就相对来说比较方便，直接在插件中心搜索Lombok,安装Lombok Plugin即可。接下来，我们在程序中引入jar包： 1234567&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 我们平时的POJO类一般都是这样写: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { } public String getUserName() { return this.userName; } public void setUserName(String userName) { this.userName = userName; } public String getOperator() { return this.operator; } public void setOperator(String operator) { this.operator = operator; } public String getSource() { return this.source; } public void setSource(String source) { this.source = source; } public String getDisplayName() { return this.displayName; } public void setDisplayName(String displayName) { this.displayName = displayName; } public String getFilePath() { return this.filePath; } public void setFilePath(String filePath) { this.filePath = filePath; } public String getCreator() { return this.creator; } public void setCreator(String creator) { this.creator = creator; } public Timestamp getStartTime() { return this.startTime; } public void setStartTime(Timestamp startTime) { this.startTime = startTime; } public Timestamp getCreateTime() { return this.createTime; } public void setCreateTime(Timestamp createTime) { this.createTime = createTime; } public long getFileSize() { return this.fileSize; } public void setFileSize(long fileSize) { this.fileSize = fileSize; }} 如果属性更多的话，添加getter、setter就需要花更多的时间。如果使用Lombok插件的话，不仅可以节省时间，而且代码也更加简洁: 1234567891011121314151617181920public class DataFileDownloadAudit { @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private Timestamp startTime; @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { }} 这样只是给属性加getter、setter，我们也可以用@Data来继续简化: 123456789101112@Datapublic class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime;} 这两种方式有什么差异呢？@Getter和@Setter是作用在bean属性上，可以自动生成getter、setter方法，@Data是作用在类上，他结合了@ToString, @EqualsAndHashCode, @Getter,@Setter,@RequiredArgsConstructor注解的功能。这仅仅说了Lombok两个常用的注解，总的来说，它会给我们带来更加简洁的代码和快速的开发效率，其他更加强大的功能可以去https://projectlombok.org/features/all自行查看。","link":"/2019/11/06/%E4%BD%BF%E7%94%A8Lombok%E7%AE%80%E5%8C%96java%E4%BB%A3%E7%A0%81/"},{"title":".net core 3.x Web API使用Swagger添加多版本以及JWT Authorization","text":"很多时候，要给我们的接口升级，但是又怕影响之前的接口业务或者是要开发特定的接口，我们会给接口加上一个版本号，保障老接口依然能稳定运行，例如百度的坐标转换服务 1http://api.map.baidu.com/geoconv/v1/?coords=114.21892734521,29.575429778924&amp;from=1&amp;to=5&amp;ak=你的密钥 //GET请求 在.net core中，想给接口加上版本号，有多种方式: 1、通过URL Path Segment来实现; 2、通过HTTP Headers来实现; 3、通过QueryString来实现;具体的实现可以去百度或者bing。这里暂时只讲swagger doc实现多版本切换。我个人喜欢使用第一种方式。 ApiExplorer组件的使用在实现多版本Web API，我们需要借助一个组件: 1Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer 成功添加依赖包后，就可以在程序中使用相应的API了，首先我们先创建如下的目录结构(大家可随意):接下来，就将我们之前的Controller类上添加相应的特性: 1234//当前Controller的版本号[ApiVersion(&quot;1.0&quot;)]//接口访问路径[Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] 然后在Startup的ConfigureServices中使用ApiExplorer 12services.AddApiVersioning();services.AddVersionedApiExplorer(options =&gt; options.GroupNameFormat = &quot;&apos;v&apos;VVV&quot;); Swagger中多版本API文档下面，我就用Swagger来自动生成多版本文档，为了使我的Startup类相对简洁，我们新建一个ConfigureSwaggerOptions类来放置Swagger的相关配置,完整代码如下： 1234567891011121314151617181920212223242526272829public class ConfigureSwaggerOptions : IConfigureOptions&lt;SwaggerGenOptions&gt; { readonly IApiVersionDescriptionProvider provider; public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) =&gt; this.provider = provider; public void Configure(SwaggerGenOptions options) { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerDoc(description.GroupName, new OpenApiInfo { Description = $&quot;Demo API {description.ApiVersion} Description&quot;, Version = description.ApiVersion.ToString(), Title = $&quot;Demo API 文档{description.ApiVersion}&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; }, License = new OpenApiLicense { Name = &quot;Apache 2.0&quot;, Url = new Uri(&quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;) } }); } var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); options.IncludeXmlComments(docXmlPath); } } 修改Startup类ConfigureServices中: 12services.AddTransient&lt;IConfigureOptions&lt;SwaggerGenOptions&gt;, ConfigureSwaggerOptions&gt;();services.AddSwaggerGen(); Configure中 1234567891011121314151617181920212223242526272829public void Configure(IApplicationBuilder app, IWebHostEnvironment env, IApiVersionDescriptionProvider provider) { if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(options =&gt; { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerEndpoint( $&quot;/swagger/{description.GroupName}/swagger.json&quot;, description.GroupName.ToUpperInvariant()); } }); app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); } 最终效果如下：可以点击Select a definition切换我们不同版本的doc 在Swagger中添加Header Authorization 一般情况下，我们的Web API是使用Jwt来保障接口安全，当然还有很多其他的方式，我只是选择一种相对简单一些的方式。这里只是说怎么在Swagger调试的时候带上我们的Jwt Token，具体的Jwt实现，也请自己实现。 其实Swashbuckle已经给我们提供了很方便的API，只需要配置一下即可: 123456789101112131415161718options.AddSecurityDefinition(&quot;bearer&quot;, new OpenApiSecurityScheme { Type = SecuritySchemeType.Http, In = ParameterLocation.Header, Name = &quot;Authorization&quot;, Scheme = &quot;bearer&quot;, BearerFormat = &quot;JWT&quot;, Description = &quot;JWT Authorization header using the Bearer scheme.&quot;, }); var req = new OpenApiSecurityRequirement(); req.Add(new OpenApiSecurityScheme { Reference = new OpenApiReference { Type = ReferenceType.SecurityScheme, Id = &quot;bearer&quot; } }, new[] { &quot;&quot; }); options.AddSecurityRequirement(req); 效果如下:我们会看到有一个Authorization的按钮，我们点击可以输入我们获取到的Jwt Token,在文本框内不需要输入Bearer关键字，Swagger会自动为我们加上Bearer关键字。在这里也需要注意到Swagger的坑，因为大写的问题可能会导致Authorization无法添加到request请求头中.下面是Swagger的build-request.js 123456789101112131415161718else if (type === &apos;http&apos;) { if (schema.scheme === &apos;basic&apos;) { let scheme = schema.scheme; if (scheme) { scheme = scheme.toLowerCase() } if (scheme === &apos;basic&apos;) { const {username, password} = value const encoded = btoa(`${username}:${password}`) result.headers.Authorization = `Basic ${encoded}` } if (schema.scheme === &apos;bearer&apos;) { if (scheme === &apos;bearer&apos;) { result.headers.Authorization = `Bearer ${value}` } } 大家可以自己去看看代码，我继续说Authorization的设置，点击按钮就会出现设置token的文本框:设置完后，我们的小锁会变为关闭状态:最后就可以通过Swagger UI调用我们的接口，就可以在我们的请求中看到Authorization的参数内容，后端就可以接受处理.当然，Swagger还有其他的自定义UI功能，大家可以去官网查询相关文档。","link":"/2019/11/18/swagger-add-apiversion/"},{"title":"高德地图和google地图整合","text":"整合百度和google地图 因为高德地图的卫星地图不全，但是在高德地图没有的地方，google地图却有，所以客户有一个需求，就是当高德地图显示”无卫星地图”的时候，就显示google地图的图片。 求助万能的百度当然，因为对地图api不是很熟悉，所以就只有百度和看高德官方文档，但是都没有找到合适的解决方案，有看到叠加地图图层并自定义图片路径，这显然不适合我目前的场景，另外一个就是通过API来叠加地图，结合api判断大概的x-y-z的数值范围来加载不同的切片路径. 1234567891011google = new AMap.TileLayer({ map: map, zIndex: 70, //图块取图地址 getTileUrl: function (x, y, z) { //console.log(arguments); if (x &gt;= 12931 &amp;&amp; y &gt;= 3364 &amp;&amp; z &gt;= 16) return &quot;http://mt0.google.cn/vt/lyrs=s&amp;hl=zh-CN&amp;gl=cn&amp;x=&quot; + x + &quot;&amp;y=&quot; + y + &quot;&amp;z=&quot; + z + &quot;&amp;s=Galile&quot;; } }); 当然，这种方式解决起来并不优雅，而且客户也反馈过，很多地方google有卫星地图但是现在依然没有，因为如果要加载得更细，就要判断更多的xyz，所以处理起来也不方便。 突发奇想之后，突然想到，为何不在服务端来判断当前切片是否是正常的卫星地图切片，如果不是则去请求google地图的切片，采用这种方式的话，那么就需要修改jsapi，但是高德并不提供离线的js api，怎么办呢？ 当然办法是肯定有的，就是自己去下载一个高德js api，然后把卫星地图模式所指向的地址改为自己的服务端地址即可，项目中就引用自己下载的离线js。js api修改代码： 123456在离线js中查询关键字:autonavi.com/appmaptile?style=6可以找到这样的地址:http://webst0{1,2,3,4}.is.autonavi.com/appmaptile?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z]将其修改为自己的代理地址:http://211.137.xxx.xxx/map/?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z] 其他调用方式不变，使用这种方式之后，融合率几乎是99.99%，如果高德和google结合后还是有无卫星地图的情况，那我暂时也没想到比较好的处理方式了。最终效果如下:","link":"/2019/10/24/%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BE%E5%92%8Cgoogle%E5%9C%B0%E5%9B%BE%E6%95%B4%E5%90%88/"},{"title":"没有java源代码如何修改bug","text":"有时候遇到比较老的产品，公司的产品组也不提供维护了，更可恨的是，源代码也不给。在这种情况，遇到有bug，怎么办呢？ 我们项目组一直在维护着一个2013年基于公司老产品开发的项目，既然是产品，公司产品弄死不肯定提供老产品的代码，原因大概是因为代码管理混乱，已经找不到我们项目的代码了。 这个bug出现在数据授权的时候，按常规组织授权后，下级用户居然能看到上级用户数据，我们的数据授权原理是：获取授权用户所在层级，并获取当前的授权组织表，将组织表数据和当前用户进行匹配，并记录在授权表，然后，用户在查询数据的时候就读取授权表拼接in语句去数据库查询。当出现这个问题的时候，显然是不允许的，这时候，我们的检查步骤是：1、检查用户组织表2、检查授权表3、检查最终执行sql语句通过以上步骤，最终发现是在做sql拼接成in的条件的时候出现的问题，这时候，就只有进入到代码里面一探究竟，由于没有源代码，就只有借用各种反编译工具：1、Java Decompiler2、Jadclipse3、jad4、jd-gui…..等等，还有很多其他的，这里，我选用的是jd-gui，如果是用的idea作为IDE的话，可以直接查看。借助反编译工具反编译出来的代码如下： 12345678910111213141516171819202122static boolean userIsDept(JdbcTemplate sysJdbcTemplate, final String dept, String userId) { String sql = SQLProvider.getSQL(&quot;query.all.sub.dept&quot;); List&lt;String&gt; depts = (List)sysJdbcTemplate.query(sql, new PreparedStatementSetter() { public void setValues(PreparedStatement ps) throws SQLException { ps.setString(1, dept); ps.setString(2, dept); } }, new ResultSetExtractor&lt;List&lt;String&gt;&gt;() { public List&lt;String&gt; extractData(ResultSet rs) throws SQLException, DataAccessException { ArrayList trs = new ArrayList(); while(rs.next()) { trs.add(rs.getString(&quot;DEPT_ID&quot;)); } return trs; } }); String userDeptSql = SQLProvider.getSQL(&quot;query.user.dept&quot;); String userDeptId = (String)sysJdbcTemplate.queryForObject(userDeptSql, String.class, new Object[]{userId}); return depts.contains(userDeptId); } 经过分析，发现该处的组织id过多加载，因为在授权表中已经将当前用户所属组织的授权内容全量写进去，这儿过多加载，其实把父组织的授权内容也一并拼接到了in条件内，所以出现这种情况。最后，我通过idea新建一个java项目，把项目的依赖包添加进去，新建了一个同包名、同类名的类，将代码copy进新类，稍作修改，就可导出一个jar包。然后将class文件复制到原来的jar包中覆盖即可，在这里，一定要注意JDK版本，否者会报错。","link":"/2019/11/05/%E6%B2%A1%E6%9C%89java%E6%BA%90%E4%BB%A3%E7%A0%81%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9bug/"},{"title":"shell脚本学习","text":"Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但读者朋友要知道，shell 和 shell script 是两个不同的概念。由于习惯的原因，简洁起见，本文出现的 “shell编程” 都是指 shell 脚本编程，不是指开发 shell 自身。 以上内容来源于runoob 上半年花了一个多月时间修改一个开源的BI项目(Redash),改完后,由于没有使用也就暂时告一段落，就在昨天，一个客户说想找一个开源的BI系统，我们就给他推荐这个工具，因为它简单、方便、快捷，而且也比较受欢迎。但是客户对Docker不熟悉，就给他大致的讲了一个怎么在 Windows搭建一个测试环境。后来，突然想看看Redash的Dockerfile文件，看到里面的执行文件： 12ENTRYPOINT [&quot;/app/bin/docker-entrypoint&quot;]CMD [&quot;server&quot;] docker-entrypoint是一个shell脚本，但是因为自己对shell的使用还未入门，所以就着这个机会，去简单了解一下。我们先看一下docker-entrypoint中的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#!/bin/bashset -ecelery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS}scheduler() { echo &quot;Starting RQ scheduler...&quot; exec /app/manage.py rq scheduler}dev_scheduler() { echo &quot;Starting dev RQ scheduler...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq scheduler}worker() { echo &quot;Starting RQ worker...&quot; exec /app/manage.py rq worker $QUEUES}dev_worker() { echo &quot;Starting dev RQ worker...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq worker $QUEUES}dev_celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair}server() { # Recycle gunicorn workers every n-th request. See http://docs.gunicorn.org/en/stable/settings.html#max-requests for more details. MAX_REQUESTS=${MAX_REQUESTS:-1000} MAX_REQUESTS_JITTER=${MAX_REQUESTS_JITTER:-100} exec /usr/local/bin/gunicorn -b 0.0.0.0:5000 --name redash -w${REDASH_WEB_WORKERS:-4} redash.wsgi:app --max-requests $MAX_REQUESTS --max-requests-jitter $MAX_REQUESTS_JITTER}create_db() { exec /app/manage.py database create_tables}celery_healthcheck() { exec /usr/local/bin/celery inspect ping --app=redash.worker -d celery@$HOSTNAME}rq_healthcheck() { exec /app/manage.py rq healthcheck}help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}tests() { export REDASH_DATABASE_URL=&quot;postgresql://postgres@postgres/tests&quot; if [ $# -eq 0 ]; then TEST_ARGS=tests/ else TEST_ARGS=$@ fi exec pytest $TEST_ARGS}case &quot;$1&quot; in worker) shift worker ;; server) shift server ;; scheduler) shift scheduler ;; dev_scheduler) shift dev_scheduler ;; celery_worker) shift celery_worker ;; dev_celery_worker) shift dev_celery_worker ;; dev_worker) shift dev_worker ;; rq_healthcheck) shift rq_healthcheck ;; celery_healthcheck) shift celery_healthcheck ;; dev_server) export FLASK_DEBUG=1 exec /app/manage.py runserver --debugger --reload -h 0.0.0.0 ;; debug) export FLASK_DEBUG=1 export REMOTE_DEBUG=1 exec /app/manage.py runserver --debugger --no-reload -h 0.0.0.0 ;; shell) exec /app/manage.py shell ;; create_db) create_db ;; manage) shift exec /app/manage.py $* ;; tests) shift tests $@ ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac #!/bin/bash的作用我们可以再很多sh脚本里面看到#!/bin/bash这段代码，那么它有什么作用呢?shell是一种脚本命令语言，它有多种解析器，例如：/bin/csh、/bin/perl、/bin/bash、bin/sh等等，那么在在第一行加上#!/bin/bash，就是告诉系统这个脚本需要bin/bash解释器来执行。 set -e的作用set -e的作用是：当命令的返回值为非零状态时，则立即退出脚本的执行，防止导致一个致命的错误，而这些错误本应该在之前就被处理掉。set -e 命令用法总结如下： 当命令的返回值为非零状态时，则立即退出脚本的执行。 作用范围只限于脚本执行的当前进行，不作用于其创建的子进程（https://blog.csdn.net/fc34235/article/details/76598448 ）。 另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。shell 中的 set -e 和 set +e的区别 shell 函数shell函数的定义格式如下： 12345[ function ] funname [()]{ action; [return int;]} 函数定义可以带function funname() 定义，也可以直接funname() 定义,不带任何参数。函数返回值可加return也可以不加，不加则以最后一条命令运行结果作为返回值。 12345678celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS} shell变量12# 如果WORKERS_COUNT未定义或者为空字符串，则返回默认值，否则返回WORKERS_COUNT的值WORKERS_COUNT=${WORKERS_COUNT:-2} 注意，变量名和等号之间不能有空格,而且还需要遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 使用一个定义过的变量，只要在变量名前面加美元符号即可。例如: 1$WORKERS_COUNT或者${WORKERS_COUNT} shell 参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n,n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： 123456789101112131415161718#!/bin/bash# author:菜鸟教程# url:www.runoob.comecho &quot;Shell 传递参数实例！&quot;;echo &quot;执行的文件名：$0&quot;;echo &quot;第一个参数为：$1&quot;;echo &quot;第二个参数为：$2&quot;;echo &quot;第三个参数为：$3&quot;;为脚本设置可执行权限，并执行脚本，输出结果如下所示：$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：./test.sh第一个参数为：1第二个参数为：2第三个参数为：3 123456789$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数。如&quot;$*&quot;用「&quot;」括起来的情况、以&quot;$1 $2 … $n&quot;的形式输出所有参数。$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如&quot;$@&quot;用「&quot;」括起来的情况、以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 这里直接copy runoob的内容 shell case 用法12345678910111213case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac shift命令：在shell中，经常可能会遇到多参数传递，例如$1,$2,…$9，借助shift命令可以访问更多传递的参数case语句： 以case开头，esac结尾； 取值后面必须为单词in 匹配一个值与一个模式以”)”(右括号)结束 双分号 “;;” 表示命令序列结束； 默认模式使用”*)”表示，在不满足前面的模式后，执行默认模式后的命令示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; echo &quot;$WORKERS_COUNT&quot; }help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac 效果如下:123[root@VM_175_142_centos ~]# ./shell_echo.sh workerStarting 2 workers for queues: queries,scheduled_queries...2 结束这里只是借助redash的sh脚本来简单了解了一下shell的一些常用命令及语法，当然，shell的强大之处肯定不止于此，后面再遇到的时候，再来学习。大家也可以去runoob系统的学习一下","link":"/2019/11/14/shell-command/"}],"tags":[{"name":"Docker命令","slug":"Docker命令","link":"/tags/Docker%E5%91%BD%E4%BB%A4/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":".net core","slug":"net-core","link":"/tags/net-core/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"redash","slug":"redash","link":"/tags/redash/"}],"categories":[{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Nginx","slug":"Nginx","link":"/categories/Nginx/"},{"name":".net core","slug":"net-core","link":"/categories/net-core/"},{"name":"shell","slug":"shell","link":"/categories/shell/"}]}
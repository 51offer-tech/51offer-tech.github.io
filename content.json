{"pages":[{"title":"关于我","text":"我是一个大龄低学历程序猿，虽然不是非常热爱代码，但是还是喜欢折腾，如果有兴趣交流，可以加我QQ:188781475","link":"/about/index.html"},{"title":"文章分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"Docker常用命令整理","text":"Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的镜像中，然后发布到任何流行的 Linux或Windows 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口。 Docker基础命令docker images 查看当前下载镜像列表 12345[root@VM_175_142_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEhwdsl2/ipsec-vpn-server latest 62e5a169190a 7 months ago 206MBpostgres latest 30bf4f039abe 8 months ago 312MBredis latest 0f88f9be5839 8 months ago 95MB docker search {镜像名} (镜像仓库中的镜像)docker pull {镜像名}:{版本号} (拉取指定版本镜像,如果不指定版本， 将默认使用 latest 镜像)docker run -t -i {镜像名} (启动镜像,如果主机不存在，会自动下载镜像) 123456789101112131415161718192021222324252627282930313233343536373839404142-d, --detach=false， 设置容器上前台运行还是后台运行，默认为false后台运行-i, --interactive=false， 打开STDIN，用于控制台交互-t, --tty=false， 分配tty设备，可以支持终端登录，默认为false-u, --user=&quot;&quot;， 设置容器的用户-a, --attach=[] 登录容器（必须是以docker run -d启动的容器） -w, --workdir=&quot;&quot; 指定容器的工作目录 -c, --cpu-shares=0 设置容器CPU权重，在CPU共享场景使用 -e, --env=[] 指定环境变量，容器中可以使用该环境变量 -m, --memory=&quot;&quot; 指定容器的内存上限 -P, --publish-all=false， 指定容器暴露的端口-p, --publish=[]， 指定容器暴露的端口-h, --hostname=&quot;&quot;， 指定容器的主机名-v, --volume=[]， 给容器挂载存储卷，挂载到容器的某个目录--volumes-from=[]， 给容器挂载其他容器上的卷，挂载到容器的某个目录--cap-add=[]， 添加权限，权限清单详见：http://linux.die.net/man/7/capabilities--cap-drop=[]， 删除权限，权限清单详见：http://linux.die.net/man/7/capabilities--cidfile=&quot;&quot;， 运行容器后，在指定文件中写入容器PID值，一种典型的监控系统用法--cpuset=&quot;&quot;， 设置容器可以使用哪些CPU，此参数可以用来容器独占CPU--device=[]， 添加主机设备给容器，相当于设备直通--dns=[]， 指定容器的dns服务器--dns-search=[]， 指定容器的dns搜索域名，写入到容器的/etc/resolv.conf文件--entrypoint=&quot;&quot;， 覆盖image的入口点--env-file=[]， 指定环境变量文件，文件格式为每行一个环境变量--expose=[]， 指定容器暴露的端口，即修改镜像的暴露端口--link=[]， 指定容器间的关联，使用其他容器的IP、env等信息--lxc-conf=[]， 指定容器的配置文件，只有在指定--exec-driver=lxc时使用--name=&quot;&quot;， 指定容器名字，后续可以通过名字进行容器管理，links特性需要使用名字--net=&quot;bridge&quot; 容器网络设置: bridge 使用docker daemon指定的网桥 host //容器使用主机的网络 container:NAME_or_ID &gt;//使用其他容器的网路，共享IP和PORT等网络资源 none 容器使用自己的网络（类似--net=bridge),但是不进行配置--privileged=false 指定容器是否为特权容器，特权容器拥有所有的capabilities --restart=&quot;no&quot; 指定容器停止后的重启策略: no：容器退出时不重启 on-failure：容器故障退出（返回值非零）时重启 always：容器退出时总是重启 --rm=false 指定容器停止后自动删除容器(不支持以docker run -d启动的容器) --sig-proxy=true 设置由代理接受并处理信号，但是SIGCHLD、SIGSTOP和SIGKILL不能被代理 docker run -d --name=nginx nginx:latest -p 宿主机端口:容器端口 -v 宿主机目录:容器目录 docker ps #查看正在运行的容器docker ps -l #查看最后退出的容器的IDdocker ps -a #查看所有的容器，包括退出的。docker logs {容器ID|容器名称} #查询某个容器的所有操作记录。docker logs -f {容器ID|容器名称} #实时查看容易的操作记录。 1234docker rm$(docker ps -a -q) #删除所有容器docker rm {容器ID|容器名} #删除单个容器docker rmi {镜像ID} #删除单个镜像docker rmi$(docker images | grep none | awk &apos;{print $3}&apos; | sort -r) #删除所有镜像 docker stop {容器ID|容器名} #停止某个容器docker start {容器ID|容器名} #启动某个容器docker kill {容器ID|容器名} #杀掉某个容器 docker export {容器ID|容器名} -o /root/文件名.tar(或者docker export {容器ID|容器名} &gt; /root/文件名.tar) #导出docker import {容器文件} {镜像名}:{tag} #导入后生成的是镜像不是容器，docker load也可以导入，其中两者人区别如下： 12docker load 保留了容器的完整记录docker import 仅保存容器当时的快照状态，在导入的时候自己定义标签、名称等元数据 docker container inspect {容器ID|容器名} #返回容器的ID、创建时间、路径、状态、镜像等信息 docker container stats {容器ID|容器名} #查看容器的CPU、内存、存储、网络等资源的使用情况可以使用 docker cp {宿主机目录} {容器ID}:{容器目录} #将宿主机内的指定目录文件传输至容器内部的指定目录 docker cp {容器ID}:{容器目录} {宿主机目录} #将容器内部的指定目录文件复制到宿主机指定目录 docker commit {容器ID} {镜像名}:{tag} #将容器重新打包成镜像 1234567-a :提交的镜像作者；-c :使用Dockerfile指令来创建镜像；-m :提交时的说明文字；-p :在commit时，将容器暂停。 docker push {镜像名|镜像ID} #推送在镜像仓库 Dockerfile文件参数 FROM #指定基础镜像，必须为第一个命令 MAINTAINER #作者信息 RUN #构建镜像时执行的命令 ADD #复制文件到容器中 COPY #复制文本到容器中COPY &lt;源路径&gt;… &lt;目标路径&gt; 1ADD和COPY的差别：ADD命令tar类型文件会自动解压(网络压缩资源不会被解压)，可以访问网络资源，COPY不会自动解压文件，也不能访问网络资源 CMD #容器启动时执行的命令。shell 格式： CMD &lt;命令&gt; exec 格式： CMD [“可执行文件”, “参数1”, “参数2”…] ENTRYPOINT #配置容器 LABEL #为镜像添加元数据 ENV #设置环境变量 EXPOSE #指定外界交互的容器端口EXPOSE &lt;端口1&gt; [&lt;端口2&gt;…] VOLUME #指定持久化目录VOLUME [“&lt;路径1&gt;”, “&lt;路径2&gt;”…] WORKDIR #工作目录，自动cd到执行目录 示例： 123456789101112 # FROM代表此次构建的镜像的基础镜像基础,可在镜像名后带版本号，不带版本号默认latestFROM python# COPY是拷贝宿主机文件到镜像中COPY ./spider /work# RUN则是在镜像中执行命令，有时候可能需要安装依赖环境，也可以在run中执行RUN ls /work# 切换工作目录，相当于cd workWORKDIR /work#EXPOSE 外界交互的端口EXPOSE 8080# CMD是镜像启动后默认执行，CMD加中括号等同于exec执行命令，不加中括号等同于 sh -c 执行命令CMD [&quot;python&quot;,&quot;spider.py&quot;] docker build ocnfig #用于检查dockerfile文件是否有误 docker build . -t spider:v1.0 #构建镜像，构建好之后可以使用docker images命令进行查询 Docker-compose.yml文件配置build：定义镜像生成，可以指定Dockerfile构建，在up 启动之时执行构建任务 image：指定镜像启动容器，如果镜像不存在会自动拉去最新镜像 environment：环境变量和配置 ports：端口映射，将容器端口映射在宿主机 depends_on：指定依赖关系。适用于需要按顺序启动的服务，会先启动所依赖的镜像 volumes：挂载宿主机目录或者数据容器卷 volumes_from: 从容器挂载 context：指定Dockerfile文件或者是远程网络文件 args：构建参数，这些参数只能在构建过程中访问 container_name：指定容器名称 links: 链接其他容器 command: 启动执行命令 示例： 123456789101112131415161718192021version: &quot;3&quot;services: pgsql: image: postgres ports: - &quot;15432:5432&quot; environment: POSTGRES_PASSWORD: scyd! volumes: - ./data/postgresql_data1:/var/lib/postgresql/data restart: always redis: image: redis command: redis-server --requirepass scyd! ports: - &quot;16379:6379&quot; volumes: - ./data/redis_data1:/data restart: always 执行docker-compose ps： 12345[root@VM_175_142_centos ~]# docker-compose ps Name Command State Ports -------------------------------------------------------------------------------root_pgsql_1 docker-entrypoint.sh postgres Up 0.0.0.0:15432-&gt;5432/tcproot_redis_1 docker-entrypoint.sh redis ... Up 0.0.0.0:16379-&gt;6379/tcp 容器名：{目录名}{服务名}{容器序号} 从1开始 docker-compose up -d #构建并启动容器,首次运行会执行docker-compose build 1234-d：后台进程--scale：指定服务运行的容器个数（如果服务有对外的端口就不能指定多个容器，因为端口已经被占用） Eg：docker-compose up -d --scale web=1 --scale redis=2 docker-compose exec {服务名称} bash #登录到某个容器中 docker-compose down #删除所有容器,镜像 docker-compose ps #显示所有容器 docker-compose restart {服务名称} #重新启动容器 docker-compose build {服务名称} #构建镜像 。 docker-compose build –no-cache {服务名称} #不带缓存的构建。 docker-compose logs {服务名称} #查看容器的日志 docker-compose logs -f {服务名称} #查看容器的实时日志 docker-compose rm {服务名称} #删除compose服务 docker-compose kill {服务名称} #kill compose服务 docker-compose stop {服务名称} #重启compose服务 docker-compose start {服务名称} #启动容器 docker-compose config -q #验证yml文件配置，当配置正确时，不输出任何内容，当文件配置错误，输出错误信息 docker-compose run {服务名} {cmd} #在某个服务上运行shell命令","link":"/2019/11/08/Docker-compose-ymal/"},{"title":"AccessibilityService自动刷视频","text":"使用AccessibilityService实现自动刷视频，赚点小钱 最近很多人在推精简版的快手、抖音等app来赚钱，邀请人之后，可得佣金，每天刷视频也可以的金币换RMB，所以一些闲来无事的人就整体拿着手机刷刷刷，那么有没有什么自动的方式，让我们解放双手呢？Android自动化测试的框架比较多，大家可以自行百度。下面就介绍几种常用的： 模拟MotionEvent这个功能只能给自己本身的app发送Event，无法跨App。 Instrumentation现在有很多基于Instrumentation的自动化测试框架，但是也无法跨App操作，如果想要跨App的话，就只有获得root权限或者系统签名。这两种方式都有些麻烦。 ADB命令需要在PC端执行adb命令，那么就需要USB连接到电脑上，在PC端发送input的shell脚本命令，如果再手机端执行input tap等命令，也需要root权限。操作还是很麻烦 AccessibilityService服务现在很多复制工具都是基于AccessibilityService开发的，通过给予一定的权限，监听手机端的动作，然后查找相应节点，向指定节点发送相应的指令。为了节约时间，我在百度找到一篇文章AccessibilityService实现文本的自动全选黏贴、点击、滑动。利用dispatchGesture+AccessibilityService来实现自动刷新视频，我将其稍作修改，就可以对刷抖音、快手、趣多多等app进行跨应用刷视频，这样一来省了不少时间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647private void slideVertical(int startSlideRatio, int stopSlideRatio) { sliderCount++; int screenHeight = ScreenUtils.getScreenHeight(getApplicationContext()); int screenWidth = ScreenUtils.getScreenWidth(getApplicationContext()); L.e(&quot;屏幕：&quot; + (screenHeight - (screenHeight / 10)) + &quot;/&quot; + (screenHeight - (screenHeight - (screenHeight / 10))) + &quot;/&quot; + screenWidth / 2); Path path = new Path(); int start = (screenHeight / 20) * startSlideRatio; int stop = (screenHeight / 20) * stopSlideRatio; L.e(&quot;屏幕：&quot; + start + &quot;/&quot; + stop + &quot;/&quot; + screenWidth / 2); path.moveTo(screenWidth / 2, start);//如果只是设置moveTo就是点击 path.lineTo(screenWidth / 2, stop);//如果设置这句就是滑动 StringBuffer sb = new StringBuffer(); sb.append(&quot;滑动次数&quot; + sliderCount + &quot;次\\n&quot;); sb.append(&quot;滑动时间&quot; + Utils.formatUTC(System.currentTimeMillis(),null) + &quot;\\n&quot;); sb.append(&quot;开始位置&quot; + start + &quot;\\n&quot;); sb.append(&quot;结束位置&quot; + stop + &quot;\\n&quot;); Intent mIntent = new Intent(MainActivity.RECEIVER_ACTION); mIntent.putExtra(&quot;result&quot;, sb.toString()); //发送广播 sendBroadcast(mIntent); GestureDescription.Builder builder = new GestureDescription.Builder(); GestureDescription gestureDescription = builder .addStroke(new GestureDescription. StrokeDescription(path, 200, 200)) .build(); dispatchGesture(gestureDescription, new GestureResultCallback() { @Override public void onCompleted(GestureDescription gestureDescription) { super.onCompleted(gestureDescription); L.w(&quot;滑动结束&quot; + gestureDescription.getStrokeCount()); } @Override public void onCancelled(GestureDescription gestureDescription) { super.onCancelled(gestureDescription); L.w(&quot;滑动取消&quot;); } }, null); } 效果图:","link":"/2019/10/24/AccessibilityService%E8%87%AA%E5%8A%A8%E5%88%B7%E8%A7%86%E9%A2%91/"},{"title":"Golang基础学习总结之开篇","text":"Go, also known as Golang, is a statically typed, compiled programming language designed at Google by Robert Griesemer, Rob Pike, and Ken Thompson. Go is syntactically similar to C, but with memory safety, garbage collection, structural typing, and CSP-style concurrency 几个月前，兴趣使然，我偶然学了一个月的go语言，并开发了两个简单的小程序(短域名服务和微信记事本小程序)，感受到了golang的简洁和强大。可是我并没有做一个学习总结，所以接下来，我将简单是分几篇文章来简单的总结一下golang的基础内容。这里我们先简单列举几个Golang的优点： 1、语法简洁 2、强大的标准库 3、性能好 4、开发效率高 5、天生支持并发 6、编译效率高 …… Hello World一般学习一门新语言，都是从Hello world开始的，下面，我就来感受一下Golang的简洁，在这里我推荐大家使用Goland这款IDE,当然如果vs code用得很6的话也可以。 12345678package main //包名import &quot;fmt&quot; 导入fmt包//main主函数func main() { fmt.Println(&quot;Hello World&quot;) //打印输出Hello World} Go语言以包(package)作为管理单位，每个Go 源文件都必须先声明它所属的包，Go语言的包与文件夹是一一对应的，默认情况下同级目录下的文件属于同一个包，包名也可以与目录名不同。main包是Go语言程序的入口包，一个Go语言程序必须有且仅有一个 main 包。如果一个程序没有 main 包，那么编译时将会出错，无法生成可执行文件。main函数是main包里面的启动函数，如果没有main函数启动也是会报错。go预览编译也很简单，直接到项目目录执行go build 即可在同级目录生成一个exe的可执行文件。","link":"/2019/11/21/Golang%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93/"},{"title":"AngularJS v1.x使用总结","text":"最近在改一个前后端分离的项目,前端用的Angular 1.4.5,后端用的java,由于AngularJs在4年前简单的使用过一次，大多都忘记了，这次拿到这个项目(前端被压缩过),第一眼就瞬间懵逼了,但是领导已经下了死命令了，也只得硬着头皮干，索性就把这次遇到的一些知识点记录一下。 控制器&amp;作用域ng-controller 指令指定使用的控制器，ng-app 指令初始化一个 AngularJS 应用程序,$scope作用域作为当前controller范围内的数据传输纽带，在controller中的$scope上添加相应的对象或者属性，在html即可使用 12345678910&lt;div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []); //定义一个模块app.controller(&apos;myCtrl&apos;, function($scope) { });&lt;/script&gt; 表达式 ,AngularJS 表达式可包含文字、运算符、变量、对象，将表达式中的内容绑定到HTML中 12345678910111213div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;&lt;h1&gt;{{carname}}&lt;/h1&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []);app.controller(&apos;myCtrl&apos;, function($scope) { $scope.carname = &quot;Volvo&quot;;});&lt;/script&gt; ng-model 指令数据双向绑定,在界面或者js中改变绑定变量的值，另一边也会随之影响 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=&quot;utf-8&quot;&gt;&lt;script src=&quot;https://cdn.staticfile.org/angular.js/1.4.6/angular.min.js&quot;&gt;&lt;/script&gt; &lt;/head&gt;&lt;body&gt;&lt;div ng-app=&quot;myApp&quot; ng-controller=&quot;myCtrl&quot;&gt;名字: &lt;input ng-model=&quot;name&quot;&gt;&lt;h1&gt;你输入了: {{name}}&lt;/h1&gt;&lt;/div&gt;&lt;script&gt;var app = angular.module(&apos;myApp&apos;, []);app.controller(&apos;myCtrl&apos;, function($scope) { $scope.name = &quot;John Doe&quot;;});&lt;/script&gt;&lt;p&gt;修改输入框的值，标题的名字也会相应修改。&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 自定义指令Angular可以使用directive 来自定义指令 12345678910111213angular.module(&quot;app&quot;).directive(&quot;pivottableViewPanel&quot;, function() { return { restrict: &quot;AE&quot;, scope: { authType: &quot;@&quot;, authId: &quot;=&quot;, appChange(): &quot;&amp;&quot; }, templateUrl: &quot;js/modules/apps/pivottable/tpls/pivottableViewPanel.html&quot;, link: function($scope, $element, $attr) {} } }) restrict 值可以是以下几种: E 作为元素名使用 A 作为属性使用 C 作为类名使用 M 作为注释使用templateUrl：指定组件引用的html，可以是html代码也可以是html路径；scope：定义组件属性:@:单项绑定的前缀标识符,例如:;=:双向数据绑定前缀标识符,例如:;&lt;:单项绑定的前缀标识符，和=使用类似,例如:,但是不会影响父组件对象的值;&amp;:绑定函数方法的前缀标识符，例如：我们定义好的组件有一下几种方式可以调用: 元素名:&lt;pivottable-view-panel&gt;&lt;/pivottable-view-panel&gt;; 属性：&lt;div pivottable-view-panel&gt;&lt;/div&gt;; 类名：&lt;div class=&quot;pivottable-view-panel&quot;&gt;&lt;/div&gt;; 注解：&lt;!--directive: pivottable-view-panel--&gt;;这里需要注意的是，组件用驼峰命名法，Angular会自动将大写字母转为小写且在字母前以-隔开,在定义的scope中，如果对象属性只有值，默认组件属性是属性名转换后的名称,如果属性有值则使用属性值转换后的属性123456789101112scope: { authType: &quot;@&quot;, authId: &quot;=&quot;, appChange(): &quot;&amp;&quot; } 用的时候则是&lt;xxx auth-id&gt;&lt;/xxx&gt;scope: { authType: &quot;@&quot;, authId: &quot;=curAuthId&quot;, appChange(): &quot;&amp;&quot; } 用的时候则是&lt;xxx cur-auth-id&gt;&lt;/xxx&gt; 自定义服务Service是一个函数或对象，AngularJs自带了30多个服务，例如$http(向服务器请求数据)、$timeout(setTimeout),也可以自定义 123angular.module(&quot;demo&quot;).service(&quot;dataSetService&quot;,function(){}); 使用的话需要在控制器中注入这个Service 123angular.module(&quot;demo&quot;).controller(&apos;myCtrl&apos;, function($scope, dataSetService) { //使用dataSetService}); 依赖注入Angular提供了依赖注入功能，在使用的时候，加入事先定义好的service/factory/provider即可在自动注入 [\"$q\", \"$timeout\", \"DataAjaxService\"123function ($q, $timeout, dataAjaxService) { //此处即可使用$q}]); 未完待续","link":"/2019/11/23/AngularJS-v1-4-5/"},{"title":"ES6常用关键字总结","text":"ES6(ECMAScript 6.0)是JavaScript 语言的新一代标准，2015年6月正式发布。其提供了一些新特性使代码更加简洁。由于目前有些版本浏览兼容性不足，所以需要实用babel这类工具讲我们的ES6转换为ES5. let、const在ES6之前，是使用var来定义变量， 1var demo=&apos;demo&apos;; ES6之前，只有全局作用域和函数作用域，没有块级作用域,这种情况下会出现变量提升的现象导致变量被覆盖之类的问题，在ES6中，使用let就不存在这种问题，它只会在定义之后且在该块级作用域内可使用 1let demo=&apos;demo&apos;; const声明一个只读的常量，在声明时必须赋初始值，并且赋值后不可改变 1const API_URL=&quot;http://xxx.xxx.xxx&quot;; 模板字符串在ES6之前，需要拼接字符串，一般是通过”+”或者数组join的方式 123var a1=&apos;a1&apos;;var a2=a1+&apos;aa&apos;;var strs=[&apos;a1&apos;,&apos;a2&apos;].join(); 现在我们可以通过模版字符串来拼接 12let a1=&apos;a1&apos;;let a2=`aa${a1}`; 变量解构赋值E6之前只能一个个变量赋值 123let a = 1;let b = 2;let c = 3; ES6以后可以使用数组批量按照对应位置赋值 12let [a, b, c] = [1, 2, 3]; //a=1,b=2,c=3;let [a1,b1,c1]=[1,2]; //a1=1,a2=2,a3=undefined 也可以解析对象，解析对象的时候变量名必须和属性名一致，否则会解构失败， 1let { a, b } = { a: &apos;aaa&apos;, b: &apos;bbb&apos; }; //a=&apos;aaa&apos;,b=&apos;bbb&apos; 解构赋值对提取 JSON 对象中的数据 123456789let jsonData = { id: 42, status: &quot;OK&quot;, data: [867, 5309]};let { id, status, data: number } = jsonData;console.log(id, status, number); 箭头函数ES6 允许使用”箭头”（=&gt;）定义函数。函数体内的this对象，就是定义时所在的对象，而不是使用时所在的对象 123456var f = v =&gt; v;// 等同于var f = function (v) { return v;}; 如果箭头函数不需要参数或需要多个参数，就使用一个圆括号代表参数部分。 123456789var f = () =&gt; 5;// 等同于var f = function () { return 5 };var sum = (num1, num2) =&gt; num1 + num2;// 等同于var sum = function(num1, num2) { return num1 + num2;}; …操作符…用于获取函数的多余参数，这样就不需要使用arguments对象了。rest 参数搭配的变量是一个数组，该变量将多余的参数放入数组中。 1234567891011function add(...values) { let sum = 0; for (var val of values) { sum += val; } return sum;}add(2, 5, 3) // 10 注意，rest 参数之后不能再有其他参数（即只能是最后一个参数），否则会报错。 Class类ES6中提供了class关键字来定义类 12345678910111213141516171819class Point { constructor(x, y) { this.x = x; this.y = y; } toString() { return &apos;(&apos; + this.x + &apos;, &apos; + this.y + &apos;)&apos;; }}//等价于function Point(x, y) { this.x = x; this.y = y;}Point.prototype.toString = function () { return &apos;(&apos; + this.x + &apos;, &apos; + this.y + &apos;)&apos;;}; constructor方法是类的默认方法，通过new命令生成对象实例时，自动调用该方法。一个类必须有constructor方法，如果没有显式定义，一个空的constructor方法会被默认添加。 1234567class Point {}// 等同于class Point { constructor() {}} 这里只记录了几个常用的 新特性关键字，系统完整的学习可以去阮一峰大神的博客学习","link":"/2019/11/22/ES6-7-8-9-10/"},{"title":"Go在Windows下编译linux可执行二进制文件","text":"完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？ 完成Golang应用开发之后，接下来肯定就是编译成可执行文件，如果开发环境是Windows的话，我们想要编译成可执行文件会非常方便,执行go build即可。但是我们想要编译成Linux环境下可执行的文件呢？我们需要修改几个参数： 1234SET CGO_ENABLED=0SET GOARCH=amd64SET GOOS=linuxgo build main.go 一次执行以上命令，就可以在项目目录生成一个二进制文件，所修改的变量值仅对当前窗口有效，可以如果我们每次都需要输入这些命令的话，着实还是有些繁琐，那么，我们可以新建一个bat文件，将命令复制到bat文件中，以后每次就只需要执行这个bat文件即可。如果又想编译成Windows文件，要么就是关闭窗口重新打开，要么就是修改变量值： 1234SET CGO_ENABLED=1SET GOARCH=SET GOOS=windowsgo build main.go","link":"/2019/11/03/Go%E5%9C%A8Windows%E4%B8%8B%E7%BC%96%E8%AF%91linux%E5%8F%AF%E6%89%A7%E8%A1%8C%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/"},{"title":"Linux中inode引起的故障","text":"inode是什么？ ETL脚本调度故障今日一大早，用户群就炸了，很多人说脚本调度无法运行，一直是未开始状态，起初，我并未引起重视，猜想可能是pieline服务阻塞引起的，由于情况紧急，就直接进入到tomcat manager进行reload操作，但是奇怪的是，reload之后，大批量的作业都直接终止掉，查看日志，发现是ETL脚本日志创建失败， 遂想到，肯定是文件系统占满，就开始rm一部分，然后，df -h，发现还有160+G，以为问题就解决掉了，但是没过多久，依然有很多未开始的作业。 df -i 解围因为对linux使用不是很熟，也只会ps -ef、cd、kill等常用命令，在百度中得知一个命令df -i，执行命令后，发现使用率100%，原来，真正的原因是：etl工具每天产生的小文件过多，把inode占满，导致工具无法创建日志文件。既然找到原因，当然就只有找到目录，将历史文件给rm掉 df的用法df命令一般用于查看磁盘空间大小，du -sh 查看当前目录使用大小。df -h 大文件占用大量的磁盘容量。df -i 过多的文件占用了大量的inode号。 [参考]linux命令df中df -h和df -i的区别","link":"/2019/10/24/Linux%E4%B8%ADinode%E5%BC%95%E8%B5%B7%E7%9A%84%E6%95%85%E9%9A%9C/"},{"title":"Nginx HTTP/TCP代理配置","text":"众所周知，nginx是一款高性能的反向代理工具，在之前nginx只能代理应用层的应用，如果是要做TCP即网络第4层的代理就只有借助HaProxy等工具，在nginx1.9版本之后即可支持TCP的代理。下面，我们来展现一下nginx强大的代理能力。 我们的网络有内网和办公网还有互联网，首先所有项目部署在内网，使用只能在生产网(需要开通特殊策略)，特殊情况下，可以申请互联网的网络，但是比较麻烦，而且，我们进入生产服务器必须在内网的环境下通过堡垒机才能登陆，现在多个生产部署多个系统，但是映射到办公网只有个IP且只有一个端口。此时，我们就需要用到反向代理实现系统的访问。 Nginx基本配置说明 nginx有强大的url匹配功能，下面，我们一起来了解一下nginx的优先级匹配。以下是匹配语法模版 1234location [=|~|~*|^~] /uri/ { root html; index index.html index.htm;} 说明： 1234567= 表示精确匹配^~ 表示uri以某个常规字符串开头~ 表示区分大小写的正则匹配~* 表示不区分大小写的正则匹配 !~ 表示区分大小写不匹配的正则!~* 表示不区分大小写不匹配的正则/ 通用匹配，相当于根目录可以匹配到任何请求 优先级: 精确匹配&gt;普通匹配&gt;正则匹配 nginx对http进行反向代理： 123location / { proxy_pass http://127.0.0.1; } Nginx Http反向代理实践配置下面是我们为解决上面的问题所做的配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445 //HTTP代理 location / { proxy_pass http://xx.xx.xxx.xxx:8081/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /Insight { proxy_pass http://xx.xxx.x.xxx:8083/BingoInsight; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; } location ^~ /etl{ proxy_pass http://xx.xxx.x.xxx:8080/etl; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #proxy_set_header Host $host:$server_port; #这里是重点,这样配置才不会丢失端口} //websocket 代理 location /gateone/{ proxy_pass http://xx.xx.xx.xx:58080/gateone/; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $http_host; proxy_connect_timeout 1690; proxy_read_timeout 1690; proxy_send_timeout 1690; client_max_body_size 300m; proxy_http_version 1.1; proxy_redirect off; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;;} ...... Nginx 代理转发TCP配置 我又有另外一个场景，也是内网和办公网的交互，但是这个场景不需要那么严格，可以直连服务器，但是我们是想在办公网直连数据库。这显然形成了一个屏障 这种情况下，我们想要连接到数据库就只有做一个TCP四层代理。我们就可以借助nginx upstream的功能实现TCP转发。配置如下 123456789upstream proxy_redis{ server xx.xxx.xx.xxx:6379;} server { listen 6379; #监听端口 proxy_pass proxy_redis; #转发请求} 然后刷新一下nginx配置: 1nginx -s reload 此时连接代理服务器响应的端口，就可以将TCP请求转发到实际服务器。 官方文档nginx下载地址","link":"/2019/11/08/Nginx-agent-configuration/"},{"title":"Spring Boot集成Swagger","text":"大部分人应该都知道Swagger是帮我们的Web API快速生成接口文档，前面我们也有提到.Net Core3.x集成Swagger，这里，我们再来归纳一下Spring Boot集成Swagger的常规操作 创建一个Spring Boot项目创建Spring Boot应用的方式有很多，如：直接访问spring提供的项目生成工具https://start.spring.io/、或者Idea里面的Spring Initializr模块创建等等。这里我们就直接通过Idea工具来创建，创建完成后，就是maven自动安装包了。 集成Swagger首先，我们需要引入引入jar包: 123456789101112&lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger2 --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/io.springfox/springfox-swagger-ui --&gt; &lt;dependency&gt; &lt;groupId&gt;io.springfox&lt;/groupId&gt; &lt;artifactId&gt;springfox-swagger-ui&lt;/artifactId&gt; &lt;version&gt;2.9.2&lt;/version&gt; &lt;/dependency&gt; 配置Swagger 新建一个SwaggerConfiguration类，添加注解@Configuration、@EnableSwagger21234567891011121314151617181920212223@Configuration@EnableSwagger2public class SwaggerConfiguration { @Bean public Docket createRestApi() { return new Docket(DocumentationType.SWAGGER_2) .apiInfo( new ApiInfoBuilder() //页面标题 .title(&quot;Demo Web Api文档&quot;) //创建人 .contact(new Contact(&quot;eyiadmin&quot;, &quot;https://springfox.github.io/springfox/&quot;, &quot;eyiadmin@163.com&quot;)) .version(&quot;1.0&quot;) .description(&quot;Demo Web Api文档&quot;) .build()) .select() //API接口所在的包位置 .apis(RequestHandlerSelectors.basePackage(&quot;com.eyiadmin.demo.controller&quot;)) .paths(PathSelectors.any()) .build(); }} 配置Controller:123456789101112@Api(tags = {&quot;Swagger Demo API展示&quot;})@RequestMapping(&quot;/demo&quot;)@RestControllerpublic class DemoController { @ApiOperation(value = &quot;示例&quot;, notes = &quot;通过名字打个招呼&quot;) @RequestMapping(value = &quot;hello/{name}&quot;, method= RequestMethod.GET) public ResponseEntity&lt;String&gt; Hello(@ApiParam(value = &quot;用户姓名&quot;,required = true) @PathVariable String name) { return new ResponseEntity&lt;&gt;(String.format(&quot;Hello %s!&quot;,name), HttpStatus.OK); }} 启动起来，访问localhost:8080/swagger-ui.html，还是那个熟悉的界面: 使用Swagger增强版knife4j-spring-ui在https://gitee.com/xiaoym/knife4j提供了swagger-bootstrap-ui,界面相对来说更加美观,也可以导出md文档，同时可以借助其他工具转成pdf等文档我们把修改一下pom.xml文件，将swagger替换成knife4j: 12345&lt;dependency&gt; &lt;groupId&gt;com.github.xiaoymin&lt;/groupId&gt; &lt;artifactId&gt;knife4j-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.9.6&lt;/version&gt; &lt;/dependency&gt; 修改配置类: 1234@Configuration@EnableSwagger2@EnableSwaggerBootstrapUi@Import(BeanValidatorPluginsConfiguration.class) 启动Spring Boot，访问localhost:8080/doc.html：至此，Spring Boot集成Swagger暂时告一段落,下面，我会整理一些Swagger 常用注解. @Api一般作用于Controller类,标识类作用说明 1234参数说明:* tags=&quot;说明该类的作用&quot;* value=&quot;可不配置&quot;@Api(tags = {&quot;Swagger Demo API展示&quot;}) @ApiOperation一般作用于方法，标识说明该方法的作用 1234参数说明: * value=&quot;方法描述&quot; * notes=&quot;备注说明&quot;@ApiOperation(value = &quot;方法描述&quot;, notes = &quot;备注说明&quot;) @ApiParam作用于方法，解释方法中的参数说明 1public ResponseEntity&lt;String&gt; Hello(@ApiParam(value = &quot;参数名称&quot;,required = true) @PathVariable String name) @ApiModel作用于VO类,解释说明类 1@ApiModel(&quot;例如说明&quot;) @ApiModelProperty作用于字段属性,为VO类属性解释说明 12@ApiModelProperty(&quot;用户名&quot;) private String userName;","link":"/2019/12/06/Spring-Boot-Swagger/"},{"title":"Nginx二级域名转发到不同端口/服务器","text":"有时候，我们资源有限，那么就会遇到一台主机对应1-N个域名，那么就会出现主机80端口占用完了，其他应用就只能占用其他的端口了，但是如果在域名后面带上端口号(如www.xxxx.com:8080 ),这显然很不优雅,而且像开发微信的时候，配置的域名只能使用80端口。那么有没有更好的处理方式能让我们不在域名后添加端口号呢？答案是肯定是，这里我们可以借助强大的Nginx来帮我们解决这个问题。 Nginx通过二级目录方式我们知道Nginx location强大的匹配模式，那么我们就可以通过location来匹配请求目录从而在内部转发到不同的端口/服务器。当然也可以使用Nginx+Lua(openresty、tengine)来判断请求参数也可以处理.但是现在我暂时还是才用的Nginx自身的一些API来实现. 1234567891011121314151617181920server { listen 443 ssl; server_name localhost; location / { root html; index index.html index.htm; } location /api/ { proxy_pass http://xxx.xxx.xxx.xx:8000/api/; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } 这时候，我们通过www.xxx.com/api 就可以转发到 http://xxx.xxx.xxx.xx:8000/api ,这里还有可以设置更高端的，比如才用Nginx Rewrite等。 Nginx匹配二级域名进行代理多个server模块通过server_name匹配代理server_name 是虚拟服务器的识别路径，不同的域名请求会带上相应的HOST请求头来匹配Nginx的server模块 12345678910111213141516171819202122232425262728293031323334353637383940414243server { listen 80; server_name www.cddj.top; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } } server { listen 80; server_name www.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html1; index index.html index.htm; } } server { listen 80; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html2; index index.html index.htm; } } 我们可以看到访问不同的域名就转到了不同的server模块,这里只是简单是静态显示，我们可以再server模块中做转发,例如: 1234567891011121314151617181920server { listen 80; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { proxy_pass http://localhost:8000/; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } } 多个server同端口的匹配规则是:完全匹配-&gt;通配符在前(如.biz)-&gt;通配符在后(如52fx.)-&gt;正则匹配(~^.52fx.biz$),如果都没匹配到就找默认server，如果还是匹配不到则去匹配端口的第一个server 一个server模块通过IF指令判断转发到不同端口/服务器可以借助Nginx if指令判断$host中的域名来转发到不同的端口: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566server { listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / { if ($host = &quot;www.cddj.top&quot;) { proxy_pass http://localhost:801; } if ($host = &quot;www.51offer.wang&quot;) { proxy_pass http://localhost:802; } if ($host = &quot;sub.51offer.wang&quot;) { proxy_pass http://localhost:803; } } }server { listen 801; server_name www.cddj.top; #charset koi8-r; #access_log logs/host.access.log main; location / { root html; index index.html index.htm; } }server { listen 802; server_name www.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html1; index index.html index.htm; } }server { listen 803; server_name sub.51offer.wang; #charset koi8-r; #access_log logs/host.access.log main; location / { root html2; index index.html index.htm; } } 结果和上面的图片一样，这里就不追加了。 Nginx+Lua我们可以借助Nginx+Lua来判断转发，这里也暂时就不说明，有兴趣的 可以自己去查找资料，在使用Lua的时候需要自行下载Nginx源码加Lua模块编译进去，或者使用openresty、tengine这种已经集成好的工具，个人比较喜欢openresty,因为社区相对比较活跃，有很多强大的插件如waf等。 修改配置后记得刷新配置哟 12nginx -t #验证配置文件nginx -s reload 刷新配置文件 如果有更方便快捷且强大的方式，请加我QQ告知我哟！！！","link":"/2019/11/28/Nginx-domain-configuration/"},{"title":"golang下载妹子图","text":"想用golang下载妹子图吗？点进来看看吧!很方便 闲来无趣，就想着看用golang来做点什么事情，这不，到处都是python下载妹子图,我就想着用golang来弄一个下载妹子图的简单小工具 简单分析页面结构访问https://www.meizitu.com 页面后, 进入到详情页面，可以看到url变为https://www.meizitu.com/a/5511.html ，我们将url中的数字任意修改，发现都能访问，那么，我们暂且就通过手动输入页面索引的方式来访问页面。我们再看看页面结构,通过google浏览器的开发者工具很容易就可以看到： 下载图片刚才我们已经大致的分析了页面结构，接下来 ，我们就开始简单的实现图片下载的功能，在这里我们选用了：colly:用于采集页面和图片uuid:生产UUIDcli:命令行工具包1、我们先初始化一个队列，用于存放需要访问的url 1234var q, _ = queue.New( 2, // Number of consumer threads &amp;queue.InMemoryQueueStorage{MaxSize: 10000}, // Use default queue storage ) 2、初始化需要下载的页面，我用命令行的方式来决定起始页 123456789101112if args := context.Args(); len(args) &gt; 0 { return fmt.Errorf(&quot;invalid command: %q&quot;, args.Get(0)) } start := context.Int(&quot;s&quot;) log.Println(&quot;起始页:&quot;, start) end := context.Int(&quot;e&quot;) log.Println(&quot;截止页:&quot;, end) for i := start; i &lt;= end; i++ { url := fmt.Sprintf(&quot;https://www.meizitu.com/a/%d.html&quot;, i) q.AddURL(url)} 3、初始化一个colly来处理队列中的url,我在OnHTML中，查找页面的postContent&gt;img的dom节点，获取图片的路径，又放在队列中 1234567891011121314151617181920c := colly.NewCollector() c.UserAgent = &quot;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36&quot; c.OnHTML(&quot;.postContent&quot;, func(e *colly.HTMLElement) { //e.Request.Visit(e.Attr(&quot;href&quot;)) e.ForEach(&quot;img&quot;, func(i int, element *colly.HTMLElement) { //e.Request.Visit(element.Attr(&quot;src&quot;)) q.AddURL(element.Attr(&quot;src&quot;)) }) }) c.OnResponse(func(resp *colly.Response) { if strings.Contains(resp.Headers.Get(&quot;Content-Type&quot;), &quot;image/jpeg&quot;) { download(resp.Body) } }) c.OnRequest(func(r *colly.Request) { fmt.Println(&quot;Visiting&quot;, r.URL) }) q.Run(c) 最后的效果：代码很简单，如果需要可以去https://github.com/eyiadmin/meizitu 看看，如果想下载图片，就直接下载exe文件。在命令行输入main -s 1 -e 100即可下载 12345678910111213141516171819202122232425main -s 100 -e 1082019/10/07 14:26:42 起始页: 1002019/10/07 14:26:43 截止页: 108Visiting https://www.meizitu.com/a/100.htmlVisiting https://www.meizitu.com/a/101.htmlVisiting https://www.meizitu.com/a/102.htmlVisiting https://www.meizitu.com/a/103.htmlVisiting https://www.meizitu.com/a/104.htmlVisiting https://www.meizitu.com/a/105.htmlVisiting https://www.meizitu.com/a/106.htmlVisiting https://www.meizitu.com/a/107.htmlVisiting https://www.meizitu.com/a/108.htmlVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/04.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/05.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/06.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/01.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/07.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/08.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/29/09.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/02.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/03.jpgVisiting http://pic.topmeizi.com/wp-content/uploads/2012a/01/30/04.jpg","link":"/2019/10/24/golang%E4%B8%8B%E8%BD%BD%E5%A6%B9%E5%AD%90%E5%9B%BE/"},{"title":"展示一下Github的常规操作","text":"一般情况下，大部分人会自己使用Gitlab搭建一个私有的Git服务器，但是有时候为了避免麻烦，也可以使用诸如：Gitee,Github等免费的Git服务器来托管代码，这里个人使用的是Github 初始化项目Github账号注册很简单，这里就不说了。我们来看看怎么创建项目，登录到Github之后，右上角会有一个加号，从这里来new repository创建一个新repository这里public(公开项目),private(私有项目)都是免费的，根据个人情况选择常见完成后，会有操作提示，可以使用git clone到本地或者直接下载。这里我们还是使用git init来初始化一个项目吧 1234561. 先创建一个存放项目的文件夹，随意创建一个文件，通过cmd命令行cd到该目录开始执行命令2. git init #初始化仓库3. git add * #添加所有文件到暂存区4. git commit -m &quot;仓库初始化&quot; #此次的提交注释说明,并提交到本地仓库5. git remote add origin https://github.com/eyiadmin/demo.git # 与远程仓库建立关联关系6. git push -u origin master # 提交到远程仓库 常用命令 git add 文件名 添加单个文件到暂存区 git add -A 添加当前目录所有文件到暂存区 git add . 添加当前变更文件到暂存区 git commit -m '说明' 提交暂存区文件到本地仓库 git commit 文件名 -m '说明' 单个文件提交到本地仓库 git fetch 拉取代码 git pull 拉取最新内容并合并到当前分支 git pull origin develop 拉取具体的远程分支 git push origin master 提交到具体的远程分支,如果不存在会自动创建本地同名的远程分支 git checkout 分支名称 切换本地分支 git checkout origin/分支名称 切换远程分支 git checkout -b 新分支名称 基于本地分支新建新分支 git branch -d 分支名称 删除分支 git branch -M 旧分支名称 新分支名称 移动或者重命名分支 git checkout --track origin/分支名称 基于远程分支创建本地分支，并跟踪对应来自 ‘origin’ 的远程分支 git merge --no-ff 分支名称 保留合并分支的提交记录 git remote add origin 仓库地址 建立远程连接 git remote set-url origin 仓库地址 修改推送源 git reset --soft HEAD~1 软回滚到上一个版本 简单的代码提交流程 git status 查看仓库的状态 git add . 提交代码到暂存区 git commit -m &quot;提交内容说明&quot; 将暂存区代码提交到本地仓库 git pull 提交之前从远程拉取项目更新,git diff 对比内容，一般使用GUI查看 git push origin 分支名称 提交到指定分区 Git回滚到指定版本 git log 查看记录获取commit_sha1 git reset ---hard commit_sha1 硬回滚,抛弃回滚之后的内容,git reset ---soft commit_sha1 软回滚 未完待续","link":"/2019/12/05/github-routine-operation/"},{"title":"mysql慢查询语句分析总结","text":"我们经常会接触到MySQL，也经常会遇到一些MySQL的性能问题。我们可以借助慢查询日志和explain命令初步分析出SQL语句存在的性能问题 通过SHOW FULL PROCESSLIST查看问题SHOW FULL PROCESSLIST相当于select * from information_schema.processlist可以列出正在运行的连接线程， 说明： id 连接id，可以使用kill+连接id的方式关闭连接(kill 9339) user显示当前用户 host显示连接的客户端IP和端口 db显示进程连接的数据库 command显示当前连接的当前执行的状态，sleep、query、connect time显示当前状态持续的时间(秒) state显示当前连接的sql语句的执行状态，copying to tmp table、sorting result、sending data等 info显示sql语句,如果发现比较耗时的语句可以复制出来使用explain分析。 慢查询日志慢查询日志是MySQL用于记录响应时间超过设置阈值(long_query_time)的SQL语句，默认情况下未开启慢查询日志，需要手动配置。下面我们要记住几个常用的属性: slow_query_log:是否开启慢查询(ON为开启，OFF则为关闭) long_query_time:慢查询阀值，表示SQL语句执行时间超过这个值就会记录,默认为10s slow_query_log_file:慢查询日志存储的文件路径 log_queries_not_using_indexes: 记录没有使用索引查询语句(ON为开启,OFF为关闭) log_output:日志存储方式(FILE表示将日志写入文件,TABLE表示写入数据库中，默认值为FILE,如果存入数据库中，我们可以通过select * from mysql.slow_log的方式去查询，一般性能要求相对较高的建议存文件) 我们可以通过show variables like ‘%关键字%’的方式查询我们设置的属性值我们有两种方式设置我们的属性,一种是set global 属性=值的方式(重启失效)，另一种是配置文件(重启生效)命令方式: 123set global slow_query_log=1;set global long_query_time=1; set global slow_query_log_file=&apos;mysql-slow.log&apos; 配置文件方式: 1234slow_query_log = &apos;ON&apos;slow_query_log_file = D:/Tools/mysql-8.0.16/slow.loglong_query_time = 1log-queries-not-using-indexes pt-qurey-digest分析慢查询语句percona-toolkit包含了很多实用强大的mysql工具包，pt-qurey-digest只是其中一个用于分析慢查询日志是工具。需要去官网下载,使用方法也很简单: 1./pt-query-digest slow2.log &gt;&gt; slow2.txt 即可得出一个分析结果: 12345678910111213141516171819202122232425262728293031323334# Query 9: 0.00 QPS, 0.00x concurrency, ID 0xF914D8CC2938CE6CAA13F8E57DF04B2F at byte 499246# This item is included in the report because it matches --limit.# Scores: V/M = 0.22# Time range: 2019-07-08T03:56:12 to 2019-07-12T00:46:28# Attribute pct total min max avg 95% stddev median# ============ === ======= ======= ======= ======= ======= ======= =======# Count 8 69# Exec time 1 147s 1s 3s 2s 3s 685ms 2s# Lock time 0 140ms 2ms 22ms 2ms 3ms 2ms 2ms# Rows sent 0 0 0 0 0 0 0 0# Rows examine 0 23.96M 225.33k 482.77k 355.65k 462.39k 81.66k 345.04k# Query size 2 17.72k 263 263 263 263 0 263# String:# Databases xxxx# Hosts xx.xxx.xxx.xxx# Users root# Query_time distribution# 1us# 10us# 100us# 1ms# 10ms# 100ms# 1s ################################################################# 10s+# Tables# SHOW TABLE STATUS FROM `xxxx` LIKE &apos;xxxxx_track_exec_channel&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxxxxx_exec_channel`\\G# SHOW TABLE STATUS FROM `xxx` LIKE &apos;xxxxx_TRACK_ASSIGN&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxx_EFFECTIVE_TRACK_ASSIGN`\\G# SHOW TABLE STATUS FROM `xxx` LIKE &apos;xxxx_task_exec&apos;\\G# SHOW CREATE TABLE `xxxx`.`xxxxx_task_exec`\\GUPDATExxxxxx_effective_track_exec_channel a SET EXEC_CHANNEL_CODE=(SELECT GROUP_CONCAT(DISTINCT(channel_id)) FROM xxxxxx_EFFECTIVE_TRACK_ASSIGN WHERE status in (1,2,4) AND id IN (SELECT assgin_id FROM xxxxxx_task_exec WHERE task_id=a.task_id))\\G explain分析SQL语句上面几点大概的介绍到了几种获取慢查询SQL语句的方式，现在，我们就需要借助explain来分析查找SQL语句慢的原因。explain使用也很简单，直接在SELECT|UPDATE等语句前加上EXPLAIN即可 id表的执行顺序，复制的sql语句往往会分为很多步,序号越大越先执行,id相同执行顺序从上往下 select_type数据读取操作的操作类型: SIMPLE(简单SELECT，不使用UNION或子查询等) PRIMARY(子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY) UNION(UNION中的第二个或后面的SELECT语句) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询) UNION RESULT(UNION的结果，union语句中第二个select开始后面所有select) SUBQUERY(子查询中的第一个SELECT，结果不依赖于外部查询) DEPENDENT SUBQUERY(子查询中的第一个SELECT，依赖于外部查询) DERIVED(派生表的SELECT, FROM子句的子查询) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行) table数据来源于那张表，关联等复杂查询时会用临时虚拟表 type检索数据的方式 system:表只有一行记录 const:通过索引查找并且一次性找到 eq_ref:唯一性索引扫描 ref:非唯一行索引扫描 range:按范围查找 index:遍历索引树 all:全表扫描 possible_keys显示可能使用的索引 Key实际使用的索引 key_len索引的长度，一般来说，长度越短越好 ref列与索引的比较，表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值 rows估算查找的结果记录条数 ExtraSQL查询的详细信息 Using where:表示使用where条件过滤 Using temporary:使用了临时表暂存结果 Using filesort:说明mysql对数据使用一个外部索引排序。未按照表内的索引顺序进行读取。 Using index:表示select语句中使用了覆盖索引，直接从索引中取值 Using join buffer:使用了连接缓存 Using index condition:表示查询的列有非索引的列 [参考]MySQL Explain详解","link":"/2019/11/26/mysql-slow-explain/"},{"title":"golang平滑升级服务","text":"不中断服务进行服务升级 最近在学习go语言，想着用gin+gorm来做一个微信小程序，在gin的github中看到了如何优雅的重启或者停止，因为在生产项目中，如果强行kill掉的话会造成正在执行的业务中断、用户访问被拒绝。显然，平滑的重启或升级我们的应用是多么的重要。 .net的发布过程我做了很多年的.net ，但是从来没有想过如何去平滑更新服务端，也是因为业务要求的可用性不高。一般发布新版本都是采用最笨拙的方式，就是发通知(xx时间升级会暂停服务)-&gt;到点停止服务备份、copy新文件-&gt;启动服务。 java的发布过程在用java做项目的时候，当时就用到了nginx中的upstream来负载均衡，当然，这时候要求的可用性较高，所以在发布服务的时候，就不能再采用简单粗暴的停止-启动大法。我们可以配合nginx -s reload来实现后端服务的灰度发布并且让用户无感知。 golang的发布过程Graceful restart or stopgolang中有很多开源的解决方案：endlessgraceoverseer 实践出真知在这里我们来试试grace(star最多，commits最多)，在github上面有详细的demo和测试步骤。v1 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) v2 12345router := gin.Default()router.GET(&quot;/&quot;, func(c *gin.Context) { c.String(http.StatusOK, &quot;Welcome Gin New Server&quot;)})gracehttp.Serve(&amp;http.Server{Addr:&quot;:8080&quot;,Handler:router}) 如果是在windows环境下开发，会提示: 1github.com\\facebookgo\\grace\\gracehttp\\http.go:104:53: undefined: syscall.SIGUSR2 貌似是因为grace不支持windows的原因，我们可以暂时不用搭理他，先编译一个二进制文件， 123SET GOARCH=amd64SET GOOS=linuxgo build main.go 把生成好的文件复制到linux上，先启动起来(我是用的nohup ./grace &amp;来启动的)，这时候我们查看pid是多少 1234ps -ef|grep graceroot 11915 11364 0 13:06 pts/0 00:00:00 ./graceroot 11921 11364 0 13:08 pts/0 00:00:00 grep --color=auto grace 此时访问服务结果：这时候，我们把之前的文件备份，将v2的代码编译好并拷贝上去，执行命令 123456kill -USR2 11915这时候在看看应用进程ps -ef|grep graceroot 11928 1 0 13:11 pts/0 00:00:00 ./graceroot 11935 11364 0 13:12 pts/0 00:00:00 grep --color=auto grace pid已经变为11928,此时访问服务结果：[参考]https://github.com/facebookarchive/gracehttps://github.com/gin-gonic/gin","link":"/2019/10/24/golang%E5%B9%B3%E6%BB%91%E5%8D%87%E7%BA%A7%E6%9C%8D%E5%8A%A1/"},{"title":"Hexo搭建个人博客锦集","text":"我想很多人都想有一个自己的博客网站，现在开源的博客系统也很多，但是像java，python这种开源的博客系统需要宿主机、申请域名、安装环境等稍稍复杂的操作，当然现在也可以基于阿里或者腾讯云提供的Docker容器服务搭建也是非常方便。那么，还有没有成本更低的搭建方式呢？这时候就需要提到Hexo了，什么是Hexo？Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。我可以将生产的静态页面托管到Github、Coding、Gitee等代码托管平台上，从而节约我们的服务器费用。 Hexo环境准备我们首先需要安装一下几个环境: Node.js:安装的时候直接下一步即可(默认已勾选Add to PATH) Git 以上两项安装成功后,即可安装 Hexo: 1npm install -g hexo-cli #全局安装 新建博客打开cmd命令行，进入到要创建博客的目录,执行以下命令: 123hexo init &lt;文件夹名&gt; #会在当前目录创建一个文件夹,并下载hexo模版cd &lt;文件夹名&gt; #进入博客文件夹npm install #安装hexo相应依赖 构建成功后的目录如下:启动起来看看效果: 1hexo serve 我们可以看到hexo会自动生成一篇文章，并会提到4个常用命令: 1234hexo new &quot;My New Post&quot; #创建博客,缩写hexo n &quot;My New Post&quot;hexo server #启动hexo,缩写hexo shexo generate #生成静态页面,缩写hexo ghexo deploy #发布到静态托管服务器,缩写hexo d 一般我们发布都是 hexo g &amp; hexo d 一起执行。 配置博客这时候需要去修改根目录下的 _config.yml 配置文件,我们可以参考一下https://hexo.io/zh-cn/docs/configuration 属性名 作用 title 网站标题 subtitle 网站副标题 description 主要用于SEO，告诉搜索引擎一个关于您站点的简单描述，通常建议在其中包含您网站的关键词 keywords 网站的关键词。使用半角逗号 , 分隔多个关键词。 author 用于主题显示文章的作者 language 网站使用的语言 timezone 网站时区。Hexo 默认使用您电脑的时区。请参考 时区列表 进行设置，如 America/New_York, Japan, 和 UTC 。一般的，对于中国大陆地区可以使用 Asia/Shanghai。 url 网址,如果您的网站存放在子目录中，例如 http://yoursite.com/blog，则请将您的 url 设为 http://yoursite.com/blog 并把 root 设为 /blog/ root 网站根目录 permalink 文章的 永久链接 格式 :year/:month/:day/:title/ permalink_defaults 永久链接中各部分的默认值 pretty_urls 改写 permalink 的值来美化 URL pretty_urls.trailing_index 是否在永久链接中保留尾部的 index.html，设置为 false 时去除,默认:true source_dir 资源文件夹，这个文件夹用来存放内容。默认:source public_dir 公共文件夹，这个文件夹用于存放生成的站点文件。默认:public tag_dir 标签文件夹,默认:tags archive_dir 归档文件夹,默认:archives category_dir 分类文件夹,默认:categories code_dir Include code 文件夹，source_dir 下的子目录,默认:downloads/code i18n_dir 国际化（i18n）文件夹,默认: :lang skip_render 跳过指定文件的渲染。匹配到的文件将会被不做改动地复制到 public 目录中。您可使用 glob 表达式来匹配路径。 new_post_name 新文章的文件名称,默认: :title.md default_layout 预设布局,默认: post auto_spacing 在中文和英文之间加入空格,默认: false titlecase 把标题转换为 title case,默认:false external_link 在新标签中打开链接,默认:true external_link.enable 在新标签中打开链接,默认:true external_link.field 对整个网站（site）生效或仅对文章（post）生效,默认:site external_link.exclude 需要排除的域名。主域名和子域名如 www 需分别配置 [] 其他的可以去网站查看，或者自行百度吧,实在是懒得抄了。 配置博客主题Hexo为我们提供了很多主题模版,这里我推荐我喜欢的两个: hexo-theme-butterfly hexo-theme-icarus 更换主题步骤: 下载主题 将主题解压复制到themes文件夹中 修改_config.yml中的theme:属性，属性值为themes中文件夹名，如：theme: butterfly。 如果使用butterfly主题的话，需要安装hexo-renderer-jade(pug的编译工具，内包括了pug的渲染引擎),npm install hexo-renderer-jade 部署到 GitHub Pages 新建一个 repository。如果你希望你的站点能通过 &lt;你的 GitHub 用户名&gt;.github.io 域名访问，你的 repository 应该直接命名为 &lt;你的 GitHub 用户名&gt;.github.io 修改_config.yml:12345deploy: type: git repository: github: https://github.com/eyiadmin/eyiadmin.github.io.git #这里我们选择HTTPS的方式,当然也可以通过SSH方式(后期更加方便) branch: master 因为是git，所以需要npm install --save hexo-deployer-git来安装插件, 发布到GitHub Pages:1hexo g &amp; hexo d 上传成功后就可以在我们的repository中看到上传的静态页面,这时候就可以通过https://&lt;你的 GitHub 用户名&gt;.github.io来访问，如：https://eyiadmin.github.io/ Markdown常用语法标题12345# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题 一级标题二级标题三级标题四级标题五级标题超链接123[超链接名称](超链接地址 &quot;超链接title(鼠标hover显示内容)&quot;) 例如：[农民工学编程](http://blog.52fx.biz &quot;快来看农民工学编程啦&quot;) 农民工学编程 图片12![图片描述(显示在图片下方,可不填)](图片连接地址 &quot;图片title(鼠标hover显示内容)&quot;)![](http://xxnote.51offer.wang/publish.png &quot;发布效果图&quot;) 代码1`单行内容` 多行用内容``` ``` First Blood 123456789Double Kill Trible Kill Quadra Kill Penta Kill Ace 团灭! 未完待续，不定期更新 https://github.com/gohugoio/hugo(Hugo是由Go语言实现的静态网站生成器)https://github.com/jekyll/jekyll(jekyll是由Ruby语言实现的静态网站生成器)https://github.com/hexojs/hexo(Hexo是由Nodejs语言实现的静态网站生成器) https://blog.csdn.net/mqdxiaoxiao/article/details/93378785https://www.jianshu.com/p/25145964abf3","link":"/2019/12/03/hexo-blog/"},{"title":"借助alibaba Driud SQL Parser组件处理sql语句","text":"Druid是Java语言中最好的数据库连接池。Druid能够提供强大的监控和扩展功能。 先来看看我们要达到的效果:这个项目的目的是让业务用户通过手动拖拽自己想要的字段即可展示、分析、下载数据，之前的流程是先添加数据源-&gt;在系统中导入表-&gt;配置分析模型-选择分析模型展示数据。这里的分析模型其实就是通过拖拽表类配置表与表之间是关联关系。然后拖拽字段后，前端就发送选择的字段表达式和过滤条件表达式到后端，通过配置是分析模型关系，解析出相应数据库的SQL语句发送到数据库执行。现在有一种场景，就是用户能只需要查询单张表，如果这样也需要去配置分析模型，那么就增加了复杂度。所以，需要给用户提供一种直接通过数据源直接选择未建立关联关系的原表来查询、分析、下载数据。由于项目是没有源代码，而且之前的解析那一块都是基于分析模型，内部逻辑比较复杂。所以我选择了一种相对来说要方便一点的方式就是通过Driud来解析生成SQL语句。我们都知道Druid是一个JDBC组件库，包括数据库连接池、SQL Parser等组件,我们一般都是拿来做JDBC连接池和SQL语句监控使用。这里，我只是把这次SQL Parser组件的使用过程记录一下。感兴趣的朋友可以去看看Druid 使用手册 Druid_SQL_AST学习什么是ASTAST是abstract syntax tree的缩写，也就是抽象语法树。和所有的Parser一样，Druid Parser会生成一个抽象语法树。 在Druid SQL Parser中有哪些AST节点类型在Druid中，AST节点类型主要包括SQLObject、SQLExpr、SQLStatement三种抽象类型。 123456789package com.alibaba.druid.sql.ast; interface SQLObject {}interface SQLExpr extends SQLObject {}interface SQLStatement extends SQLObject {} interface SQLTableSource extends SQLObject {}class SQLSelect extends SQLObject {}class SQLSelectQueryBlock extends SQLObject {} 常用的SQLExpr有哪些123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.alibaba.druid.sql.ast.expr; // SQLName是一种的SQLExpr的Expr，包括SQLIdentifierExpr、SQLPropertyExpr等public interface SQLName extends SQLExpr {} // 例如 ID = 3 这里的ID是一个SQLIdentifierExprclass SQLIdentifierExpr implements SQLExpr, SQLName { String name;} // 例如 A.ID = 3 这里的A.ID是一个SQLPropertyExprclass SQLPropertyExpr implements SQLExpr, SQLName { SQLExpr owner; String name;} // 例如 ID = 3 这是一个SQLBinaryOpExpr// left是ID (SQLIdentifierExpr)// right是3 (SQLIntegerExpr)class SQLBinaryOpExpr implements SQLExpr { SQLExpr left; SQLExpr right; SQLBinaryOperator operator;} // 例如 select * from where id = ?，这里的?是一个SQLVariantRefExpr，name是&apos;?&apos;class SQLVariantRefExpr extends SQLExprImpl { String name;} // 例如 ID = 3 这里的3是一个SQLIntegerExprpublic class SQLIntegerExpr extends SQLNumericLiteralExpr implements SQLValuableExpr { Number number; // 所有实现了SQLValuableExpr接口的SQLExpr都可以直接调用这个方法求值 @Override public Object getValue() { return this.number; }} // 例如 NAME = &apos;jobs&apos; 这里的&apos;jobs&apos;是一个SQLCharExprpublic class SQLCharExpr extends SQLTextLiteralExpr implements SQLValuableExpr{ String text;} 常用的SQLStatemment最常用的Statement当然是SELECT/UPDATE/DELETE/INSERT，他们分别是 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192package com.alibaba.druid.sql.ast.statement; class SQLSelectStatement implements SQLStatement { SQLSelect select;}class SQLUpdateStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLUpdateSetItem&gt; items; SQLExpr where;}class SQLDeleteStatement implements SQLStatement { SQLTableSource tableSource; SQLExpr where;}class SQLInsertStatement implements SQLStatement { SQLExprTableSource tableSource; List&lt;SQLExpr&gt; columns; SQLSelect query;}2.3. SQLTableSource常见的SQLTableSource包括SQLExprTableSource、SQLJoinTableSource、SQLSubqueryTableSource、SQLWithSubqueryClause.Entryclass SQLTableSourceImpl extends SQLObjectImpl implements SQLTableSource { String alias;} // 例如 select * from emp where i = 3，这里的from emp是一个SQLExprTableSource// 其中expr是一个name=emp的SQLIdentifierExprclass SQLExprTableSource extends SQLTableSourceImpl { SQLExpr expr;} // 例如 select * from emp e inner join org o on e.org_id = o.id// 其中left &apos;emp e&apos; 是一个SQLExprTableSource，right &apos;org o&apos;也是一个SQLExprTableSource// condition &apos;e.org_id = o.id&apos;是一个SQLBinaryOpExprclass SQLJoinTableSource extends SQLTableSourceImpl { SQLTableSource left; SQLTableSource right; JoinType joinType; // INNER_JOIN/CROSS_JOIN/LEFT_OUTER_JOIN/RIGHT_OUTER_JOIN/... SQLExpr condition;} // 例如 select * from (select * from temp) a，这里第一层from(...)是一个SQLSubqueryTableSourceSQLSubqueryTableSource extends SQLTableSourceImpl { SQLSelect select;} /* 例如WITH RECURSIVE ancestors AS ( SELECT * FROM org UNION SELECT f.* FROM org f, ancestors a WHERE f.id = a.parent_id)SELECT *FROM ancestors; 这里的ancestors AS (...) 是一个SQLWithSubqueryClause.Entry*/class SQLWithSubqueryClause { static class Entry extends SQLTableSourceImpl { SQLSelect subQuery; }}2.4. SQLSelect &amp; SQLSelectQuerySQLSelectStatement包含一个SQLSelect，SQLSelect包含一个SQLSelectQuery，都是组成的关系。SQLSelectQuery有主要的两个派生类，分别是SQLSelectQueryBlock和SQLUnionQuery。class SQLSelect extends SQLObjectImpl { SQLWithSubqueryClause withSubQuery; SQLSelectQuery query;} interface SQLSelectQuery extends SQLObject {} class SQLSelectQueryBlock implements SQLSelectQuery { List&lt;SQLSelectItem&gt; selectList; SQLTableSource from; SQLExprTableSource into; SQLExpr where; SQLSelectGroupByClause groupBy; SQLOrderBy orderBy; SQLLimit limit;} class SQLUnionQuery implements SQLSelectQuery { SQLSelectQuery left; SQLSelectQuery right; SQLUnionOperator operator; // UNION/UNION_ALL/MINUS/INTERSECT} SQLCreateTableStatement建表语句包含了一系列方法，用于方便各种操作 1234567891011121314public class SQLCreateTableStatement extends SQLStatementImpl implements SQLDDLStatement, SQLCreateStatement { SQLExprTableSource tableSource; List&lt;SQLTableElement&gt; tableElementList; Select select; // 忽略大小写的查找SQLCreateTableStatement中的SQLColumnDefinition public SQLColumnDefinition findColumn(String columName) {} // 忽略大小写的查找SQLCreateTableStatement中的column关联的索引 public SQLTableElement findIndex(String columnName) {} // 是否外键依赖另外一个表 public boolean isReferenced(String tableName) {}} 怎样产生AST通过SQLUtils产生List1234import com.alibaba.druid.util.JdbcConstants; String dbType = JdbcConstants.MYSQL;List&lt;SQLStatement&gt; statementList = SQLUtils.parseStatements(sql, dbType); 通过SQLUtils产生SQLExpr12String dbType = JdbcConstants.MYSQL;SQLExpr expr = SQLUtils.toSQLExpr(&quot;id=3&quot;, dbType); 怎样打印AST节点通过SQLUtils工具类打印节点123456789package com.alibaba.druid.sql; public class SQLUtils { // 可以将SQLExpr/SQLStatement打印为String类型 static String toSQLString(SQLObject sqlObj, String dbType); // 可以将一个&amp;lt;SQLStatement&amp;gt;打印为String类型 static String toSQLString(List&lt;SQLStatement&gt; statementList, String dbType);} 在Select语句中添加Group by这个先简单的做一个场景，依然拿本次这个项目来说，在前端发送SUM、COUNT等聚合表达式的SQL时，我们需要在语句后面添加Group by。 123456789101112131415161718192021222324252627282930313233343536373839404142public static String getSql(String sql, int offset, int count) { List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, JdbcConstants.MYSQL); SQLSelectStatement sqlSelectStatement = (SQLSelectStatement) stmtList.get(0); SQLSelectQuery sqlSelectQuery = sqlSelectStatement.getSelect().getQuery(); MySqlSchemaStatVisitor visitor = new MySqlSchemaStatVisitor(); sqlSelectStatement.accept(visitor); if (sqlSelectQuery instanceof SQLSelectQueryBlock) { SQLSelectQueryBlock sqlSelectQueryBlock = (SQLSelectQueryBlock) sqlSelectQuery; List&lt;TableStat.Column&gt; cols = new ArrayList&lt;&gt;(visitor.getColumns()); SQLExpr where = sqlSelectQueryBlock.getWhere(); // 获取字段列表 List&lt;SQLSelectItem&gt; selectItems = sqlSelectQueryBlock.getSelectList(); int idx = 0; boolean hasAggregate = false; SQLSelectGroupByClause sqlSelectGroupByClause = new SQLSelectGroupByClause(); //判断是否有聚合函数 for (int selectIdx = 0; selectIdx &lt;= selectItems.size() - 1; selectIdx++) { if (selectItems.get(selectIdx).getExpr() instanceof SQLAggregateExpr) { hasAggregate = true; break; } } if (hasAggregate) { //添加SQLSelectGroupByClause字段 for (int colIndex = 0; colIndex &lt;= cols.size() - 1; colIndex++) { if (cols.get(colIndex).isSelect()) { sqlSelectGroupByClause.addItem(SQLUtils.toSQLExpr(cols.get(colIndex).toString(), JdbcConstants.MYSQL)); } } } sqlSelectQueryBlock.setGroupBy(sqlSelectGroupByClause); if (count &gt;= 1) { return PagerUtils.limit(sqlSelectStatement.toString(), JdbcConstants.MYSQL, offset, count); } return sqlSelectStatement.toString(); } return &quot;&quot;; } 输入sql语句： 1SELECT SUM(`address`) `address`,SUM(`address1`) `address1` FROM `demo` WHERE 1 = 1 最终结果: 1234SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1 生成分页 12345SELECT SUM(`address`) AS `address`, SUM(`address1`) AS `address1`FROM `demo`WHERE 1 = 1GROUP BY address, address1LIMIT 1, 100 也可以创建一个SQLSelect对象来生成sql语句: 1234567SQLSelect sqlSelect = new SQLSelect();MySqlSelectQueryBlock sqlSelectQueryBlock = new MySqlSelectQueryBlock();sqlSelectQueryBlock.addSelectItem(new SQLSelectItem(new SQLIdentifierExpr(&quot;col1&quot;))); //查询列名sqlSelectQueryBlock.addSelectItem(new SQLSelectItem(new SQLIdentifierExpr(&quot;col2&quot;))); //查询列名sqlSelectQueryBlock.setFrom(new SQLExprTableSource(new SQLIdentifierExpr(&quot;demo&quot;))); //表名sqlSelect.setQuery(sqlSelectQueryBlock);String sql = SQLUtils.toSQLString(sqlSelect); Druid支持多种数据库的sql解析,在JdbcConstants中可以看到 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103public interface JdbcConstants { String JTDS = &quot;jtds&quot;; String MOCK = &quot;mock&quot;; String HSQL = &quot;hsql&quot;; String DB2 = &quot;db2&quot;; String DB2_DRIVER = &quot;com.ibm.db2.jcc.DB2Driver&quot;; String POSTGRESQL = &quot;postgresql&quot;; String POSTGRESQL_DRIVER = &quot;org.postgresql.Driver&quot;; String SYBASE = &quot;sybase&quot;; String SQL_SERVER = &quot;sqlserver&quot;; String SQL_SERVER_DRIVER = &quot;com.microsoft.jdbc.sqlserver.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_SQLJDBC4 = &quot;com.microsoft.sqlserver.jdbc.SQLServerDriver&quot;; String SQL_SERVER_DRIVER_JTDS = &quot;net.sourceforge.jtds.jdbc.Driver&quot;; String ORACLE = &quot;oracle&quot;; String ORACLE_DRIVER = &quot;oracle.jdbc.OracleDriver&quot;; String ORACLE_DRIVER2 = &quot;oracle.jdbc.driver.OracleDriver&quot;; String ALI_ORACLE = &quot;AliOracle&quot;; String ALI_ORACLE_DRIVER = &quot;com.alibaba.jdbc.AlibabaDriver&quot;; String MYSQL = &quot;mysql&quot;; String MYSQL_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String MYSQL_DRIVER_6 = &quot;com.mysql.cj.jdbc.Driver&quot;; String MYSQL_DRIVER_REPLICATE = &quot;com.mysql.jdbc.&quot;; String MARIADB = &quot;mariadb&quot;; String MARIADB_DRIVER = &quot;org.mariadb.jdbc.Driver&quot;; String DERBY = &quot;derby&quot;; String HBASE = &quot;hbase&quot;; String HIVE = &quot;hive&quot;; String HIVE_DRIVER = &quot;org.apache.hive.jdbc.HiveDriver&quot;; String H2 = &quot;h2&quot;; String H2_DRIVER = &quot;org.h2.Driver&quot;; String DM = &quot;dm&quot;; String DM_DRIVER = &quot;dm.jdbc.driver.DmDriver&quot;; String KINGBASE = &quot;kingbase&quot;; String KINGBASE_DRIVER = &quot;com.kingbase.Driver&quot;; String GBASE = &quot;gbase&quot;; String GBASE_DRIVER = &quot;com.gbase.jdbc.Driver&quot;; String XUGU = &quot;xugu&quot;; String XUGU_DRIVER = &quot;com.xugu.cloudjdbc.Driver&quot;; String OCEANBASE = &quot;oceanbase&quot;; String OCEANBASE_DRIVER = &quot;com.mysql.jdbc.Driver&quot;; String INFORMIX = &quot;informix&quot;; /** * 阿里云odps */ String ODPS = &quot;odps&quot;; String ODPS_DRIVER = &quot;com.aliyun.odps.jdbc.OdpsDriver&quot;; String TERADATA = &quot;teradata&quot;; String TERADATA_DRIVER = &quot;com.teradata.jdbc.TeraDriver&quot;; /** * Log4JDBC */ String LOG4JDBC = &quot;log4jdbc&quot;; String LOG4JDBC_DRIVER = &quot;net.sf.log4jdbc.DriverSpy&quot;; String PHOENIX = &quot;phoenix&quot;; String PHOENIX_DRIVER = &quot;org.apache.phoenix.jdbc.PhoenixDriver&quot;; String ENTERPRISEDB = &quot;edb&quot;; String ENTERPRISEDB_DRIVER = &quot;com.edb.Driver&quot;; String KYLIN = &quot;kylin&quot;; String KYLIN_DRIVER = &quot;org.apache.kylin.jdbc.Driver&quot;; String SQLITE = &quot;sqlite&quot;; String SQLITE_DRIVER = &quot;org.sqlite.JDBC&quot;; String ALIYUN_ADS = &quot;aliyun_ads&quot;; String ALIYUN_DRDS = &quot;aliyun_drds&quot;; String PRESTO = &quot;presto&quot;; String PRESTO_DRIVER = &quot;com.facebook.presto.jdbc.PrestoDriver&quot;; String ELASTIC_SEARCH = &quot;elastic_search&quot;; String ELASTIC_SEARCH_DRIVER = &quot;com.alibaba.xdriver.elastic.jdbc.ElasticDriver&quot;; String CLICKHOUSE = &quot;clickhouse&quot;; String CLICKHOUSE_DRIVER = &quot;ru.yandex.clickhouse.ClickHouseDriver&quot;;} github","link":"/2019/11/20/Driud-SqlParse/"},{"title":".net core 3.x使用Swagger","text":".net core3.0问世已经两个多月了，我并没有急着将生产上的项目升级到3.0，因为怕踩坑，这不3.1马上就要出来了，想着core3.x逐渐稳定，所以就开始来琢磨一下，此次就简单是说一下.net core3.0中使丝袜哥(Swagger)生成API文档。 在这里，我使用的开发工具是VS2019,Swashbuckle.AspNetCore 5.0.0-rc4， 安装Swashbuckle.AspNetCore1、首先新建一个Web API项目2、安装swagger,打开程序包管理器控制台执行： 1Install-Package Swashbuckle.AspNetCore -Version 5.0.0-rc4 引用Swagger1、在Startup.cs中引入命名空间 12using Microsoft.OpenApi.Models;using Swashbuckle.AspNetCore.Swagger; 2、在ConfigureServices中添加Swagger 1234services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot; }); }); 3、在Configure中添加Swagger中间件,我们最好放在env.IsDevelopment()中 123456789if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;Demo API&quot;); }); app.UseDeveloperExceptionPage(); } 4、配置完后，运行一下，在浏览器中输入http://localhost:5000/swagger, 看看效果： 为Api添加注释刚才的配置，只是能看到我们的API方法，并且可以发送调试请求，但是没有注释，接下来，我们就给API加上注释1、在想要添加注释的API对应分方法上添加注释,格式如下： 12345678910111213141516/// &lt;summary&gt; /// 获取天气预报信息 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] public IEnumerable&lt;WeatherForecast&gt; Get() { var rng = new Random(); return Enumerable.Range(1, 5).Select(index =&gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)] }) .ToArray(); } 2、在项目属性选项卡中，设置生成中的XML文档输出目录:3、在AddSwaggerGen中添加xml文件路径: 123456services.AddSwaggerGen(swagger =&gt; { swagger.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Description = &quot;Demo API Description&quot;, Version = &quot;v1.0&quot;, Title = &quot;Demo API&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; } }); var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); swagger.IncludeXmlComments(docXmlPath); }); 4、最终效果: 每次启动都会打开默认的IE浏览器，由于个人喜欢Google浏览器，所以，现在修改vs启动的默认浏览器：另外，每次启动，在浏览中打开的是默认的Controller，我们可以设置一下启动参数，让每次启动都是Swagger目录，就不需要我们每次都手动输入Swagger目录：。 这次写的是Swagger最基本的设置,后面我们会继续学习一些常用的高级功能。","link":"/2019/11/12/net-core-3-0-use-swagger-ui/"},{"title":"nginx搭建https服务","text":"nginx搭建https服务,转发到http后端服务 花了差不多5个小时用golang做了一个短域名服务+简单的微信小程序，在发布的时候需要用过https协议的服务，遂出此文 gin发布https因为是第一次用gin发布一个真实的环境，很多东西也不是很熟，所以只能百度，当时找到gin中间件把端口转换为https协议这篇文章，看了一下，很简单，就尝试着cv实现以下。由于的采用了gin在github提到的Graceful restart or stop功能，简单cv没有实现，就想了一个便捷的方式(毕竟菜嘛)–采用nginx代理一层。 采用nginx部署https安装步骤 123456789101112# 安装依赖yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel# 下载nginxwget http://nginx.org/download/nginx-1.17.4.tar.gz# 解压文件tar -zxvf nginx-1.17.4.tar.gz# 进入nginx源码目录cd nginx-1.17.4# 配置https模块./configure --prefix=/root/nginx --with-http_stub_status_module --with-http_ssl_module# 编译并安装make &amp;&amp; make install 如果上面的步骤没有异常，那么久算安装成功了，下面就开始配置https代理。 1、先把申请下来的证书复制到nginx目录下，我是新建了一个cert的文件目录，2、修改nginx.conf123456789101112131415161718192021server { listen 443 ssl; server_name domain; ssl_certificate /root/nginx/cert/1_domain_bundle.crt; #证书公钥 ssl_certificate_key /root/nginx/cert/2_domain.key; #证书私钥 ssl_session_cache shared:SSL:1m; ssl_session_timeout 5m; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers ECDH:AESGCM:HIGH:!RC4:!DH:!MD5:!3DES:!aNULL:!eNULL; ssl_prefer_server_ciphers on; location / { proxy_pass http://0.0.0.0:80; proxy_redirect off; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Cookie $http_cookie; #proxy_cookie_path chunked_transfer_encoding off; } } 3、进入到nginx目录执行sbin/nginx执行二进制文件启动nginx服务，如果修改了conf配置文件，则执行sbin/nginx -s reload 刷新配置。至此，nginx服务便搭建好了。在微信小程序开发设置里面配置好https的域名地址，就可以愉快的玩耍了。","link":"/2019/10/24/nginx%E6%90%AD%E5%BB%BAhttps%E6%9C%8D%E5%8A%A1/"},{"title":".Net Core 3.x 使用Autofac替换默认Ioc容器","text":".net 中的IOC容器也不少，如Autofac、Windsor Castle、Spring.NET、Unity、Ninject等，现在使用Autofac作为IOC容器的较多,据说速度是最快的一个。 那么我们有必要将其应用到我们的项目中，来体验其带给我们的极速快感。 安装Autofac依赖我们需要通过nuget包管理安装两个包: 12AutofacAutofac.Extensions.DependencyInjection 使用Autofac包在Autofac中有多种生命周期: Instance Per Dependency 对于一个服务每次请求都会返回一个唯一的实例. Single Instance 所有的请求都将会返回同一个实例. Instance Per Lifetime Scope 每个生命周期作用域的组件在每个嵌套的生命周期作用域中最多只会有一个单一实例 Instance Per Matching Lifetime Scope 每个匹配生命周期作用域的组件在每个名称匹配的嵌套生命周期作用域中最多只会有一个单一实例. Instance Per Request 每个请求一个实例建立于每个匹配生命周期一个实例之上 Instance Per Owned Owned 隐式关系类型 创建了一个嵌套的生命周期作用域. 使用每次被拥有一个实例注册, 可以把该依赖的作用域绑定到拥有它的实例上. Thread Scope 每个线程就有了它各自的生命周期作用域,在这种多线程场景中, 你必须得注意父级作用域不能在派生出的线程下被释放了 新建一个ITransientDependency空接口123public interface ITransientDependency { } 这里的主要目的是为了标识接口注册不同的声明周期。你们可以根据自己的情况新增不同的标识注入不同的生命周期 新建一个WebModule类继承Autofac的Module1234567891011121314151617public class WebModule : Module { protected override void Load(ContainerBuilder builder) { //获取当前程序集 var dataAccess = Reflection.Assembly.GetExecutingAssembly(); var transientDependencyType = typeof(ITransientDependency); //查找ITransientDependency接口类型程序并注册为每次调用创建一个实例 builder.RegisterAssemblyTypes(dataAccess) .Where(t =&gt; transientDependencyType.IsAssignableFrom(t) &amp;&amp; t != transientDependencyType) .AsImplementedInterfaces().InstancePerLifetimeScope().PropertiesAutowired(); } } 主要是查找程序集，批量注册相应依赖， 配置使用在Program中稍作修改 1234567public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .UseServiceProviderFactory(new AutofacServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); }); 在Startup文件中加入ConfigureContainer方法: 1234public void ConfigureContainer(ContainerBuilder builder) { builder.RegisterModule(new WebModule()); } 至此，我们对Autofac已经配置完成 示例接下来我们新建一个IExampleService示例接口继承ITransientDependency, 1234public interface IExampleService: ITransientDependency { string GetName(string Name); } 新建IExampleService接口实现类: 1234567public class ExampleService : IExampleService { public string GetName(string Name) { return $&quot;My name is {Name}&quot;; } } 新建一个Controller,并注入IExampleService: 123456789101112131415161718192021222324252627namespace Web.Controllers.v1{ [ApiVersion(&quot;1.0&quot;)] [Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] [ApiController] public class ExampleController : ControllerBase { IExampleService _exampleService; public ExampleController(IExampleService exampleService) { _exampleService = exampleService; } /// &lt;summary&gt; /// 查询名字 /// &lt;/summary&gt; /// &lt;param name=&quot;name&quot;&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpGet] [Route(&quot;GetName/{Name}&quot;)] public string GetName(string Name) { return _exampleService.GetName(Name); } }} 参考https://autofaccn.readthedocs.io/zh/latest/https://docs.autofac.org/en/latest/","link":"/2019/12/02/net-core3-x-autofac-ioc/"},{"title":".net core3.x发布到Docker运行","text":"我们开发完之后，需要进行发布部署，一般高端的公司是采用CI/CD方式自动发布，但是我所处的公司都是使用手动发布，之前我都是输入命令的方式: 1dotnet publish -c Release -r win7-x64 -o ./bin/output 执行之后就会在相应目录生成所有dll 随迎时代潮流，我们也该有些骚气的操作了，这次咱们就把.net core3.x才用docker发布，因为我的电脑无法安装docker： 那么就想到要么先publish然后把DLL构建成docker镜像，要么就直接通过源码构建镜像，我就偷偷懒，选择后者。那么首先在vs添加【Docker支持】-&gt;【Linux】就会生成一个Dockerfile: 1234567891011121314151617181920212223242526FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim AS baseWORKDIR /appEXPOSE 80EXPOSE 443FROM mcr.microsoft.com/dotnet/core/sdk:3.0-buster AS build# 相当于cd /srcWORKDIR /src# 将当前本地Web/Web.csproj 复制到/src/Web/目录下COPY [&quot;Web/Web.csproj&quot;, &quot;Web/&quot;]# 还原项目依赖库RUN dotnet restore &quot;Web/Web.csproj&quot;将当前本地目录复制到/srcCOPY . .WORKDIR &quot;/src/Web&quot;RUN dotnet build &quot;Web.csproj&quot; -c Release -o /app/buildFROM build AS publishRUN dotnet publish &quot;Web.csproj&quot; -c Release -o /app/publishFROM base AS finalWORKDIR /app# 从编译阶段的中的publish层镜像拷贝/app/publish目录到/app目录下COPY --from=publish /app/publish .COPY [&quot;Web/Web.xml&quot;, &quot;.&quot;]ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] 如果你是提前编译好的，那么可以将Dockerfile修改一下: 12345678FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim EXPOSE 80EXPOSE 443COPY . /appWORKDIR /appENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] 我们将整个源码复制到Centos服务器上,cd到dockerfile目录执行命令: 1docker build -t core3.x-swagger -f Dockerfile . 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071Sending build context to Docker daemon 40.45kBStep 1/17 : FROM mcr.microsoft.com/dotnet/core/aspnet:3.0-buster-slim AS base ---&gt; 880d85db3775Step 2/17 : WORKDIR /app ---&gt; Using cache ---&gt; 2686a6832749Step 3/17 : EXPOSE 80 ---&gt; Using cache ---&gt; f910a2eacda4Step 4/17 : EXPOSE 443 ---&gt; Using cache ---&gt; a157473c89eeStep 5/17 : FROM mcr.microsoft.com/dotnet/core/sdk:3.0-buster AS build ---&gt; a345b68a725eStep 6/17 : WORKDIR /src ---&gt; Using cache ---&gt; 8b2a2b0743f5Step 7/17 : COPY [&quot;Web/Web.csproj&quot;, &quot;Web/&quot;] ---&gt; 29f558699c69Step 8/17 : RUN dotnet restore &quot;Web/Web.csproj&quot; ---&gt; Running in 31e08f04df6c Restore completed in 1.4 min for /src/Web/Web.csproj.Removing intermediate container 31e08f04df6c ---&gt; ed0f20f4056aStep 9/17 : COPY . . ---&gt; 1999712c7eceStep 10/17 : WORKDIR &quot;/src/Web&quot; ---&gt; Running in 6d81af8f98dcRemoving intermediate container 6d81af8f98dc ---&gt; b31d42182d2aStep 11/17 : RUN dotnet build &quot;Web.csproj&quot; -c Release -o /app/build ---&gt; Running in b2c16188ce9aMicrosoft (R) Build Engine version 16.3.2+e481bbf88 for .NET CoreCopyright (C) Microsoft Corporation. All rights reserved. Restore completed in 29.82 ms for /src/Web/Web.csproj. Web -&gt; /app/build/Web.dllBuild succeeded. 0 Warning(s) 0 Error(s)Time Elapsed 00:00:04.89Removing intermediate container b2c16188ce9a ---&gt; b249fe8e976bStep 12/17 : FROM build AS publish ---&gt; b249fe8e976bStep 13/17 : RUN dotnet publish &quot;Web.csproj&quot; -c Release -o /app/publish ---&gt; Running in 43766cf2eb2dMicrosoft (R) Build Engine version 16.3.2+e481bbf88 for .NET CoreCopyright (C) Microsoft Corporation. All rights reserved. Restore completed in 35.91 ms for /src/Web/Web.csproj. Web -&gt; /src/Web/bin/Release/netcoreapp3.0/Web.dll Web -&gt; /app/publish/Removing intermediate container 43766cf2eb2d ---&gt; e07c5fc08616Step 14/17 : FROM base AS final ---&gt; a157473c89eeStep 15/17 : WORKDIR /app ---&gt; Running in 3ab7aca5e289Removing intermediate container 3ab7aca5e289 ---&gt; 0b7196de9a3fStep 16/17 : COPY --from=publish /app/publish . ---&gt; 6178981834aeStep 17/17 : ENTRYPOINT [&quot;dotnet&quot;, &quot;Web.dll&quot;] ---&gt; Running in 488f804c2854Removing intermediate container 488f804c2854 ---&gt; 5aa2ed7e047fSuccessfully built 5aa2ed7e047fSuccessfully tagged core3.x-swagger:latest 生成之后便可以查询到我们的镜像文件: 123[root@VM_175_142_centos ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcore3.x-swagger latest 5aa2ed7e047f 2 minutes ago 237MB 我们可以运行我们的image镜像文件了： 12# 将容器80端口映射到宿主机的9999端口docker run --name swagger -d -p 9999:80 core3.x-swagger 但是当我访问的时候并没有给我惊喜，而是令人头皮发麻的服务端500错误,那么我们就去看看容器的日志吧: 1docker logs 083d0c79c078 错误日志如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980info: Microsoft.Hosting.Lifetime[0] Now listening on: http://[::]:80info: Microsoft.Hosting.Lifetime[0] Application started. Press Ctrl+C to shut down.info: Microsoft.Hosting.Lifetime[0] Hosting environment: Productioninfo: Microsoft.Hosting.Lifetime[0] Content root path: /appfail: Microsoft.AspNetCore.Server.Kestrel[13] Connection id &quot;0HLRJSUAI4BAT&quot;, Request id &quot;0HLRJSUAI4BAT:00000001&quot;: An unhandled exception was thrown by the application.System.IO.FileNotFoundException: Could not find file &apos;/app/Web.xml&apos;.File name: &apos;/app/Web.xml&apos; at Interop.ThrowExceptionForIoErrno(ErrorInfo errorInfo, String path, Boolean isDirectory, Func`2 errorRewriter) at Microsoft.Win32.SafeHandles.SafeFileHandle.Open(String path, OpenFlags flags, Int32 mode) at System.IO.FileStream.OpenHandle(FileMode mode, FileShare share, FileOptions options) at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options) at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize) at System.Xml.XmlDownloadManager.GetStream(Uri uri, ICredentials credentials, IWebProxy proxy, RequestCachePolicy cachePolicy) at System.Xml.XmlUrlResolver.GetEntity(Uri absoluteUri, String role, Type ofObjectToReturn) at System.Xml.XmlTextReaderImpl.OpenUrl() at System.Xml.XmlTextReaderImpl.Read() at System.Xml.XPath.XPathDocument.LoadFromReader(XmlReader reader, XmlSpace space) at System.Xml.XPath.XPathDocument..ctor(String uri, XmlSpace space) at System.Xml.XPath.XPathDocument..ctor(String uri) at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.&lt;&gt;c__DisplayClass23_0.&lt;IncludeXmlComments&gt;b__0() at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.IncludeXmlComments(SwaggerGenOptions swaggerGenOptions, Func`1 xmlDocFactory, Boolean includeControllerXmlComments) at Microsoft.Extensions.DependencyInjection.SwaggerGenOptionsExtensions.IncludeXmlComments(SwaggerGenOptions swaggerGenOptions, String filePath, Boolean includeControllerXmlComments) at Microsoft.Extensions.Options.OptionsFactory`1.Create(String name) at Microsoft.Extensions.Options.OptionsManager`1.&lt;&gt;c__DisplayClass5_0.&lt;Get&gt;b__0() at System.Lazy`1.ViaFactory(LazyThreadSafetyMode mode) at System.Lazy`1.ExecutionAndPublication(LazyHelper executionAndPublication, Boolean useDefaultConstructor) at System.Lazy`1.CreateValue() at System.Lazy`1.get_Value() at Microsoft.Extensions.Options.OptionsCache`1.GetOrAdd(String name, Func`1 createOptions) at Microsoft.Extensions.Options.OptionsManager`1.Get(String name) at Microsoft.Extensions.Options.OptionsManager`1.get_Value() at Swashbuckle.AspNetCore.SwaggerGen.ConfigureSchemaGeneratorOptions..ctor(IServiceProvider serviceProvider, IOptions`1 swaggerGenOptionsAccessor) at System.RuntimeMethodHandle.InvokeMethod(Object target, Object[] arguments, Signature sig, Boolean constructor, Boolean wrapExceptions) at System.Reflection.RuntimeConstructorInfo.Invoke(BindingFlags invokeAttr, Binder binder, Object[] parameters, CultureInfo culture) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitIEnumerable(IEnumerableCallSite enumerableCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitNoCache(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitCache(ServiceCallSite callSite, RuntimeResolverContext context, ServiceProviderEngineScope serviceProviderEngine, RuntimeResolverLock lockType) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitRootCache(ServiceCallSite singletonCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitConstructor(ConstructorCallSite constructorCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSiteMain(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.VisitDisposeCache(ServiceCallSite transientCallSite, RuntimeResolverContext context) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteVisitor`2.VisitCallSite(ServiceCallSite callSite, TArgument argument) at Microsoft.Extensions.DependencyInjection.ServiceLookup.CallSiteRuntimeResolver.Resolve(ServiceCallSite callSite, ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.DynamicServiceProviderEngine.&lt;&gt;c__DisplayClass1_0.&lt;RealizeService&gt;b__0(ServiceProviderEngineScope scope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngine.GetService(Type serviceType, ServiceProviderEngineScope serviceProviderEngineScope) at Microsoft.Extensions.DependencyInjection.ServiceLookup.ServiceProviderEngineScope.GetService(Type serviceType) at Microsoft.AspNetCore.Builder.UseMiddlewareExtensions.GetService(IServiceProvider sp, Type type, Type middleware) at lambda_method(Closure , Object , HttpContext , IServiceProvider ) at Microsoft.AspNetCore.Builder.UseMiddlewareExtensions.&lt;&gt;c__DisplayClass4_1.&lt;UseMiddleware&gt;b__2(HttpContext context) at Microsoft.AspNetCore.Mvc.Versioning.ApiVersioningMiddleware.InvokeAsync(HttpContext context) at Microsoft.AspNetCore.HostFiltering.HostFilteringMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.Hosting.HostingApplication.ProcessRequestAsync(Context context) at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.Http.HttpProtocol.ProcessRequests[TContext](IHttpApplication`1 application)fail: Microsoft.AspNetCore.Server.Kestrel[13] 很明显，是因为publish的时候没有把我们的Web.xml文件复制进去,那么我们在Dockerfile中添加一条 1COPY [&quot;Web/Web.xml&quot;, &quot;.&quot;] 在把之前是容器删除掉: 1docker rm 083d0c79c078 然后重新build一次 1docker build -t core3.x-swagger -f Dockerfile . 重启启动容器,很好，是想要的结果: 123[root@VM_175_142_centos Swagger.Demo]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb475841bece6 core3.x-swagger &quot;dotnet Web.dll&quot; 3 minutes ago Up 3 minutes 443/tcp, 0.0.0.0:9999-&gt;80/tcp swagger 后面，我们尝试使用腾讯云容器服务（Tencent Kubernetes Engine ，TKE）或者阿里容器服务 Kubernetes 版（简称 ACK）来部署我们的Docker镜像","link":"/2019/11/28/net-core3-x-publish/"},{"title":".net core 3.x Web API使用Swagger添加多版本以及JWT Authorization","text":"很多时候，要给我们的接口升级，但是又怕影响之前的接口业务或者是要开发特定的接口，我们会给接口加上一个版本号，保障老接口依然能稳定运行，例如百度的坐标转换服务 1http://api.map.baidu.com/geoconv/v1/?coords=114.21892734521,29.575429778924&amp;from=1&amp;to=5&amp;ak=你的密钥 //GET请求 在.net core中，想给接口加上版本号，有多种方式: 1、通过URL Path Segment来实现; 2、通过HTTP Headers来实现; 3、通过QueryString来实现;具体的实现可以去百度或者bing。这里暂时只讲swagger doc实现多版本切换。我个人喜欢使用第一种方式。 ApiExplorer组件的使用在实现多版本Web API，我们需要借助一个组件: 1Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer 成功添加依赖包后，就可以在程序中使用相应的API了，首先我们先创建如下的目录结构(大家可随意):接下来，就将我们之前的Controller类上添加相应的特性: 1234//当前Controller的版本号[ApiVersion(&quot;1.0&quot;)]//接口访问路径[Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] 然后在Startup的ConfigureServices中使用ApiExplorer 12services.AddApiVersioning();services.AddVersionedApiExplorer(options =&gt; options.GroupNameFormat = &quot;&apos;v&apos;VVV&quot;); Swagger中多版本API文档下面，我就用Swagger来自动生成多版本文档，为了使我的Startup类相对简洁，我们新建一个ConfigureSwaggerOptions类来放置Swagger的相关配置,完整代码如下： 1234567891011121314151617181920212223242526272829public class ConfigureSwaggerOptions : IConfigureOptions&lt;SwaggerGenOptions&gt; { readonly IApiVersionDescriptionProvider provider; public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) =&gt; this.provider = provider; public void Configure(SwaggerGenOptions options) { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerDoc(description.GroupName, new OpenApiInfo { Description = $&quot;Demo API {description.ApiVersion} Description&quot;, Version = description.ApiVersion.ToString(), Title = $&quot;Demo API 文档{description.ApiVersion}&quot;, Contact = new OpenApiContact() { Name = &quot;eyiadmin&quot;, Email = &quot;188781475@qq.com&quot; }, License = new OpenApiLicense { Name = &quot;Apache 2.0&quot;, Url = new Uri(&quot;http://www.apache.org/licenses/LICENSE-2.0.html&quot;) } }); } var docXmlPath = Path.Combine(AppContext.BaseDirectory, &quot;Web.xml&quot;); options.IncludeXmlComments(docXmlPath); } } 修改Startup类ConfigureServices中: 12services.AddTransient&lt;IConfigureOptions&lt;SwaggerGenOptions&gt;, ConfigureSwaggerOptions&gt;();services.AddSwaggerGen(); Configure中 1234567891011121314151617181920212223242526272829public void Configure(IApplicationBuilder app, IWebHostEnvironment env, IApiVersionDescriptionProvider provider) { if (env.IsDevelopment()) { app.UseSwagger(); app.UseSwaggerUI(options =&gt; { foreach (var description in provider.ApiVersionDescriptions) { options.SwaggerEndpoint( $&quot;/swagger/{description.GroupName}/swagger.json&quot;, description.GroupName.ToUpperInvariant()); } }); app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); } 最终效果如下：可以点击Select a definition切换我们不同版本的doc 在Swagger中添加Header Authorization 一般情况下，我们的Web API是使用Jwt来保障接口安全，当然还有很多其他的方式，我只是选择一种相对简单一些的方式。这里只是说怎么在Swagger调试的时候带上我们的Jwt Token，具体的Jwt实现，也请自己实现。 其实Swashbuckle已经给我们提供了很方便的API，只需要配置一下即可: 123456789101112131415161718options.AddSecurityDefinition(&quot;bearer&quot;, new OpenApiSecurityScheme { Type = SecuritySchemeType.Http, In = ParameterLocation.Header, Name = &quot;Authorization&quot;, Scheme = &quot;bearer&quot;, BearerFormat = &quot;JWT&quot;, Description = &quot;JWT Authorization header using the Bearer scheme.&quot;, }); var req = new OpenApiSecurityRequirement(); req.Add(new OpenApiSecurityScheme { Reference = new OpenApiReference { Type = ReferenceType.SecurityScheme, Id = &quot;bearer&quot; } }, new[] { &quot;&quot; }); options.AddSecurityRequirement(req); 效果如下:我们会看到有一个Authorization的按钮，我们点击可以输入我们获取到的Jwt Token,在文本框内不需要输入Bearer关键字，Swagger会自动为我们加上Bearer关键字。在这里也需要注意到Swagger的坑，因为大写的问题可能会导致Authorization无法添加到request请求头中.下面是Swagger的build-request.js 123456789101112131415161718else if (type === &apos;http&apos;) { if (schema.scheme === &apos;basic&apos;) { let scheme = schema.scheme; if (scheme) { scheme = scheme.toLowerCase() } if (scheme === &apos;basic&apos;) { const {username, password} = value const encoded = btoa(`${username}:${password}`) result.headers.Authorization = `Basic ${encoded}` } if (schema.scheme === &apos;bearer&apos;) { if (scheme === &apos;bearer&apos;) { result.headers.Authorization = `Bearer ${value}` } } 大家可以自己去看看代码，我继续说Authorization的设置，点击按钮就会出现设置token的文本框:设置完后，我们的小锁会变为关闭状态:最后就可以通过Swagger UI调用我们的接口，就可以在我们的请求中看到Authorization的参数内容，后端就可以接受处理.当然，Swagger还有其他的自定义UI功能，大家可以去官网查询相关文档。","link":"/2019/11/18/swagger-add-apiversion/"},{"title":"shell脚本学习","text":"Shell 脚本（shell script），是一种为 shell 编写的脚本程序。业界所说的 shell 通常都是指 shell 脚本，但读者朋友要知道，shell 和 shell script 是两个不同的概念。由于习惯的原因，简洁起见，本文出现的 “shell编程” 都是指 shell 脚本编程，不是指开发 shell 自身。 以上内容来源于runoob 上半年花了一个多月时间修改一个开源的BI项目(Redash),改完后,由于没有使用也就暂时告一段落，就在昨天，一个客户说想找一个开源的BI系统，我们就给他推荐这个工具，因为它简单、方便、快捷，而且也比较受欢迎。但是客户对Docker不熟悉，就给他大致的讲了一个怎么在 Windows搭建一个测试环境。后来，突然想看看Redash的Dockerfile文件，看到里面的执行文件： 12ENTRYPOINT [&quot;/app/bin/docker-entrypoint&quot;]CMD [&quot;server&quot;] docker-entrypoint是一个shell脚本，但是因为自己对shell的使用还未入门，所以就着这个机会，去简单了解一下。我们先看一下docker-entrypoint中的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#!/bin/bashset -ecelery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS}scheduler() { echo &quot;Starting RQ scheduler...&quot; exec /app/manage.py rq scheduler}dev_scheduler() { echo &quot;Starting dev RQ scheduler...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq scheduler}worker() { echo &quot;Starting RQ worker...&quot; exec /app/manage.py rq worker $QUEUES}dev_worker() { echo &quot;Starting dev RQ worker...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- ./manage.py rq worker $QUEUES}dev_celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec watchmedo auto-restart --directory=./redash/ --pattern=*.py --recursive -- /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair}server() { # Recycle gunicorn workers every n-th request. See http://docs.gunicorn.org/en/stable/settings.html#max-requests for more details. MAX_REQUESTS=${MAX_REQUESTS:-1000} MAX_REQUESTS_JITTER=${MAX_REQUESTS_JITTER:-100} exec /usr/local/bin/gunicorn -b 0.0.0.0:5000 --name redash -w${REDASH_WEB_WORKERS:-4} redash.wsgi:app --max-requests $MAX_REQUESTS --max-requests-jitter $MAX_REQUESTS_JITTER}create_db() { exec /app/manage.py database create_tables}celery_healthcheck() { exec /usr/local/bin/celery inspect ping --app=redash.worker -d celery@$HOSTNAME}rq_healthcheck() { exec /app/manage.py rq healthcheck}help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}tests() { export REDASH_DATABASE_URL=&quot;postgresql://postgres@postgres/tests&quot; if [ $# -eq 0 ]; then TEST_ARGS=tests/ else TEST_ARGS=$@ fi exec pytest $TEST_ARGS}case &quot;$1&quot; in worker) shift worker ;; server) shift server ;; scheduler) shift scheduler ;; dev_scheduler) shift dev_scheduler ;; celery_worker) shift celery_worker ;; dev_celery_worker) shift dev_celery_worker ;; dev_worker) shift dev_worker ;; rq_healthcheck) shift rq_healthcheck ;; celery_healthcheck) shift celery_healthcheck ;; dev_server) export FLASK_DEBUG=1 exec /app/manage.py runserver --debugger --reload -h 0.0.0.0 ;; debug) export FLASK_DEBUG=1 export REMOTE_DEBUG=1 exec /app/manage.py runserver --debugger --no-reload -h 0.0.0.0 ;; shell) exec /app/manage.py shell ;; create_db) create_db ;; manage) shift exec /app/manage.py $* ;; tests) shift tests $@ ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac #!/bin/bash的作用我们可以再很多sh脚本里面看到#!/bin/bash这段代码，那么它有什么作用呢?shell是一种脚本命令语言，它有多种解析器，例如：/bin/csh、/bin/perl、/bin/bash、bin/sh等等，那么在在第一行加上#!/bin/bash，就是告诉系统这个脚本需要bin/bash解释器来执行。 set -e的作用set -e的作用是：当命令的返回值为非零状态时，则立即退出脚本的执行，防止导致一个致命的错误，而这些错误本应该在之前就被处理掉。set -e 命令用法总结如下： 当命令的返回值为非零状态时，则立即退出脚本的执行。 作用范围只限于脚本执行的当前进行，不作用于其创建的子进程（https://blog.csdn.net/fc34235/article/details/76598448 ）。 另外，当想根据命令执行的返回值，输出对应的log时，最好不要采用set -e选项，而是通过配合exit 命令来达到输出log并退出执行的目的。shell 中的 set -e 和 set +e的区别 shell 函数shell函数的定义格式如下： 12345[ function ] funname [()]{ action; [return int;]} 函数定义可以带function funname() 定义，也可以直接funname() 定义,不带任何参数。函数返回值可加return也可以不加，不加则以最后一条命令运行结果作为返回值。 12345678celery_worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; exec /usr/local/bin/celery worker --app=redash.worker -c$WORKERS_COUNT -Q$QUEUES -linfo --max-tasks-per-child=10 -Ofair $WORKER_EXTRA_OPTIONS} shell变量12# 如果WORKERS_COUNT未定义或者为空字符串，则返回默认值，否则返回WORKERS_COUNT的值WORKERS_COUNT=${WORKERS_COUNT:-2} 注意，变量名和等号之间不能有空格,而且还需要遵循如下规则： 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用bash里的关键字（可用help命令查看保留关键字）。 使用一个定义过的变量，只要在变量名前面加美元符号即可。例如: 1$WORKERS_COUNT或者${WORKERS_COUNT} shell 参数我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：$n,n 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推实例以下实例我们向脚本传递三个参数，并分别输出，其中 $0 为执行的文件名： 123456789101112131415161718#!/bin/bash# author:菜鸟教程# url:www.runoob.comecho &quot;Shell 传递参数实例！&quot;;echo &quot;执行的文件名：$0&quot;;echo &quot;第一个参数为：$1&quot;;echo &quot;第二个参数为：$2&quot;;echo &quot;第三个参数为：$3&quot;;为脚本设置可执行权限，并执行脚本，输出结果如下所示：$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：./test.sh第一个参数为：1第二个参数为：2第三个参数为：3 123456789$# 传递到脚本的参数个数$* 以一个单字符串显示所有向脚本传递的参数。如&quot;$*&quot;用「&quot;」括起来的情况、以&quot;$1 $2 … $n&quot;的形式输出所有参数。$$ 脚本运行的当前进程ID号$! 后台运行的最后一个进程的ID号$@ 与$*相同，但是使用时加引号，并在引号中返回每个参数。如&quot;$@&quot;用「&quot;」括起来的情况、以&quot;$1&quot; &quot;$2&quot; … &quot;$n&quot; 的形式输出所有参数。$- 显示Shell使用的当前选项，与set命令功能相同。$? 显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。 这里直接copy runoob的内容 shell case 用法12345678910111213case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac shift命令：在shell中，经常可能会遇到多参数传递，例如$1,$2,…$9，借助shift命令可以访问更多传递的参数case语句： 以case开头，esac结尾； 取值后面必须为单词in 匹配一个值与一个模式以”)”(右括号)结束 双分号 “;;” 表示命令序列结束； 默认模式使用”*)”表示，在不满足前面的模式后，执行默认模式后的命令示例:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748worker() { WORKERS_COUNT=${WORKERS_COUNT:-2} QUEUES=${QUEUES:-queries,scheduled_queries} WORKER_EXTRA_OPTIONS=${WORKER_EXTRA_OPTIONS:-} echo &quot;Starting $WORKERS_COUNT workers for queues: $QUEUES...&quot; echo &quot;$WORKERS_COUNT&quot; }help() { echo &quot;Redash Docker.&quot; echo &quot;&quot; echo &quot;Usage:&quot; echo &quot;&quot; echo &quot;server -- start Redash server (with gunicorn)&quot; echo &quot;celery_worker -- start Celery worker&quot; echo &quot;dev_celery_worker -- start Celery worker process which picks up code changes and reloads&quot; echo &quot;worker -- start a single RQ worker&quot; echo &quot;dev_worker -- start a single RQ worker with code reloading&quot; echo &quot;scheduler -- start an rq-scheduler instance&quot; echo &quot;dev_scheduler -- start an rq-scheduler instance with code reloading&quot; echo &quot;celery_healthcheck -- runs a Celery healthcheck. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;rq_healthcheck -- runs a RQ healthcheck that verifies that all local workers are active. Useful for Docker&apos;s HEALTHCHECK mechanism.&quot; echo &quot;&quot; echo &quot;shell -- open shell&quot; echo &quot;dev_server -- start Flask development server with debugger and auto reload&quot; echo &quot;debug -- start Flask development server with remote debugger via ptvsd&quot; echo &quot;create_db -- create database tables&quot; echo &quot;manage -- CLI to manage redash&quot; echo &quot;tests -- run tests&quot;}case &quot;$1&quot; in worker) shift worker ;; help) shift help ;; *) exec &quot;$@&quot; ;;esac 效果如下:123[root@VM_175_142_centos ~]# ./shell_echo.sh workerStarting 2 workers for queues: queries,scheduled_queries...2 结束这里只是借助redash的sh脚本来简单了解了一下shell的一些常用命令及语法，当然，shell的强大之处肯定不止于此，后面再遇到的时候，再来学习。大家也可以去runoob系统的学习一下","link":"/2019/11/14/shell-command/"},{"title":"Hexo静态网页上传到七牛云","text":"很多人都是把Hexo、hugo等工具生成的静态页面都是上传到Github,这样虽然很方便，但是毕竟在国外，而且百度爬虫老是失败，虽然有盆友说可以上传到Gitee上，域名识别不同的访问线路解析不同的空间。我也这样搞过，但是最近发现，好像七牛云可以托管静态页面。那么就来搞搞咯 要上传到七牛云，当然得有个七牛云账号啦，这个没有的自己去搞一下，就不说了。下面我们来说说具体的操作。 配置对象空间 新建一个对象空间 在空间设置中打开【默认首页设置】 安装七牛云上传工具qshell是利用七牛文档上公开的API实现的一个方便开发者测试和使用七牛API服务的命令行工具,下载qshell,下载之后解压， 文件名 描述 qshell_linux_x86 Linux 32位系统 qshell_linux_x64 Linux 64位系统 qshell_windows_x86.exe Windows 32位系统 qshell_windows_x64.exe Windows 64位系统 qshell_darwin_x64 Mac 64位系统，主流的系统 我这里是Win10-X64,所以下载后重命名qshell_windows_x64.exe为qshell.exe,在环境变量中配置qshell文件路径 上传文件到七牛云首选需要添加账号: 1qshell account &lt;Your AccessKey&gt; &lt;Your SecretKey&gt; &lt;Your Name&gt; qshell有qupload配置文件方式和qupload2命令行方式，具体操作去https://github.com/qiniu/qshell查看详细文档，这里我更倾向于命令行: 1qshell qupload2 --src-dir=E:/hexo/hexo/public --bucket=空间名 配置域名 进入域名管理 新增域名,输入域名点击创建 创建成功后，会有一个CNAME，复制CNAME去解析域名: 回到七牛云的内容空间，设置默认域名这时候，我们的博客就可以正常访问了 小技巧:我们可以再package.json自定义一个我们的命令, 如下: 1234567&quot;scripts&quot;: { &quot;build&quot;: &quot;hexo generate&quot;, &quot;clean&quot;: &quot;hexo clean&quot;, &quot;deploy&quot;: &quot;hexo deploy&quot;, &quot;server&quot;: &quot;hexo server&quot;, &quot;d&quot;:&quot;hexo clean &amp; hexo g &amp; hexo d &amp; qshell qupload2 --overwrite=true --rescan-local=true --src-dir=E:/hexo/hexo/public --bucket=七牛云空间名称&quot; }, 这时候我们在命令行执行npm run d 即可清理、生成、上传文件啦","link":"/2019/12/08/upload-blog-2-qiniu/"},{"title":"使用Lombok简化java代码","text":"Lombok是一款提高javaer开发效率的插件工具，特别是在繁多是bean类中的getter、setter，使用Lombok可以使用注解的方式省去了添加getter、setter的时间 在使用Lombok之前，需要在IDE上安装插件，eclipse安装步骤稍微多一点，具体请自行百度或者去官方查看https://projectlombok.org/features/configuration，IntelliJ安装就相对来说比较方便，直接在插件中心搜索Lombok,安装Lombok Plugin即可。接下来，我们在程序中引入jar包： 1234567&lt;!-- https://mvnrepository.com/artifact/org.projectlombok/lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.10&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 我们平时的POJO类一般都是这样写: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586public class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { } public String getUserName() { return this.userName; } public void setUserName(String userName) { this.userName = userName; } public String getOperator() { return this.operator; } public void setOperator(String operator) { this.operator = operator; } public String getSource() { return this.source; } public void setSource(String source) { this.source = source; } public String getDisplayName() { return this.displayName; } public void setDisplayName(String displayName) { this.displayName = displayName; } public String getFilePath() { return this.filePath; } public void setFilePath(String filePath) { this.filePath = filePath; } public String getCreator() { return this.creator; } public void setCreator(String creator) { this.creator = creator; } public Timestamp getStartTime() { return this.startTime; } public void setStartTime(Timestamp startTime) { this.startTime = startTime; } public Timestamp getCreateTime() { return this.createTime; } public void setCreateTime(Timestamp createTime) { this.createTime = createTime; } public long getFileSize() { return this.fileSize; } public void setFileSize(long fileSize) { this.fileSize = fileSize; }} 如果属性更多的话，添加getter、setter就需要花更多的时间。如果使用Lombok插件的话，不仅可以节省时间，而且代码也更加简洁: 1234567891011121314151617181920public class DataFileDownloadAudit { @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private Timestamp startTime; @Setter(AccessLevel.PUBLIC) @Getter(AccessLevel.PROTECTED) private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime; public DataFileDownloadAudit() { }} 这样只是给属性加getter、setter，我们也可以用@Data来继续简化: 123456789101112@Datapublic class DataFileDownloadAudit { private Timestamp startTime; private String userName; private String operator; private String source; private String displayName; private String filePath; private long fileSize; private String creator; private Timestamp createTime;} 这两种方式有什么差异呢？@Getter和@Setter是作用在bean属性上，可以自动生成getter、setter方法，@Data是作用在类上，他结合了@ToString, @EqualsAndHashCode, @Getter,@Setter,@RequiredArgsConstructor注解的功能。这仅仅说了Lombok两个常用的注解，总的来说，它会给我们带来更加简洁的代码和快速的开发效率，其他更加强大的功能可以去https://projectlombok.org/features/all自行查看。","link":"/2019/11/06/%E4%BD%BF%E7%94%A8Lombok%E7%AE%80%E5%8C%96java%E4%BB%A3%E7%A0%81/"},{"title":"没有java源代码如何修改bug","text":"有时候遇到比较老的产品，公司的产品组也不提供维护了，更可恨的是，源代码也不给。在这种情况，遇到有bug，怎么办呢？ 我们项目组一直在维护着一个2013年基于公司老产品开发的项目，既然是产品，公司产品弄死不肯定提供老产品的代码，原因大概是因为代码管理混乱，已经找不到我们项目的代码了。 这个bug出现在数据授权的时候，按常规组织授权后，下级用户居然能看到上级用户数据，我们的数据授权原理是：获取授权用户所在层级，并获取当前的授权组织表，将组织表数据和当前用户进行匹配，并记录在授权表，然后，用户在查询数据的时候就读取授权表拼接in语句去数据库查询。当出现这个问题的时候，显然是不允许的，这时候，我们的检查步骤是：1、检查用户组织表2、检查授权表3、检查最终执行sql语句通过以上步骤，最终发现是在做sql拼接成in的条件的时候出现的问题，这时候，就只有进入到代码里面一探究竟，由于没有源代码，就只有借用各种反编译工具：1、Java Decompiler2、Jadclipse3、jad4、jd-gui…..等等，还有很多其他的，这里，我选用的是jd-gui，如果是用的idea作为IDE的话，可以直接查看。借助反编译工具反编译出来的代码如下： 12345678910111213141516171819202122static boolean userIsDept(JdbcTemplate sysJdbcTemplate, final String dept, String userId) { String sql = SQLProvider.getSQL(&quot;query.all.sub.dept&quot;); List&lt;String&gt; depts = (List)sysJdbcTemplate.query(sql, new PreparedStatementSetter() { public void setValues(PreparedStatement ps) throws SQLException { ps.setString(1, dept); ps.setString(2, dept); } }, new ResultSetExtractor&lt;List&lt;String&gt;&gt;() { public List&lt;String&gt; extractData(ResultSet rs) throws SQLException, DataAccessException { ArrayList trs = new ArrayList(); while(rs.next()) { trs.add(rs.getString(&quot;DEPT_ID&quot;)); } return trs; } }); String userDeptSql = SQLProvider.getSQL(&quot;query.user.dept&quot;); String userDeptId = (String)sysJdbcTemplate.queryForObject(userDeptSql, String.class, new Object[]{userId}); return depts.contains(userDeptId); } 经过分析，发现该处的组织id过多加载，因为在授权表中已经将当前用户所属组织的授权内容全量写进去，这儿过多加载，其实把父组织的授权内容也一并拼接到了in条件内，所以出现这种情况。最后，我通过idea新建一个java项目，把项目的依赖包添加进去，新建了一个同包名、同类名的类，将代码copy进新类，稍作修改，就可导出一个jar包。然后将class文件复制到原来的jar包中覆盖即可，在这里，一定要注意JDK版本，否者会报错。","link":"/2019/11/05/%E6%B2%A1%E6%9C%89java%E6%BA%90%E4%BB%A3%E7%A0%81%E5%A6%82%E4%BD%95%E4%BF%AE%E6%94%B9bug/"},{"title":"基于redis key失效机制实现状态实时更新","text":"基于redis key失效事件通知机制来处理状态实时更新 在我们的业务中，有这样一个场景，在手机端实时采集用用户经纬度，判断用户是否在某个场景(小区、商场等)内,如果再场景内则变更用户任务状态为”执行中”，当用户离开场景超过20分钟，需要将用户任务状态更改为”离场”状态。 一般，我们更新状态，要么定时去扫描数据库，要么就是触发某个事件，在最开始，有想到几种方案：1、定时（采用quartz定时执行作业，去扫描数据库）2、用hangfire、rabbitmq等实现延迟执行3、redis key失效事件，实时处理经过评估，最后选择了redis key失效机制来处理这个业务。 redis key失效事件监听redis自2.8之后就提供Keyspace Notifications功能，允许客户订阅Pub/Sub。 开启事件通知默认情况下，redis是没有开启事件通知的，所以我们需要手动配置： 12打开redis.conf配置文件搜索notify-keyspace-events，该配置默认是被注释掉的，需要将其修改为notify-keyspace-events Ex ,然后重启便可生效 值说明: 1234567891011# K 键空间通知，以__keyspace@&lt;db&gt;__为前缀# E 键事件通知，以__keysevent@&lt;db&gt;__为前缀# g del , expipre , rename 等类型无关的通用命令的通知, ...# $ String命令# l List命令# s Set命令# h Hash命令# z 有序集合命令# x 过期事件（每次key过期时生成）# e 驱逐事件（当key在内存满了被清除时生成）# A g$lshzxe的别名，因此”AKE”意味着所有的事件 spring boot实现消息监听器类pom.xml: 12345678910111213141516171819202122 &lt;!-- https://mvnrepository.com/artifact/redis.clients/jedis --&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.12&lt;/version&gt;&lt;/dependency&gt; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Componentpublic class RedisMsgPubSubListener extends JedisPubSub { private Logger logger = LoggerFactory.getLogger(getClass()); @Autowired ITaskService taskService; @Override public void unsubscribe() { super.unsubscribe(); } @Override public void unsubscribe(String... channels) { super.unsubscribe(channels); } @Override public void subscribe(String... channels) { super.subscribe(channels); } @Override public void psubscribe(String... patterns) { super.psubscribe(patterns); } @Override public void punsubscribe() { super.punsubscribe(); } @Override public void punsubscribe(String... patterns) { super.punsubscribe(patterns); } @Override public void onMessage(String channel, String message) { System.out.println(&quot;channel:&quot; + channel + &quot;receives message :&quot; + message); String key = message; } @Override public void onPMessage(String pattern, String channel, String message) { } @Override public void onSubscribe(String channel, int subscribedChannels) { } @Override public void onPUnsubscribe(String pattern, int subscribedChannels) { } @Override public void onPSubscribe(String pattern, int subscribedChannels) { } @Override public void onUnsubscribe(String channel, int subscribedChannels) { }} 创建一个Runner： 123456789101112131415161718192021public class RedisApplicationRunner implements ApplicationRunner { @Autowired RedisMsgPubSubListener redisMsgPubSubListener; @Autowired JedisPool jedisPool; @Override public void run(ApplicationArguments applicationArguments) throws Exception { Jedis jedis = jedisPool.getResource();// jedis.set(&quot;zhcj:mobile:13548074395:2018122222212&quot;,&quot;1&quot;);// jedis.expire(&quot;zhcj:mobile:13548074395:2018122222212&quot;,10); jedis.subscribe(redisMsgPubSubListener, &quot;__keyevent@0__:expired&quot;); }} 最终效果:","link":"/2019/10/24/%E5%9F%BA%E4%BA%8Eredis-key%E5%A4%B1%E6%95%88%E6%9C%BA%E5%88%B6%E5%AE%9E%E7%8E%B0%E7%8A%B6%E6%80%81%E5%AE%9E%E6%97%B6%E6%9B%B4%E6%96%B0/"},{"title":"微信小程序上传图片到七牛云","text":"微信小程序上传图片到七牛云,小程序Webview嵌入H5上传图片&amp;原生小程序上传图片 最近在帮朋友做微信小程序，没有选择mpvue，因为时间紧加上不熟悉，怕遇到坑不能快速处理，拖了进度，所以采用了原生小程序+webview的方式做了第一版。 小程序webview上传图片因为涉及到H5，所以图片上传这块就用到了微信中的jssdk， 第一步是wx.config配置前端代码如下: 123456789101112131415161718192021222324252627282930313233343536373839abp.services.app.wxAccess.getOfficialAccountJsdkConfig().done(function (data) { if (data) { var appId = data.appId; var timestamp = data.timestamp; var nonceStr = data.noncestr; var signature = data.signature; wx.config({ debug: false, //调试模式 当为tru时，开启调试模式 appId: appId, timestamp: timestamp.toString(), //签名时间戳 nonceStr: nonceStr, //生成签名的随机串 signature: signature, //签名 jsApiList: [&apos;chooseImage&apos;, &apos;uploadImage&apos;], success: function () { alert(&quot;配置成功&quot;); }, fail: function () { alert(&quot;配置失败&quot;); } }); wx.ready(function () { // 在这里调用 API wx.checkJsApi({ jsApiList: [ &apos;chooseImage&apos;, &apos;uploadImage&apos; ], success: function (res) { //console.log(JSON.stringify(res)); } }); }); wx.error(function(res){ alert(JSON.stringify(res)); }); } }); 后端代码： 1234567891011121314151617181920212223242526272829303132/// &lt;summary&gt;/// 获取公众号JsdkConfig/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public async Task&lt;Dtos.GetOfficialAccountJsdkConfigOutput&gt; GetOfficialAccountJsdkConfig() { var input = new Dtos.GetAccessInput { AppId = _appConfiguration[&quot;WechatOfficialAccount:AppId&quot;], Secret = _appConfiguration[&quot;WechatOfficialAccount:Secret&quot;] }; var noncestr = Guid.NewGuid().ToString(&quot;N&quot;); var jsapi = await GetJsapiTicket(input); //var timestamp = (DateTime.Now.Ticks - new DateTime(1970, 1, 1, 0, 0, 0, 0).Ticks) / 10000000; var timestamp = new Helper.UnixTime().DateTimeToUnix(DateTime.Now); //var url = Request.UrlReferrer.OriginalString; var url = _iHttpContextAccessor.HttpContext.Request.Headers[Microsoft.Net.Http.Headers.HeaderNames.Referer].ToString(); var shaStr = $&quot;jsapi_ticket={jsapi.Permit}&amp;noncestr={noncestr}&amp;timestamp={timestamp}&amp;url={url}&quot;; var signature = new Helper.Encrypt().Sha1Encrypt(shaStr); return new Dtos.GetOfficialAccountJsdkConfigOutput { AppId = input.AppId, Noncestr = noncestr, Timestamp = timestamp, Signature = signature }; } 第二步就是调用jssdk前端js代码如下： 123456789101112131415161718192021222324252627282930313233wx.chooseImage({ count: 9, needResult: 1, sizeType: [&apos;original&apos;, &apos;compressed&apos;], // 可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], // 可以指定来源是相册还是相机，默认二者都有 success: function (data) { //localIds = data.localIds[0]; // 返回选定照片的本地ID列表，localId可以作为img标签的src属性显示图片 for (var localId = 0; localId &lt;= data.localIds.length - 1; localId++) { if (isIOS) { wx.getLocalImgData({ localId: data.localIds[localId], // 图片的localID success: function (res) { // var localData = res.localData; // localData是图片的base64数据，可以用img标签显示 //console.log(localData); } }); } else { } } }, fail: function (res) { alert(JSON.stringify(res)); //alterShowMessage(&quot;操作提示&quot;, JSON.stringify(res), &quot;1&quot;, &quot;确定&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;); } }); jssdk中，如果是iOS的话，前端无法直接使用localIds资源id做展示，需要调用wx.getLocalImgData方法来获取图片的base64编码 提交前端选择的图片到服务端并由服务的上传到七牛云前端部分代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546wx.uploadImage({ //获取图片媒体ID localId: localIds[erp.common.idx].toString(), // 需要上传的图片的本地ID isShowProgressTips: 1, // 默认为1，显示进度提示 success: function (res) { //获取成功 // 上传序号，上传一张 累计 +1 erp.common.idx++; //存储图片媒体ID，用，号分割 // serverIds += res.serverId + &apos;,&apos;; erp.common.serverIdsArr.push(res.serverId); if (erp.common.idx &lt; localIds.length) { //本地图片ID 还没全部获取完图片媒体ID //调用上传递归函数 erp.common.wxUploadImg(localIds, callback); } else { //上传序号归零 erp.common.idx = 0; //服务器csrf 验证字符串，如果后端框架没开启csrf，则不需要 //alert(erp.common.serverIdsArr); abp.services.app.wxAccess.uploadMediaToQiniu({ WxMediaIds: mediaIds }).done(function (data) { var imageUrl = []; for (var index = 0; index &lt;= data.qiniuFiles.length - 1; index++) { imageUrl.push(data.qiniuFiles[index].qiniuUrl); } $.hideLoading(); callback &amp;&amp; callback(imageUrl); }).always(function(){ $.hideLoading(); }); //serverIds = &apos;&apos;; erp.common.serverIdsArr.length = 0; return true; } }, fail: function (res) { //获取多媒体id失败 返回错误代码 alert(&quot;上传失败，msg：&quot; + JSON.stringify(res)); } }); 后端部分代码: 1234567891011121314151617181920212223242526272829303132333435/// &lt;summary&gt;/// 上传文件到七牛/// &lt;/summary&gt;/// &lt;param name=&quot;input&quot;&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;//[RemoteService(false)]public async Task&lt;Dtos.UploadMediaToQiniuOutput&gt; UploadMediaToQiniu(Dtos.UploadMediaToQiniuInput input){ var output = new Dtos.UploadMediaToQiniuOutput(); if (input.WxMediaIds.Count &gt; 0) { output.QiniuFiles = new System.Collections.Generic.List&lt;Dtos.QiniuFile&gt;(); var access_token = await GetOfficialAccountAccessToken(); var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var prefixPath = _appConfiguration[&quot;Qny:prefixPath&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); foreach (var mediaId in input.WxMediaIds) { var url = $&quot;https://api.weixin.qq.com/cgi-bin/media/get?access_token={access_token.Permit}&amp;media_id={mediaId}&quot;; var fileKey = qiniuStorage.UploadStream(url); var fileUrl = $&quot;{prefixPath}/{fileKey}&quot;; output.QiniuFiles.Add(new Dtos.QiniuFile { QiniuUrl = fileUrl, WxMediaId = mediaId }); } } return output;} 原生小程序上传图片到七牛云后面考虑到一些交互上面的问题，就把原来的webview方式改成了全原生的模式。采用原生的方式，在图片上传上面就好处理多了，只需要实现获取到七牛云用于上传的token，然后使用wx.uploadFile即可上传。服务端获取token代码： 12345678910111213/// &lt;summary&gt;/// 获取七牛token/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;public QiniuTokenOutputDto GetQiniuUpToken(){ var accessKey = _appConfiguration[&quot;Qny:qiniuyunAK&quot;]; var secretKey = _appConfiguration[&quot;Qny:qiniuyunSK&quot;]; var bucket = _appConfiguration[&quot;Qny:qiniuyunBucket&quot;]; var qiniuStorage = new Helper.QiniuStorage(accessKey, secretKey, bucket); var output = new QiniuTokenOutputDto() { UpToken = qiniuStorage.CreateUploadToken() }; return output;} 小程序端部分代码: 12345678910111213141516171819202122232425262728293031323334353637383940411、获取token2、调用小程序API，选择图片。 wx.chooseImage({ count: 9-this.data.cardImgList.length, //默认9 sizeType: [&apos;original&apos;, &apos;compressed&apos;], //可以指定是原图还是压缩图，默认二者都有 sourceType: [&apos;album&apos;, &apos;camera&apos;], //从相册选择 success: (res) =&gt; { res.tempFilePaths.forEach((item,index)=&gt;{ that.upload2Qiniu(item); }); } }); } /*** 图片上传七牛云*/ upload2Qiniu(tempFilePaths) { let token = this.data.token; var that = this; wx.uploadFile({ url: &apos;https://up-z0.qiniup.com&apos;, name: &apos;file&apos;, filePath: tempFilePaths, header: { &quot;Content-Type&quot;: &quot;multipart/form-data&quot; }, formData: { token: that.data.upToken, }, success: function (res) { let data = JSON.parse(res.data) //data.hash图片的资源名，可直接通过域名加资源名访问 // to do ... }, fail: function (res) { console.log(res) } }); } 如果需要更详细的资料，那么就请自行百度or谷歌吧","link":"/2019/10/24/%E5%BE%AE%E4%BF%A1%E5%B0%8F%E7%A8%8B%E5%BA%8F%E4%B8%8A%E4%BC%A0%E5%9B%BE%E7%89%87%E5%88%B0%E4%B8%83%E7%89%9B%E4%BA%91/"},{"title":"高德地图和google地图整合","text":"整合百度和google地图 因为高德地图的卫星地图不全，但是在高德地图没有的地方，google地图却有，所以客户有一个需求，就是当高德地图显示”无卫星地图”的时候，就显示google地图的图片。 求助万能的百度当然，因为对地图api不是很熟悉，所以就只有百度和看高德官方文档，但是都没有找到合适的解决方案，有看到叠加地图图层并自定义图片路径，这显然不适合我目前的场景，另外一个就是通过API来叠加地图，结合api判断大概的x-y-z的数值范围来加载不同的切片路径. 1234567891011google = new AMap.TileLayer({ map: map, zIndex: 70, //图块取图地址 getTileUrl: function (x, y, z) { //console.log(arguments); if (x &gt;= 12931 &amp;&amp; y &gt;= 3364 &amp;&amp; z &gt;= 16) return &quot;http://mt0.google.cn/vt/lyrs=s&amp;hl=zh-CN&amp;gl=cn&amp;x=&quot; + x + &quot;&amp;y=&quot; + y + &quot;&amp;z=&quot; + z + &quot;&amp;s=Galile&quot;; } }); 当然，这种方式解决起来并不优雅，而且客户也反馈过，很多地方google有卫星地图但是现在依然没有，因为如果要加载得更细，就要判断更多的xyz，所以处理起来也不方便。 突发奇想之后，突然想到，为何不在服务端来判断当前切片是否是正常的卫星地图切片，如果不是则去请求google地图的切片，采用这种方式的话，那么就需要修改jsapi，但是高德并不提供离线的js api，怎么办呢？ 当然办法是肯定有的，就是自己去下载一个高德js api，然后把卫星地图模式所指向的地址改为自己的服务端地址即可，项目中就引用自己下载的离线js。js api修改代码： 123456在离线js中查询关键字:autonavi.com/appmaptile?style=6可以找到这样的地址:http://webst0{1,2,3,4}.is.autonavi.com/appmaptile?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z]将其修改为自己的代理地址:http://211.137.xxx.xxx/map/?style=6&amp;x=[x]&amp;y=[y]&amp;z=[z] 其他调用方式不变，使用这种方式之后，融合率几乎是99.99%，如果高德和google结合后还是有无卫星地图的情况，那我暂时也没想到比较好的处理方式了。最终效果如下:","link":"/2019/10/24/%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BE%E5%92%8Cgoogle%E5%9C%B0%E5%9B%BE%E6%95%B4%E5%90%88/"},{"title":".net core使用Topshelf注册windows服务","text":"Topshelf注册windows服务，方便快捷 我们经常会用一些定时处理的任务，在.net种一般是结合Quartz或者hangfire这两个组件实现定时周期性作业，但是我想把开发好的定时作业注册成windows服务，这样，在服务器重启之后，可以自动运行服务。Topshelf 就可以很方便的开发windows，而且注册安装也很方便。TopShelf的地址：http://topshelf-project.com/我们首先使用netget安装TopShelf： 1Install-Package TopShelf 然后在program.cs中加入如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243var builder = new HostBuilder() .ConfigureAppConfiguration(config =&gt; { config.AddJsonFile(&quot;monitor.json&quot;, optional: true, reloadOnChange: true); }) .ConfigureServices((hostContext, services) =&gt; { services.Configure&lt;Config&gt;(hostContext.Configuration.GetSection(&quot;monitor&quot;)); services.AddSingleton&lt;IHostLifetime, TopshelfLifetime&gt;(); services.AddHostedService&lt;MonitorService&gt;(); });HostFactory.Run(service =&gt; { service.SetServiceName(&quot;服务名&quot;); service.SetDisplayName(&quot;服务显示名称&quot;); service.SetDescription(&quot;服务描述&quot;); service.UseLog4Net(&quot;log4net.config&quot;); service.Service&lt;IHost&gt;(host =&gt; { host.ConstructUsing(() =&gt; builder.Build()); host.WhenStarted(serviceInstance =&gt; { serviceInstance.StartAsync(); }); host.WhenStopped(serviceInstance =&gt; { serviceInstance.StopAsync(); }); }); service.OnException((ex) =&gt; { Console.WriteLine(&quot;Exception thrown - &quot; + ex.Message); }); service.RunAsLocalSystem(); }); } 新建一个类继承IHostedService接口: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class MonitorService : IHostedService, IDisposable { private IScheduler scheduler; static readonly LogWriter _log = HostLogger.Get&lt;MonitorService&gt;(); public readonly Config Config; private Timer _timer; Config _config; public MonitorService() { } public MonitorService(IOptions&lt;Config&gt; config) { _config = config?.Value; //Config = _config; } public async Task StartAsync(CancellationToken cancellationToken) { _log.Info(&quot;service starting&quot;); ISchedulerFactory sf = new StdSchedulerFactory(); scheduler = await sf.GetScheduler(); IJobDetail job = JobBuilder.Create&lt;AreaSyncJob&gt;().WithIdentity(&quot;job1&quot;, &quot;group1&quot;).Build(); ITrigger trigger = TriggerBuilder.Create().WithIdentity(&quot;triggger1&quot;, &quot;group1&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.AreaJobCronExpr))).Build(); IJobDetail job1 = JobBuilder.Create&lt;LocationSyncJob&gt;().WithIdentity(&quot;job2&quot;, &quot;group2&quot;).Build(); ITrigger trigger1 = TriggerBuilder.Create().WithIdentity(&quot;triggger2&quot;, &quot;group2&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.LocationCronExpr))).Build(); IJobDetail job2 = JobBuilder.Create&lt;TaskExecAyncJob&gt;().WithIdentity(&quot;job3&quot;, &quot;group3&quot;).Build(); ITrigger trigger2 = TriggerBuilder.Create().WithIdentity(&quot;triggger3&quot;, &quot;group3&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.TaskExecCronExpr))).Build(); IJobDetail job3 = JobBuilder.Create&lt;MonitorJob&gt;().WithIdentity(&quot;job4&quot;, &quot;group4&quot;).Build(); ITrigger trigger3 = TriggerBuilder.Create().WithIdentity(&quot;triggger4&quot;, &quot;group4&quot;).WithSchedule(CronScheduleBuilder.CronSchedule(new CronExpression(_config.MonitorCronExpr))).Build(); //启动任务 await scheduler.ScheduleJob(job, trigger); await scheduler.ScheduleJob(job1, trigger1); await scheduler.ScheduleJob(job2, trigger2); await scheduler.ScheduleJob(job3, trigger3); await scheduler.Start(); _log.Info(&quot;service started&quot;); } public Task StopAsync(CancellationToken cancellationToken) { _timer?.Change(Timeout.Infinite, 0); scheduler?.Shutdown(); return Task.CompletedTask; } public void Dispose() { scheduler = null; _timer?.Dispose(); } } StartAsync方法为服务启动时运行。然后编译程序： 1dotnet publish -o ./bin/output -c Release -r win7-x64 执行成功后，会在bin/output目录下生成运行所需要的的程序和依赖DLL。将整个目录复制到指定服务器，cmd进入到程序目录，执行： 1xxxx.exe install 就可以完成服务安装.执行: 1xxxx.exe uninstall 就可以完成服务卸载，非常方便。","link":"/2019/10/31/net-core%E4%BD%BF%E7%94%A8Topshelf%E6%B3%A8%E5%86%8Cwindows%E6%9C%8D%E5%8A%A1/"}],"tags":[{"name":"Docker命令","slug":"Docker命令","link":"/tags/Docker%E5%91%BD%E4%BB%A4/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"Go基础","slug":"Go基础","link":"/tags/Go%E5%9F%BA%E7%A1%80/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"JavaScript ECMAScript","slug":"JavaScript-ECMAScript","link":"/tags/JavaScript-ECMAScript/"},{"name":"nginx","slug":"nginx","link":"/tags/nginx/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Swagger","slug":"Swagger","link":"/tags/Swagger/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"mysql explain","slug":"mysql-explain","link":"/tags/mysql-explain/"},{"name":".net core","slug":"net-core","link":"/tags/net-core/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"autofac","slug":"autofac","link":"/tags/autofac/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"redash","slug":"redash","link":"/tags/redash/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"}],"categories":[{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"JavaScript","slug":"JavaScript","link":"/categories/JavaScript/"},{"name":"Nginx","slug":"Nginx","link":"/categories/Nginx/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"mysql","slug":"mysql","link":"/categories/mysql/"},{"name":".net core","slug":"net-core","link":"/categories/net-core/"},{"name":"shell","slug":"shell","link":"/categories/shell/"}]}